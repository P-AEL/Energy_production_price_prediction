{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbidding = pd.read_csv('bidding_training.csv')\n",
    "df_bidding_imbalance_price = pd.read_csv('bidding_training_predictions_imbalance_price.csv')\n",
    "df_bidding_imbalance_price = df_bidding_imbalance_price[[\"timestamp_utc\",\"imbalance_price_predictions\"]]\n",
    "df_bidding_imbalance_price.timestamp_utc = pd.to_datetime(df_bidding_imbalance_price.timestamp_utc)\n",
    "df_bidding_day_ahead_price = pd.read_csv('bidding_training_predictions_day_ahead_price.csv')\n",
    "df_bidding_day_ahead_price = df_bidding_day_ahead_price[[\"timestamp_utc\",\"day_ahead_price_predictions\"]]\n",
    "df_bidding_day_ahead_price.timestamp_utc = pd.to_datetime(df_bidding_day_ahead_price.timestamp_utc)\n",
    "df_bbidding[\"day_ahead_price\"] = df_bbidding[\"price_x\"].rename(\"day_ahead_price\")\n",
    "df_bbidding[\"market_price\"] = df_bbidding[\"price_y\"].rename(\"market_price\")\n",
    "# df_day_ahead = pd.read_csv('D:/Users/paulh/Desktop/Domäneprojekt2/Energy_production_price_prediction/basic_files/day_ahead_price.csv')\n",
    "# df_imbalance = pd.read_csv('D:/Users/paulh/Desktop/Domäneprojekt2/Energy_production_price_prediction/basic_files/imbalance_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbidding.timestamp_utc = pd.to_datetime(df_bbidding.timestamp_utc)\n",
    "df_bbidding = df_bbidding.merge(df_bidding_imbalance_price, on=\"timestamp_utc\")\n",
    "df_bbidding = df_bbidding.merge(df_bidding_day_ahead_price, on=\"timestamp_utc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        102.844285\n",
       "1        162.689737\n",
       "2        172.662460\n",
       "3        174.278554\n",
       "4        206.460381\n",
       "            ...    \n",
       "41944     23.648000\n",
       "41945     10.865000\n",
       "41946     10.505000\n",
       "41947      4.486000\n",
       "41948      6.580000\n",
       "Name: Target_MW, Length: 41949, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbidding.Target_MW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50% quantil gibt historisch 25437.310022730526 pro periode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbidding[\"Revenue_40\"] = df_bbidding[\"day_ahead_price\"] * df_bbidding[\"4\"]+(df_bbidding[\"Target_MW\"]-df_bbidding[\"4\"])*(df_bbidding[\"imbalance_price\"]-0.07*(df_bbidding[\"Target_MW\"]-df_bbidding[\"4\"]))\n",
    "df_bbidding[\"Revenue_30\"] = df_bbidding[\"day_ahead_price\"] * df_bbidding[\"3\"]+(df_bbidding[\"Target_MW\"]-df_bbidding[\"3\"])*(df_bbidding[\"imbalance_price\"]-0.07*(df_bbidding[\"Target_MW\"]-df_bbidding[\"3\"]))\n",
    "df_bbidding[\"Revenue_20\"] = df_bbidding[\"day_ahead_price\"] * df_bbidding[\"2\"]+(df_bbidding[\"Target_MW\"]-df_bbidding[\"2\"])*(df_bbidding[\"imbalance_price\"]-0.07*(df_bbidding[\"Target_MW\"]-df_bbidding[\"2\"]))\n",
    "df_bbidding[\"Revenue_10\"] = df_bbidding[\"day_ahead_price\"] * df_bbidding[\"1\"]+(df_bbidding[\"Target_MW\"]-df_bbidding[\"1\"])*(df_bbidding[\"imbalance_price\"]-0.07*(df_bbidding[\"Target_MW\"]-df_bbidding[\"1\"]))\n",
    "df_bbidding[\"Revenue_60\"] = df_bbidding[\"day_ahead_price\"] * df_bbidding[\"6\"]+(df_bbidding[\"Target_MW\"]-df_bbidding[\"6\"])*(df_bbidding[\"imbalance_price\"]-0.07*(df_bbidding[\"Target_MW\"]-df_bbidding[\"6\"]))\n",
    "df_bbidding[\"Revenue_50\"] = df_bbidding[\"day_ahead_price\"] * df_bbidding[\"5\"]+(df_bbidding[\"Target_MW\"]-df_bbidding[\"5\"])*(df_bbidding[\"imbalance_price\"]-0.07*(df_bbidding[\"Target_MW\"]-df_bbidding[\"5\"]))\n",
    "df_bbidding[\"Revenue_70\"] = df_bbidding[\"day_ahead_price\"] * df_bbidding[\"7\"]+(df_bbidding[\"Target_MW\"]-df_bbidding[\"7\"])*(df_bbidding[\"imbalance_price\"]-0.07*(df_bbidding[\"Target_MW\"]-df_bbidding[\"7\"]))\n",
    "df_bbidding[\"Revenue_80\"] = df_bbidding[\"day_ahead_price\"] * df_bbidding[\"8\"]+(df_bbidding[\"Target_MW\"]-df_bbidding[\"8\"])*(df_bbidding[\"imbalance_price\"]-0.07*(df_bbidding[\"Target_MW\"]-df_bbidding[\"8\"]))\n",
    "df_bbidding[\"Revenue_90\"] = df_bbidding[\"day_ahead_price\"] * df_bbidding[\"9\"]+(df_bbidding[\"Target_MW\"]-df_bbidding[\"9\"])*(df_bbidding[\"imbalance_price\"]-0.07*(df_bbidding[\"Target_MW\"]-df_bbidding[\"9\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue_10\n",
      "36424.5882388013\n",
      "Revenue_20\n",
      "36525.27897374193\n",
      "Revenue_30\n",
      "36075.702761074645\n",
      "Revenue_40\n",
      "35064.55656388621\n",
      "Revenue_50\n",
      "35100.56368650106\n",
      "Revenue_60\n",
      "34516.787675207015\n",
      "Revenue_70\n",
      "34090.41254056421\n",
      "Revenue_80\n",
      "33174.758811071966\n",
      "Revenue_90\n",
      "30826.51927341632\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(\"Revenue_\"+str(i)+\"0\")\n",
    "    print(df_bbidding[\"Revenue_\"+str(i)+\"0\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the revenue function (objective function)\n",
    "def revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return zb * DAP + (Target_MW - zb) * (imbalance_price - 0.07 * (Target_MW - zb))\n",
    "\n",
    "# Negative revenue function (for minimization)\n",
    "def negative_revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return -revenue(zb, DAP, Target_MW, imbalance_price)\n",
    "\n",
    "# Optimization function to compute the optimal bidding value for each row\n",
    "def optimize_bidding(row):\n",
    "    # Extract the values from the row\n",
    "    DAP = row['day_ahead_price']\n",
    "    Target_MW = row['Target_MW']\n",
    "    imbalance_price = row['imbalance_price']\n",
    "    \n",
    "    # Initial guess for zb (midpoint between 0 and Target_MW)\n",
    "    initial_zb = Target_MW / 2\n",
    "    \n",
    "    # Bounds for zb (as per KKT conditions)\n",
    "    bounds = [(0, 1800)]\n",
    "    \n",
    "    # Perform the optimization\n",
    "    result = minimize(negative_revenue, initial_zb, args=(DAP, Target_MW, imbalance_price), bounds=bounds)\n",
    "    \n",
    "    # Optimal trade value (zb)\n",
    "    return result.x[0]\n",
    "\n",
    "# Apply the optimization to each row and replace column '5' with the optimized trade value\n",
    "df_bbidding['optimized_trade'] = df_bbidding.apply(optimize_bidding, axis=1)\n",
    "\n",
    "# Now calculate the revenue using the optimized trade values\n",
    "df_bbidding['revenue_optimal'] = df_bbidding['day_ahead_price'] * df_bbidding['optimized_trade'] + \\\n",
    "                         (df_bbidding['Target_MW'] - df_bbidding['optimized_trade']) * \\\n",
    "                         (df_bbidding['imbalance_price'] - 0.07 * (df_bbidding['Target_MW'] - df_bbidding['optimized_trade']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit optimierung 56488.5046925057 pro periode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56847.65672443437"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbidding.revenue_optimal.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenue mit estimateten values (LSTM) Mit 50% quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the revenue function (objective function)\n",
    "def revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return zb * DAP + (Target_MW - zb) * (imbalance_price - 0.07 * (Target_MW - zb))\n",
    "\n",
    "# Negative revenue function (for minimization)\n",
    "def negative_revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return -revenue(zb, DAP, Target_MW, imbalance_price)\n",
    "\n",
    "# Optimization function to compute the optimal bidding value for each row\n",
    "def optimize_bidding(row):\n",
    "    # Extract the values from the row\n",
    "    DAP = row['day_ahead_price_predictions']\n",
    "    Target_MW = row['5']\n",
    "    imbalance_price = row['imbalance_price_predictions']\n",
    "    \n",
    "    # Initial guess for zb (midpoint between 0 and Target_MW)\n",
    "    initial_zb = Target_MW / 2\n",
    "    \n",
    "    # Bounds for zb (as per KKT conditions)\n",
    "    bounds = [(0, 1800)]\n",
    "    \n",
    "    # Perform the optimization\n",
    "    result = minimize(negative_revenue, initial_zb, args=(DAP, Target_MW, imbalance_price), bounds=bounds)\n",
    "    \n",
    "    # Optimal trade value (zb)\n",
    "    return result.x[0]\n",
    "\n",
    "# Apply the optimization to each row and replace column '5' with the optimized trade value\n",
    "df_bbidding['optimized_trade'] = df_bbidding.apply(optimize_bidding, axis=1)\n",
    "\n",
    "# Now calculate the revenue using the optimized trade values\n",
    "df_bbidding['revenue_normal'] = df_bbidding['day_ahead_price'] * df_bbidding['optimized_trade'] + \\\n",
    "                         (df_bbidding['Target_MW'] - df_bbidding['optimized_trade']) * \\\n",
    "                         (df_bbidding['imbalance_price'] - 0.07 * (df_bbidding['Target_MW'] - df_bbidding['optimized_trade']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31904.5633050109"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbidding.revenue_normal.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM 40% quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the revenue function (objective function)\n",
    "def revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return zb * DAP + (Target_MW - zb) * (imbalance_price - 0.07 * (Target_MW - zb))\n",
    "\n",
    "# Negative revenue function (for minimization)\n",
    "def negative_revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return -revenue(zb, DAP, Target_MW, imbalance_price)\n",
    "\n",
    "# Optimization function to compute the optimal bidding value for each row\n",
    "def optimize_bidding(row):\n",
    "    # Extract the values from the row\n",
    "    DAP = row['day_ahead_price_predictions']\n",
    "    Target_MW = row['1']\n",
    "    imbalance_price = row['imbalance_price_predictions']\n",
    "    \n",
    "    # Initial guess for zb (midpoint between 0 and Target_MW)\n",
    "    initial_zb = Target_MW / 2\n",
    "    \n",
    "    # Bounds for zb (as per KKT conditions)\n",
    "    bounds = [(0, 1800)]\n",
    "    \n",
    "    # Perform the optimization\n",
    "    result = minimize(negative_revenue, initial_zb, args=(DAP, Target_MW, imbalance_price), bounds=bounds)\n",
    "    \n",
    "    # Optimal trade value (zb)\n",
    "    return result.x[0]\n",
    "\n",
    "# Apply the optimization to each row and replace column '5' with the optimized trade value\n",
    "df_bbidding['optimized_trade'] = df_bbidding.apply(optimize_bidding, axis=1)\n",
    "\n",
    "# Now calculate the revenue using the optimized trade values\n",
    "df_bbidding['revenue_normal'] = df_bbidding['day_ahead_price'] * df_bbidding['optimized_trade'] + \\\n",
    "                         (df_bbidding['Target_MW'] - df_bbidding['optimized_trade']) * \\\n",
    "                         (df_bbidding['imbalance_price'] - 0.07 * (df_bbidding['Target_MW'] - df_bbidding['optimized_trade']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33951.44619676805"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbidding.revenue_normal.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On newer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.1):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        \n",
    "        # Parameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define the LSTM layer(s)\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, \n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.dropout)\n",
    "        \n",
    "        # Fully connected layer to map LSTM output to the target size\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states for LSTM\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  # Hidden state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  # Cell state\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # We only need the output\n",
    "        \n",
    "        # Get the last output (many-to-one), out[:, -1, :] gives the last time step\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Pass the output through a fully connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "path_df = os.path.abspath(os.path.join(current_dir, '..', 'basic_files'))\n",
    "df_total_solar = pd.read_csv(os.path.join(path_df, 'solar_total_production.csv'))\n",
    "df_total_solar.generation_mw = df_total_solar.generation_mw *0.5\n",
    "df_total_wind = pd.read_csv(os.path.join(path_df, 'wind_total_production.csv'))\n",
    "df_total_wind.generation_mw = df_total_wind.generation_mw *0.5 - df_total_wind.boa\n",
    "df_imbalance_price = pd.read_csv(os.path.join(path_df, 'imbalance_price.csv'))\n",
    "df_day_ahead_price = pd.read_csv(os.path.join(path_df, 'day_ahead_price.csv'))\n",
    "df_market_price = pd.read_csv(os.path.join(path_df, 'market_index.csv'))\n",
    "\n",
    "# Get the path to the 'logs' directory in the parent directory\n",
    "path = os.path.abspath(os.path.join(current_dir, '..', 'logs'))\n",
    "files = os.listdir(path)\n",
    "txt_files = [file for file in files if file.endswith('.txt')]\n",
    "data = []\n",
    "for file in txt_files:\n",
    "    with open(os.path.join(path, file), 'r') as f:\n",
    "        try:\n",
    "            json_data = json.load(f)\n",
    "            data.append(json_data)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to decode JSON from file: {file}\")\n",
    "date_name = []\n",
    "for i in range(len(data)):\n",
    "    date_name.append(data[i][\"prediction_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahiere Daten\n",
    "dataframe_list = []\n",
    "\n",
    "for entry in data:\n",
    "    prediction_date = entry['prediction_date']\n",
    "    \n",
    "    # Iteriere durch jedes 'submission' Element\n",
    "    for submission in entry['solution']['submission']:\n",
    "        timestamp = submission['timestamp']\n",
    "        probabilistic_forecast = submission['probabilistic_forecast']\n",
    "        \n",
    "        # Extrahiere die Werte von 'probabilistic_forecast' und füge sie der Liste hinzu\n",
    "        row = {\n",
    "            'prediction_date': prediction_date,\n",
    "            'timestamp': timestamp,\n",
    "            '1': probabilistic_forecast.get('10', None),\n",
    "            '2': probabilistic_forecast.get('20', None),\n",
    "            '3': probabilistic_forecast.get('30', None),\n",
    "            '4': probabilistic_forecast.get('40', None),\n",
    "            '5': probabilistic_forecast.get('50', None),\n",
    "            '6': probabilistic_forecast.get('60', None),\n",
    "            '7': probabilistic_forecast.get('70', None),\n",
    "            '8': probabilistic_forecast.get('80', None),\n",
    "            '9': probabilistic_forecast.get('90', None)\n",
    "        }\n",
    "        dataframe_list.append(row)\n",
    "\n",
    "# Erstelle DataFrame\n",
    "df_api_new = pd.DataFrame(dataframe_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_new = df_api_new.groupby(\"timestamp\").last().reset_index()\n",
    "df_api_new.timestamp = pd.to_datetime(df_api_new.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a continuous time series from the minimum to maximum timestamp at 30-minute intervals\n",
    "full_timestamp_range = pd.date_range(start=df_api_new['timestamp'].min(), end=df_api_new['timestamp'].max(), freq='30min')\n",
    "# Reindex the dataframe using the full range of timestamps\n",
    "df_api_new_1 = df_api_new.set_index('timestamp').reindex(full_timestamp_range, method=None)\n",
    "df_api_new_1 = df_api_new_1.reset_index().rename(columns={'index': 'timestamp'})\n",
    "# Create the 'prediction_date' column based on the timestamp\n",
    "df_api_new_1['prediction_date'] = df_api_new_1['timestamp'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prediction_date</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-03 22:00:00+00:00</td>\n",
       "      <td>2024-10-03</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>1357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-03 22:30:00+00:00</td>\n",
       "      <td>2024-10-03</td>\n",
       "      <td>788.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-03 23:00:00+00:00</td>\n",
       "      <td>2024-10-03</td>\n",
       "      <td>571.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-03 23:30:00+00:00</td>\n",
       "      <td>2024-10-03</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-04 00:00:00+00:00</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>1340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>2024-10-28 20:30:00+00:00</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>2024-10-28 21:00:00+00:00</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>2024-10-28 21:30:00+00:00</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2024-10-28 22:00:00+00:00</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>2024-10-28 22:30:00+00:00</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     timestamp prediction_date       1       2       3  \\\n",
       "0    2024-10-03 22:00:00+00:00      2024-10-03  1355.0   487.0   963.0   \n",
       "1    2024-10-03 22:30:00+00:00      2024-10-03   788.0   584.0  1148.0   \n",
       "2    2024-10-03 23:00:00+00:00      2024-10-03   571.0   748.0  1001.0   \n",
       "3    2024-10-03 23:30:00+00:00      2024-10-03  1476.0  1194.0  1512.0   \n",
       "4    2024-10-04 00:00:00+00:00      2024-10-04  1352.0  1390.0   912.0   \n",
       "...                        ...             ...     ...     ...     ...   \n",
       "1197 2024-10-28 20:30:00+00:00      2024-10-28     1.0     8.0    20.0   \n",
       "1198 2024-10-28 21:00:00+00:00      2024-10-28     2.0     8.0    18.0   \n",
       "1199 2024-10-28 21:30:00+00:00      2024-10-28     1.0     4.0    12.0   \n",
       "1200 2024-10-28 22:00:00+00:00      2024-10-28     0.0     2.0     7.0   \n",
       "1201 2024-10-28 22:30:00+00:00      2024-10-28     0.0     0.0     6.0   \n",
       "\n",
       "           4       5       6       7       8       9  \n",
       "0     1544.0  1330.0   867.0   326.0  1402.0  1357.0  \n",
       "1     1320.0  1007.0   565.0   923.0   797.0   487.0  \n",
       "2     1460.0   740.0  1017.0  1533.0   597.0   991.0  \n",
       "3      334.0  1054.0  1572.0   744.0  1497.0   463.0  \n",
       "4      662.0  1505.0  1093.0   814.0   487.0  1340.0  \n",
       "...      ...     ...     ...     ...     ...     ...  \n",
       "1197    36.0    48.0    61.0    74.0    92.0   126.0  \n",
       "1198    32.0    43.0    56.0    66.0    80.0   118.0  \n",
       "1199    25.0    37.0    49.0    57.0    70.0   106.0  \n",
       "1200    20.0    31.0    43.0    51.0    60.0   100.0  \n",
       "1201    15.0    26.0    34.0    43.0    55.0    93.0  \n",
       "\n",
       "[1202 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_ahead_price.timestamp_utc = pd.to_datetime(df_day_ahead_price.timestamp_utc)\n",
    "df_market_price.timestamp_utc = pd.to_datetime(df_market_price.timestamp_utc)\n",
    "df_imbalance_price.timestamp_utc = pd.to_datetime(df_imbalance_price.timestamp_utc)\n",
    "df_api_new_merged = pd.merge(df_api_new_1,df_day_ahead_price, left_on='timestamp', right_on='timestamp_utc', how='left')\n",
    "df_api_new_merged = pd.merge(df_api_new_merged,df_market_price, left_on='timestamp', right_on='timestamp_utc', how='left')\n",
    "df_api_new_merged = pd.merge(df_api_new_merged,df_imbalance_price, left_on='timestamp', right_on='timestamp_utc', how='left')\n",
    "df_api_new_merged[\"day_ahead_price\"] = df_api_new_merged[\"price_x\"].rename(\"day_ahead_price\")\n",
    "df_api_new_merged[\"market_price\"] = df_api_new_merged[\"price_y\"].rename(\"market_price\")\n",
    "df_api_new_merged[\"settlement_period\"] = df_api_new_merged[\"settlement_period_x\"].rename(\"settlement_period\")\n",
    "df_api_new_merged[\"cos_hour\"] = np.cos(2*np.pi*df_api_new_merged[\"timestamp\"].dt.hour/24)\n",
    "df_api_new_merged[\"cos_day\"] = np.cos(2*np.pi*df_api_new_merged[\"timestamp\"].dt.day/7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_new_merged1 = df_api_new_merged[[\"timestamp_utc\",\"market_price\",\"day_ahead_price\",\"volume\",\"settlement_period\",\"cos_hour\",\"cos_day\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"imbalance_price\"]].copy()\n",
    "df_api_new_merged1.loc[:,\"market_price_lag96h\"] = df_api_new_merged1[\"market_price\"].shift(192)\n",
    "df_api_new_merged1.loc[:,\"imbalance_price_lag96h\"] = df_api_new_merged1[\"imbalance_price\"].shift(192)\n",
    "df_api_new_merged1.loc[:,\"day_ahead_price_lag1week\"] = df_api_new_merged1[\"day_ahead_price\"].shift(192)\n",
    "df_api_new_merged1.loc[:,\"volume_lag96h\"] = df_api_new_merged1[\"volume\"].shift(96)\n",
    "df_api_new_merged1.dropna(inplace=True)\n",
    "df_api_new_merged1 = df_api_new_merged1.groupby(\"timestamp_utc\").last().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_total = pd.read_csv('D:/Users/paulh/Desktop/Domäneprojekt2/Energy_production_price_prediction/basic_files/solar_total_production.csv')\n",
    "wind_total = pd.read_csv('D:/Users/paulh/Desktop/Domäneprojekt2/Energy_production_price_prediction/basic_files/wind_total_production.csv')\n",
    "solar_total.generation_mw = solar_total.generation_mw * 0.5\n",
    "wind_total.generation_mw = wind_total.generation_mw * 0.5 - wind_total.boa\n",
    "solar_total.timestamp_utc = pd.to_datetime(solar_total.timestamp_utc)\n",
    "wind_total.timestamp_utc = pd.to_datetime(wind_total.timestamp_utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>market_price</th>\n",
       "      <th>day_ahead_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>settlement_period_x</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>imbalance_price_lag96h</th>\n",
       "      <th>day_ahead_price_lag1week</th>\n",
       "      <th>volume_lag96h</th>\n",
       "      <th>generation_solar</th>\n",
       "      <th>installed_capacity_mwp</th>\n",
       "      <th>capacity_mwp</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_period_y</th>\n",
       "      <th>boa</th>\n",
       "      <th>generation_wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-07 22:00:00+00:00</td>\n",
       "      <td>82.03</td>\n",
       "      <td>89.55</td>\n",
       "      <td>964.20</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.00</td>\n",
       "      <td>78.47</td>\n",
       "      <td>1627.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.745251</td>\n",
       "      <td>2779.542388</td>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-07 22:30:00+00:00</td>\n",
       "      <td>84.67</td>\n",
       "      <td>89.55</td>\n",
       "      <td>1265.00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.00</td>\n",
       "      <td>78.47</td>\n",
       "      <td>1469.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.745251</td>\n",
       "      <td>2779.542388</td>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-07 23:00:00+00:00</td>\n",
       "      <td>79.56</td>\n",
       "      <td>87.15</td>\n",
       "      <td>1112.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.50</td>\n",
       "      <td>71.36</td>\n",
       "      <td>1405.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.745251</td>\n",
       "      <td>2779.542388</td>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-07 23:30:00+00:00</td>\n",
       "      <td>75.63</td>\n",
       "      <td>87.15</td>\n",
       "      <td>1240.55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.50</td>\n",
       "      <td>71.36</td>\n",
       "      <td>1268.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.745251</td>\n",
       "      <td>2779.477654</td>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-08 00:00:00+00:00</td>\n",
       "      <td>74.84</td>\n",
       "      <td>81.06</td>\n",
       "      <td>1297.45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.00</td>\n",
       "      <td>72.80</td>\n",
       "      <td>1428.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.745251</td>\n",
       "      <td>2779.477632</td>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>2024-10-20 19:30:00+00:00</td>\n",
       "      <td>2.81</td>\n",
       "      <td>17.41</td>\n",
       "      <td>1977.30</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>457.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.75</td>\n",
       "      <td>84.34</td>\n",
       "      <td>3138.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.745251</td>\n",
       "      <td>2778.700041</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>2024-10-20 20:00:00+00:00</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1974.55</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>454.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.00</td>\n",
       "      <td>79.89</td>\n",
       "      <td>2824.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.745251</td>\n",
       "      <td>2778.700028</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2024-10-20 20:30:00+00:00</td>\n",
       "      <td>-5.10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2086.35</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>454.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.00</td>\n",
       "      <td>79.89</td>\n",
       "      <td>2783.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.745251</td>\n",
       "      <td>2778.700025</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2024-10-20 21:00:00+00:00</td>\n",
       "      <td>2.71</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>1830.75</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>351.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.00</td>\n",
       "      <td>83.31</td>\n",
       "      <td>2833.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.745251</td>\n",
       "      <td>2778.700013</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>586.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2024-10-20 21:30:00+00:00</td>\n",
       "      <td>-9.74</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>2016.45</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>273.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.60</td>\n",
       "      <td>83.31</td>\n",
       "      <td>2816.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.745251</td>\n",
       "      <td>2778.699982</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>587.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp_utc  market_price  day_ahead_price   volume  \\\n",
       "0   2024-10-07 22:00:00+00:00         82.03            89.55   964.20   \n",
       "1   2024-10-07 22:30:00+00:00         84.67            89.55  1265.00   \n",
       "2   2024-10-07 23:00:00+00:00         79.56            87.15  1112.60   \n",
       "3   2024-10-07 23:30:00+00:00         75.63            87.15  1240.55   \n",
       "4   2024-10-08 00:00:00+00:00         74.84            81.06  1297.45   \n",
       "..                        ...           ...              ...      ...   \n",
       "568 2024-10-20 19:30:00+00:00          2.81            17.41  1977.30   \n",
       "569 2024-10-20 20:00:00+00:00         12.79             0.86  1974.55   \n",
       "570 2024-10-20 20:30:00+00:00         -5.10             0.86  2086.35   \n",
       "571 2024-10-20 21:00:00+00:00          2.71            -2.14  1830.75   \n",
       "572 2024-10-20 21:30:00+00:00         -9.74            -2.14  2016.45   \n",
       "\n",
       "     settlement_period_x  cos_hour  cos_day      1      2      3  ...  \\\n",
       "0                   47.0  0.866025  1.00000   19.0   17.0   15.0  ...   \n",
       "1                   48.0  0.866025  1.00000   19.0   17.0   15.0  ...   \n",
       "2                    1.0  0.965926  1.00000   19.0   17.0   15.0  ...   \n",
       "3                    2.0  0.965926  1.00000   19.0   17.0   15.0  ...   \n",
       "4                    3.0  1.000000  0.62349   18.0   16.0   14.0  ...   \n",
       "..                   ...       ...      ...    ...    ...    ...  ...   \n",
       "568                 42.0  0.258819  0.62349  457.0  495.0  499.0  ...   \n",
       "569                 43.0  0.500000  0.62349  454.0  459.0  493.0  ...   \n",
       "570                 44.0  0.500000  0.62349  454.0  464.0  489.0  ...   \n",
       "571                 45.0  0.707107  0.62349  351.0  469.0  485.0  ...   \n",
       "572                 46.0  0.707107  0.62349  273.0  375.0  432.0  ...   \n",
       "\n",
       "     imbalance_price_lag96h  day_ahead_price_lag1week  volume_lag96h  \\\n",
       "0                     61.00                     78.47        1627.05   \n",
       "1                     50.00                     78.47        1469.90   \n",
       "2                     93.50                     71.36        1405.55   \n",
       "3                     93.50                     71.36        1268.95   \n",
       "4                     93.00                     72.80        1428.80   \n",
       "..                      ...                       ...            ...   \n",
       "568                   69.75                     84.34        3138.10   \n",
       "569                  105.00                     79.89        2824.65   \n",
       "570                  102.00                     79.89        2783.75   \n",
       "571                  102.00                     83.31        2833.30   \n",
       "572                   70.60                     83.31        2816.95   \n",
       "\n",
       "     generation_solar  installed_capacity_mwp  capacity_mwp  settlement_date  \\\n",
       "0                 0.0             2956.745251   2779.542388       2024-10-07   \n",
       "1                 0.0             2956.745251   2779.542388       2024-10-07   \n",
       "2                 0.0             2956.745251   2779.542388       2024-10-08   \n",
       "3                 0.0             2956.745251   2779.477654       2024-10-08   \n",
       "4                 0.0             2956.745251   2779.477632       2024-10-08   \n",
       "..                ...                     ...           ...              ...   \n",
       "568               0.0             2956.745251   2778.700041       2024-10-20   \n",
       "569               0.0             2956.745251   2778.700028       2024-10-20   \n",
       "570               0.0             2956.745251   2778.700025       2024-10-20   \n",
       "571               0.0             2956.745251   2778.700013       2024-10-20   \n",
       "572               0.0             2956.745251   2778.699982       2024-10-20   \n",
       "\n",
       "     settlement_period_y  boa  generation_wind  \n",
       "0                     47  0.0          236.742  \n",
       "1                     48  0.0          154.032  \n",
       "2                      1  0.0          124.472  \n",
       "3                      2  0.0          145.582  \n",
       "4                      3  0.0          160.762  \n",
       "..                   ...  ...              ...  \n",
       "568                   42  0.0          586.852  \n",
       "569                   43  0.0          586.992  \n",
       "570                   44  0.0          586.911  \n",
       "571                   45  0.0          586.851  \n",
       "572                   46  0.0          587.082  \n",
       "\n",
       "[573 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_merged2 = pd.merge(df_api_new_merged1,solar_total, on=\"timestamp_utc\", how=\"inner\")\n",
    "df_api_new_merged2 = pd.merge(df_api_new_merged2,wind_total, on=\"timestamp_utc\", how=\"inner\")\n",
    "df_api_new_merged2 = df_api_new_merged2.rename(columns={\n",
    "    \"generation_mw_x\": \"generation_solar\",\n",
    "    \"generation_mw_y\": \"generation_wind\"\n",
    "})\n",
    "df_api_new_merged2 = df_api_new_merged2.groupby(\"timestamp_utc\").last().reset_index()\n",
    "df_api_new_merged2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulh\\anaconda3\\envs\\HEFTcom24\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "df_api_new_merged2_X = df_api_new_merged2[[\"market_price_lag96h\",\"imbalance_price_lag96h\",\"day_ahead_price_lag1week\",\"volume_lag96h\",\n",
    "                    \"cos_hour\",\"cos_day\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]].copy()\n",
    "\n",
    "scaler_path = \"LSTM_imbalance_scaler.pkl\"\n",
    "# Laden des StandardScalers aus der Datei\n",
    "with open(scaler_path, 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "# Skalieren der Daten\n",
    "df_api_new_merged2_X_scaled = scaler.transform(df_api_new_merged2_X)\n",
    "\n",
    "# Konvertieren der Daten in PyTorch-Tensoren\n",
    "X_test = torch.tensor(df_api_new_merged2_X_scaled, dtype=torch.float32)\n",
    "X_test = X_test.unsqueeze(1)  # Adds a sequence length dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_9060\\1576695596.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_imbalance.load_state_dict(torch.load(\"LSTM_imbalance_price.pth\"))\n"
     ]
    }
   ],
   "source": [
    "input_size = 15  # Number of features\n",
    "hidden_size = 64              # Number of LSTM units\n",
    "num_layers = 3                 # Number of LSTM layers\n",
    "output_size = 1                # Always 9 for 9 quantiles\n",
    "dropout = 0.1  \n",
    "model_imbalance = LSTMPredictor(input_size, hidden_size, num_layers, output_size, dropout=dropout)\n",
    "model_imbalance.load_state_dict(torch.load(\"LSTM_imbalance_price.pth\"))\n",
    "# Modell in den Evaluierungsmodus versetzen\n",
    "model_imbalance.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_imbalance(X_test)\n",
    "predictions = predictions.numpy()\n",
    "df_api_new_merged2[\"imvalance_price_predictions\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_9060\\823899303.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_imbalance.load_state_dict(torch.load(\"LSTM_day_ahead_price.pth\"))\n"
     ]
    }
   ],
   "source": [
    "input_size = 15  # Number of features\n",
    "hidden_size = 64              # Number of LSTM units\n",
    "num_layers = 3                 # Number of LSTM layers\n",
    "output_size = 1                # Always 9 for 9 quantiles\n",
    "dropout = 0.1  \n",
    "model_imbalance = LSTMPredictor(input_size, hidden_size, num_layers, output_size, dropout=dropout)\n",
    "model_imbalance.load_state_dict(torch.load(\"LSTM_day_ahead_price.pth\"))\n",
    "# Modell in den Evaluierungsmodus versetzen\n",
    "model_imbalance.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_imbalance(X_test)\n",
    "predictions = predictions.numpy()\n",
    "df_api_new_merged2[\"day_ahead_price_predictions\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_new_merged2[\"Total_MW\"] = df_api_new_merged2[\"generation_solar\"] + df_api_new_merged2[\"generation_wind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_new_merged2[\"Revenue_40\"] = df_api_new_merged2[\"day_ahead_price\"] * df_api_new_merged2[\"4\"]+(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"4\"])*(df_api_new_merged2[\"imbalance_price\"]-0.07*(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"4\"]))\n",
    "df_api_new_merged2[\"Revenue_30\"] = df_api_new_merged2[\"day_ahead_price\"] * df_api_new_merged2[\"3\"]+(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"3\"])*(df_api_new_merged2[\"imbalance_price\"]-0.07*(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"3\"]))\n",
    "df_api_new_merged2[\"Revenue_20\"] = df_api_new_merged2[\"day_ahead_price\"] * df_api_new_merged2[\"2\"]+(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"2\"])*(df_api_new_merged2[\"imbalance_price\"]-0.07*(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"2\"]))\n",
    "df_api_new_merged2[\"Revenue_10\"] = df_api_new_merged2[\"day_ahead_price\"] * df_api_new_merged2[\"1\"]+(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"1\"])*(df_api_new_merged2[\"imbalance_price\"]-0.07*(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"1\"]))\n",
    "df_api_new_merged2[\"Revenue_60\"] = df_api_new_merged2[\"day_ahead_price\"] * df_api_new_merged2[\"6\"]+(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"6\"])*(df_api_new_merged2[\"imbalance_price\"]-0.07*(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"6\"]))\n",
    "df_api_new_merged2[\"Revenue_50\"] = df_api_new_merged2[\"day_ahead_price\"] * df_api_new_merged2[\"5\"]+(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"5\"])*(df_api_new_merged2[\"imbalance_price\"]-0.07*(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"5\"]))\n",
    "df_api_new_merged2[\"Revenue_70\"] = df_api_new_merged2[\"day_ahead_price\"] * df_api_new_merged2[\"7\"]+(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"7\"])*(df_api_new_merged2[\"imbalance_price\"]-0.07*(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"7\"]))\n",
    "df_api_new_merged2[\"Revenue_80\"] = df_api_new_merged2[\"day_ahead_price\"] * df_api_new_merged2[\"8\"]+(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"8\"])*(df_api_new_merged2[\"imbalance_price\"]-0.07*(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"8\"]))\n",
    "df_api_new_merged2[\"Revenue_90\"] = df_api_new_merged2[\"day_ahead_price\"] * df_api_new_merged2[\"9\"]+(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"9\"])*(df_api_new_merged2[\"imbalance_price\"]-0.07*(df_api_new_merged2[\"Total_MW\"]-df_api_new_merged2[\"9\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue_10\n",
      "19056.990460588167\n",
      "Revenue_20\n",
      "17729.016953714145\n",
      "Revenue_30\n",
      "16754.83375579182\n",
      "Revenue_40\n",
      "15749.975818222612\n",
      "Revenue_50\n",
      "14652.257943307106\n",
      "Revenue_60\n",
      "13528.402400646952\n",
      "Revenue_70\n",
      "12260.181638465367\n",
      "Revenue_80\n",
      "10869.665811891955\n",
      "Revenue_90\n",
      "9107.413710058461\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(\"Revenue_\"+str(i)+\"0\")\n",
    "    print(df_api_new_merged2[\"Revenue_\"+str(i)+\"0\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the revenue function (objective function)\n",
    "def revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return zb * DAP + (Target_MW - zb) * (imbalance_price - 0.07 * (Target_MW - zb))\n",
    "\n",
    "# Negative revenue function (for minimization)\n",
    "def negative_revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return -revenue(zb, DAP, Target_MW, imbalance_price)\n",
    "\n",
    "# Optimization function to compute the optimal bidding value for each row\n",
    "def optimize_bidding(row):\n",
    "    # Extract the values from the row\n",
    "    DAP = row['day_ahead_price_predictions']\n",
    "    Target_MW = row['1']\n",
    "    imbalance_price = row['imvalance_price_predictions']\n",
    "    \n",
    "    # Initial guess for zb (midpoint between 0 and Target_MW)\n",
    "    initial_zb = Target_MW / 2\n",
    "    \n",
    "    # Bounds for zb (as per KKT conditions)\n",
    "    bounds = [(0, 1800)]\n",
    "    \n",
    "    # Perform the optimization\n",
    "    result = minimize(negative_revenue, initial_zb, args=(DAP, Target_MW, imbalance_price), bounds=bounds)\n",
    "    \n",
    "    # Optimal trade value (zb)\n",
    "    return result.x[0]\n",
    "\n",
    "# Apply the optimization to each row and replace column '5' with the optimized trade value\n",
    "df_api_new_merged2['optimized_trade'] = df_api_new_merged2.apply(optimize_bidding, axis=1)\n",
    "\n",
    "# Now calculate the revenue using the optimized trade values\n",
    "df_api_new_merged2['revenue_normal'] = df_api_new_merged2['day_ahead_price'] * df_api_new_merged2['optimized_trade'] + \\\n",
    "                         (df_api_new_merged2['Total_MW'] - df_api_new_merged2['optimized_trade']) * \\\n",
    "                         (df_api_new_merged2['imbalance_price'] - 0.07 * (df_api_new_merged2['Total_MW'] - df_api_new_merged2['optimized_trade']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21515.020879050517"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_merged2.revenue_normal.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_new_merged3 = df_api_new_merged2[300:302].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the revenue function (objective function)\n",
    "def revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return zb * DAP + (Target_MW - zb) * (imbalance_price - 0.07 * (Target_MW - zb))\n",
    "\n",
    "# Negative revenue function (for minimization)\n",
    "def negative_revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return -revenue(zb, DAP, Target_MW, imbalance_price)\n",
    "\n",
    "# Optimization function to compute the optimal bidding value for each row\n",
    "def optimize_bidding(row):\n",
    "    # Extract the values from the row\n",
    "    DAP = row['day_ahead_price_predictions']\n",
    "    Target_MW = row['1']\n",
    "    imbalance_price = row['imvalance_price_predictions']\n",
    "    \n",
    "    # Initial guess for zb (midpoint between 0 and Target_MW)\n",
    "    initial_zb = Target_MW / 2\n",
    "    \n",
    "    # Bounds for zb (as per KKT conditions)\n",
    "    bounds = [(0, 1800)]\n",
    "    \n",
    "    # Perform the optimization\n",
    "    result = minimize(negative_revenue, initial_zb, args=(DAP, Target_MW, imbalance_price), bounds=bounds)\n",
    "    \n",
    "    # Optimal trade value (zb)\n",
    "    return result.x[0]\n",
    "\n",
    "# Apply the optimization to each row and replace column '5' with the optimized trade value\n",
    "df_api_new_merged2['optimized_trade'] = df_api_new_merged2.apply(optimize_bidding, axis=1)\n",
    "# Now calculate the revenue using the optimized trade values\n",
    "df_api_new_merged2['revenue_normal2'] = df_api_new_merged2['day_ahead_price'] * df_api_new_merged2['optimized_trade'] + \\\n",
    "                         (df_api_new_merged2['Total_MW'] - df_api_new_merged2['optimized_trade']) * \\\n",
    "                         (df_api_new_merged2['imbalance_price'] - 0.07 * (df_api_new_merged2['Total_MW'] - df_api_new_merged2['optimized_trade']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21515.020879050517"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_merged2.revenue_normal2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>market_price</th>\n",
       "      <th>day_ahead_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>settlement_period_x</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>Revenue_60</th>\n",
       "      <th>Revenue_50</th>\n",
       "      <th>Revenue_70</th>\n",
       "      <th>Revenue_80</th>\n",
       "      <th>Revenue_90</th>\n",
       "      <th>optimized_trade</th>\n",
       "      <th>revenue_normal</th>\n",
       "      <th>day_ahead_price_predictions_MLP</th>\n",
       "      <th>imbalance_price_predictions_MLP</th>\n",
       "      <th>optimized_trade_MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-07 22:00:00+00:00</td>\n",
       "      <td>82.03</td>\n",
       "      <td>89.55</td>\n",
       "      <td>964.20</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19927.996821</td>\n",
       "      <td>19970.864581</td>\n",
       "      <td>19884.569061</td>\n",
       "      <td>19818.377421</td>\n",
       "      <td>19773.549661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21019.665296</td>\n",
       "      <td>104.212471</td>\n",
       "      <td>95.558464</td>\n",
       "      <td>71.814693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-07 22:30:00+00:00</td>\n",
       "      <td>84.67</td>\n",
       "      <td>89.55</td>\n",
       "      <td>1265.00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8861.737848</td>\n",
       "      <td>8949.446808</td>\n",
       "      <td>8773.468888</td>\n",
       "      <td>8640.015448</td>\n",
       "      <td>8550.346488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11373.687127</td>\n",
       "      <td>105.951241</td>\n",
       "      <td>97.339027</td>\n",
       "      <td>71.515876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-07 23:00:00+00:00</td>\n",
       "      <td>79.56</td>\n",
       "      <td>87.15</td>\n",
       "      <td>1112.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7434.751125</td>\n",
       "      <td>7509.383285</td>\n",
       "      <td>7321.752885</td>\n",
       "      <td>7207.494645</td>\n",
       "      <td>7169.128565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9645.595935</td>\n",
       "      <td>100.186302</td>\n",
       "      <td>91.008759</td>\n",
       "      <td>75.553457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-07 23:30:00+00:00</td>\n",
       "      <td>75.63</td>\n",
       "      <td>87.15</td>\n",
       "      <td>1240.55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8452.595529</td>\n",
       "      <td>8533.138489</td>\n",
       "      <td>8330.731089</td>\n",
       "      <td>8207.606649</td>\n",
       "      <td>8166.285169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10969.810809</td>\n",
       "      <td>99.638420</td>\n",
       "      <td>89.974419</td>\n",
       "      <td>79.028560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-08 00:00:00+00:00</td>\n",
       "      <td>74.84</td>\n",
       "      <td>81.06</td>\n",
       "      <td>1297.45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8906.957315</td>\n",
       "      <td>9019.087355</td>\n",
       "      <td>8831.503955</td>\n",
       "      <td>8755.490595</td>\n",
       "      <td>8678.917235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10867.184122</td>\n",
       "      <td>97.923981</td>\n",
       "      <td>90.149330</td>\n",
       "      <td>65.532779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>2024-10-20 19:30:00+00:00</td>\n",
       "      <td>2.81</td>\n",
       "      <td>17.41</td>\n",
       "      <td>1977.30</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>457.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8975.849387</td>\n",
       "      <td>8855.702987</td>\n",
       "      <td>9022.927947</td>\n",
       "      <td>9227.851467</td>\n",
       "      <td>9293.639307</td>\n",
       "      <td>1037.848672</td>\n",
       "      <td>9860.262009</td>\n",
       "      <td>112.034363</td>\n",
       "      <td>105.348930</td>\n",
       "      <td>564.752983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>2024-10-20 20:00:00+00:00</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1974.55</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>454.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>...</td>\n",
       "      <td>996.896076</td>\n",
       "      <td>1010.406156</td>\n",
       "      <td>989.872716</td>\n",
       "      <td>968.584876</td>\n",
       "      <td>949.179276</td>\n",
       "      <td>911.956130</td>\n",
       "      <td>781.944115</td>\n",
       "      <td>105.483566</td>\n",
       "      <td>98.309685</td>\n",
       "      <td>559.244751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2024-10-20 20:30:00+00:00</td>\n",
       "      <td>-5.10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2086.35</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>454.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-334.542154</td>\n",
       "      <td>-470.602474</td>\n",
       "      <td>-269.871994</td>\n",
       "      <td>-75.163974</td>\n",
       "      <td>19.878806</td>\n",
       "      <td>904.664785</td>\n",
       "      <td>209.094577</td>\n",
       "      <td>106.493591</td>\n",
       "      <td>99.802856</td>\n",
       "      <td>551.791490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2024-10-20 21:00:00+00:00</td>\n",
       "      <td>2.71</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>1830.75</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>351.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1268.763424</td>\n",
       "      <td>-1355.411384</td>\n",
       "      <td>-1235.729444</td>\n",
       "      <td>-1206.376324</td>\n",
       "      <td>-1190.241484</td>\n",
       "      <td>823.025564</td>\n",
       "      <td>-1183.573987</td>\n",
       "      <td>107.793663</td>\n",
       "      <td>98.813057</td>\n",
       "      <td>565.148542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2024-10-20 21:30:00+00:00</td>\n",
       "      <td>-9.74</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>2016.45</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>273.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2221.590151</td>\n",
       "      <td>-2429.286431</td>\n",
       "      <td>-2115.441271</td>\n",
       "      <td>-1872.119071</td>\n",
       "      <td>-1827.234631</td>\n",
       "      <td>681.801120</td>\n",
       "      <td>-1382.884710</td>\n",
       "      <td>107.551636</td>\n",
       "      <td>97.553589</td>\n",
       "      <td>572.414838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp_utc  market_price  day_ahead_price   volume  \\\n",
       "0   2024-10-07 22:00:00+00:00         82.03            89.55   964.20   \n",
       "1   2024-10-07 22:30:00+00:00         84.67            89.55  1265.00   \n",
       "2   2024-10-07 23:00:00+00:00         79.56            87.15  1112.60   \n",
       "3   2024-10-07 23:30:00+00:00         75.63            87.15  1240.55   \n",
       "4   2024-10-08 00:00:00+00:00         74.84            81.06  1297.45   \n",
       "..                        ...           ...              ...      ...   \n",
       "568 2024-10-20 19:30:00+00:00          2.81            17.41  1977.30   \n",
       "569 2024-10-20 20:00:00+00:00         12.79             0.86  1974.55   \n",
       "570 2024-10-20 20:30:00+00:00         -5.10             0.86  2086.35   \n",
       "571 2024-10-20 21:00:00+00:00          2.71            -2.14  1830.75   \n",
       "572 2024-10-20 21:30:00+00:00         -9.74            -2.14  2016.45   \n",
       "\n",
       "     settlement_period_x  cos_hour  cos_day      1      2      3  ...  \\\n",
       "0                   47.0  0.866025  1.00000   19.0   17.0   15.0  ...   \n",
       "1                   48.0  0.866025  1.00000   19.0   17.0   15.0  ...   \n",
       "2                    1.0  0.965926  1.00000   19.0   17.0   15.0  ...   \n",
       "3                    2.0  0.965926  1.00000   19.0   17.0   15.0  ...   \n",
       "4                    3.0  1.000000  0.62349   18.0   16.0   14.0  ...   \n",
       "..                   ...       ...      ...    ...    ...    ...  ...   \n",
       "568                 42.0  0.258819  0.62349  457.0  495.0  499.0  ...   \n",
       "569                 43.0  0.500000  0.62349  454.0  459.0  493.0  ...   \n",
       "570                 44.0  0.500000  0.62349  454.0  464.0  489.0  ...   \n",
       "571                 45.0  0.707107  0.62349  351.0  469.0  485.0  ...   \n",
       "572                 46.0  0.707107  0.62349  273.0  375.0  432.0  ...   \n",
       "\n",
       "       Revenue_60    Revenue_50    Revenue_70    Revenue_80    Revenue_90  \\\n",
       "0    19927.996821  19970.864581  19884.569061  19818.377421  19773.549661   \n",
       "1     8861.737848   8949.446808   8773.468888   8640.015448   8550.346488   \n",
       "2     7434.751125   7509.383285   7321.752885   7207.494645   7169.128565   \n",
       "3     8452.595529   8533.138489   8330.731089   8207.606649   8166.285169   \n",
       "4     8906.957315   9019.087355   8831.503955   8755.490595   8678.917235   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "568   8975.849387   8855.702987   9022.927947   9227.851467   9293.639307   \n",
       "569    996.896076   1010.406156    989.872716    968.584876    949.179276   \n",
       "570   -334.542154   -470.602474   -269.871994    -75.163974     19.878806   \n",
       "571  -1268.763424  -1355.411384  -1235.729444  -1206.376324  -1190.241484   \n",
       "572  -2221.590151  -2429.286431  -2115.441271  -1872.119071  -1827.234631   \n",
       "\n",
       "     optimized_trade  revenue_normal  day_ahead_price_predictions_MLP  \\\n",
       "0           0.000000    21019.665296                       104.212471   \n",
       "1           0.000000    11373.687127                       105.951241   \n",
       "2           0.000000     9645.595935                       100.186302   \n",
       "3           0.000000    10969.810809                        99.638420   \n",
       "4           0.000000    10867.184122                        97.923981   \n",
       "..               ...             ...                              ...   \n",
       "568      1037.848672     9860.262009                       112.034363   \n",
       "569       911.956130      781.944115                       105.483566   \n",
       "570       904.664785      209.094577                       106.493591   \n",
       "571       823.025564    -1183.573987                       107.793663   \n",
       "572       681.801120    -1382.884710                       107.551636   \n",
       "\n",
       "     imbalance_price_predictions_MLP  optimized_trade_MLP  \n",
       "0                          95.558464            71.814693  \n",
       "1                          97.339027            71.515876  \n",
       "2                          91.008759            75.553457  \n",
       "3                          89.974419            79.028560  \n",
       "4                          90.149330            65.532779  \n",
       "..                               ...                  ...  \n",
       "568                       105.348930           564.752983  \n",
       "569                        98.309685           559.244751  \n",
       "570                        99.802856           551.791490  \n",
       "571                        98.813057           565.148542  \n",
       "572                        97.553589           572.414838  \n",
       "\n",
       "[573 rows x 45 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_merged2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        \n",
    "        # Zwei Hidden Layers\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # Erster Hidden Layer\n",
    "        self.fc2 = nn.Linear(128, 64)         # Zweiter Hidden Layer\n",
    "        \n",
    "        # Ausgangsschicht\n",
    "        self.fc3 = nn.Linear(64, 1)           # Ausgangsschicht\n",
    "        \n",
    "        # Dropout und Aktivierungsfunktion\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.swish = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Durch die Hidden Layers\n",
    "        x = self.swish(self.fc1(x))  # Erster Hidden Layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.swish(self.fc2(x))  # Zweiter Hidden Layer\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Ausgang\n",
    "        x = self.fc3(x)  # Ausgangsschicht\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_ahead_demand = pd.read_csv('D:/Users/paulh\\Desktop/Domäneprojekt2/Energy_production_price_prediction/day_ahead_demand_forecast.csv')\n",
    "df_margin_forecast = pd.read_csv('D:/Users/paulh\\Desktop/Domäneprojekt2/Energy_production_price_prediction/margin_forecast.csv')\n",
    "df_margin_forecast.forecast_date = pd.to_datetime(df_margin_forecast.forecast_date)\n",
    "df_day_ahead_demand.timestamp_utc = pd.to_datetime(df_day_ahead_demand.timestamp_utc)\n",
    "df_api_new_merged3 = pd.merge(df_api_new_merged2,df_day_ahead_demand, left_on='timestamp_utc', right_on='timestamp_utc', how='left')\n",
    "df_api_new_merged3[\"date\"] = df_api_new_merged3[\"timestamp_utc\"].dt.date\n",
    "df_api_new_merged3[\"date\"] = pd.to_datetime(df_api_new_merged3[\"date\"])\n",
    "df_api_new_merged3 = pd.merge(df_api_new_merged3,df_margin_forecast, left_on='date', right_on='forecast_date', how='left')\n",
    "df_api_new_merged3.dropna(inplace=True)\n",
    "df_api_new_merged3 = df_api_new_merged3.groupby(\"timestamp_utc\").last().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulh\\anaconda3\\envs\\HEFTcom24\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_17300\\3067315499.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_imbalance.load_state_dict(torch.load(\"MLP_extension_imbalance.pth\"))\n"
     ]
    }
   ],
   "source": [
    "combined_imbalance_X = df_api_new_merged3[[\"imbalance_price_predictions_MLP\", \"national_demand\", \"transmission_system_demand\", \"margin\"]]\n",
    "with open(\"scaler_LSTM_extension_imbalance.pkl\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)\n",
    "combined_imbalance_X_scaled = scaler.transform(combined_imbalance_X.values)\n",
    "combined_imbalance_X_scaled = torch.tensor(combined_imbalance_X_scaled, dtype=torch.float32)\n",
    "\n",
    "model_imbalance = SimpleModel(input_dim=4)\n",
    "model_imbalance.load_state_dict(torch.load(\"MLP_extension_imbalance.pth\"))\n",
    "model_imbalance.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_imbalance(combined_imbalance_X_scaled)\n",
    "predictions = predictions.numpy()\n",
    "df_api_new_merged3[\"imbalance_price_predictions_MLP_extension\"] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulh\\anaconda3\\envs\\HEFTcom24\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_17300\\2205174426.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_day_ahead.load_state_dict(torch.load(\"MLP_extension_day_ahead.pth\"))\n"
     ]
    }
   ],
   "source": [
    "combined_day_ahead_X = df_api_new_merged3[[\"day_ahead_price_predictions_MLP\", \"national_demand\", \"transmission_system_demand\", \"margin\"]]\n",
    "with open(\"scaler_LSTM_extension_day_ahead.pkl\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)\n",
    "combined_day_ahead_X_scaled = scaler.transform(combined_day_ahead_X.values)\n",
    "combined_day_ahead_X_scaled = torch.tensor(combined_day_ahead_X_scaled, dtype=torch.float32)\n",
    "\n",
    "model_day_ahead = SimpleModel(input_dim=4)\n",
    "model_day_ahead.load_state_dict(torch.load(\"MLP_extension_day_ahead.pth\"))\n",
    "model_day_ahead.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_day_ahead(combined_day_ahead_X_scaled)\n",
    "predictions = predictions.numpy()\n",
    "df_api_new_merged3[\"day_ahead_price_predictions_MLP_extension\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the revenue function (objective function)\n",
    "def revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return zb * DAP + (Target_MW - zb) * (imbalance_price - 0.07 * (Target_MW - zb))\n",
    "\n",
    "# Negative revenue function (for minimization)\n",
    "def negative_revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return -revenue(zb, DAP, Target_MW, imbalance_price)\n",
    "\n",
    "# Optimization function to compute the optimal bidding value for each row\n",
    "def optimize_bidding(row):\n",
    "    # Extract the values from the row\n",
    "    DAP = row['day_ahead_price_predictions_MLP_extension']\n",
    "    Target_MW = row['1']\n",
    "    imbalance_price = row['imbalance_price_predictions_MLP_extension']\n",
    "    \n",
    "    # Initial guess for zb (midpoint between 0 and Target_MW)\n",
    "    initial_zb = Target_MW / 2\n",
    "    \n",
    "    # Bounds for zb (as per KKT conditions)\n",
    "    bounds = [(0, 1800)]\n",
    "    \n",
    "    # Perform the optimization\n",
    "    result = minimize(negative_revenue, initial_zb, args=(DAP, Target_MW, imbalance_price), bounds=bounds)\n",
    "    \n",
    "    # Optimal trade value (zb)\n",
    "    return result.x[0]\n",
    "\n",
    "# Apply the optimization to each row and replace column '5' with the optimized trade value\n",
    "df_api_new_merged3['optimized_trade_MLP'] = df_api_new_merged3.apply(optimize_bidding, axis=1)\n",
    "\n",
    "# Now calculate the revenue using the optimized trade values\n",
    "df_api_new_merged3['revenue_normal'] = df_api_new_merged3['day_ahead_price'] * df_api_new_merged3['optimized_trade_MLP'] + \\\n",
    "                         (df_api_new_merged3['Total_MW'] - df_api_new_merged3['optimized_trade_MLP']) * \\\n",
    "                         (df_api_new_merged3['imbalance_price'] - 0.07 * (df_api_new_merged3['Total_MW'] - df_api_new_merged3['optimized_trade_MLP']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19337.730980682445"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_merged3.revenue_normal.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPs mit extra dmeand und margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        # Layer sizes from the best trial\n",
    "        layer_sizes = [256, 448, 192, 96]\n",
    "        dropout_rates = [0.12338360578207397, 0.2192742565593194, 0.15708417985889997, 0.253419888887539]\n",
    "\n",
    "        # Define the layers\n",
    "        self.fc1 = nn.Linear(input_dim, layer_sizes[0])\n",
    "        self.fc2 = nn.Linear(layer_sizes[0], layer_sizes[1])\n",
    "        self.fc3 = nn.Linear(layer_sizes[1], layer_sizes[2])\n",
    "        self.fc4 = nn.Linear(layer_sizes[2], layer_sizes[3])\n",
    "        self.fc5 = nn.Linear(layer_sizes[3], 1)  # Output layer\n",
    "\n",
    "        # Dropouts\n",
    "        self.dropout1 = nn.Dropout(dropout_rates[0])\n",
    "        self.dropout2 = nn.Dropout(dropout_rates[1])\n",
    "        self.dropout3 = nn.Dropout(dropout_rates[2])\n",
    "        self.dropout4 = nn.Dropout(dropout_rates[3])\n",
    "\n",
    "        # Activation function (Swish)\n",
    "        self.swish = nn.SiLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # First layer with ReLU\n",
    "        x = self.dropout1(x)         # First dropout\n",
    "        x = self.swish(self.fc2(x))  # Second layer with Swish\n",
    "        x = self.dropout2(x)         # Second dropout\n",
    "        x = self.swish(self.fc3(x))  # Third layer with Swish\n",
    "        x = self.dropout3(x)         # Third dropout\n",
    "        x = self.swish(self.fc4(x))  # Fourth layer with Swish\n",
    "        x = self.dropout4(x)         # Fourth dropout\n",
    "        x = self.fc5(x)              # Output layer (no activation for raw outputs)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulh\\anaconda3\\envs\\HEFTcom24\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "df_api_new_merged2_X = df_api_new_merged2[[\"market_price_lag96h\",\"imbalance_price_lag96h\",\"day_ahead_price_lag1week\",\"volume_lag96h\",\n",
    "                    \"cos_hour\",\"cos_day\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]].copy()\n",
    "\n",
    "scaler_path = \"LSTM_imbalance_scaler.pkl\"\n",
    "# Laden des StandardScalers aus der Datei\n",
    "with open(scaler_path, 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "# Skalieren der Daten\n",
    "df_api_new_merged2_X_scaled = scaler.transform(df_api_new_merged2_X)\n",
    "\n",
    "# Konvertieren der Daten in PyTorch-Tensoren\n",
    "X_test = torch.tensor(df_api_new_merged2_X_scaled, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp_utc', 'market_price', 'day_ahead_price', 'volume',\n",
       "       'settlement_period_x', 'cos_hour', 'cos_day', '1', '2', '3', '4', '5',\n",
       "       '6', '7', '8', '9', 'imbalance_price', 'market_price_lag96h',\n",
       "       'imbalance_price_lag96h', 'day_ahead_price_lag1week', 'volume_lag96h',\n",
       "       'generation_solar', 'installed_capacity_mwp', 'capacity_mwp',\n",
       "       'settlement_date', 'settlement_period_y', 'boa', 'generation_wind',\n",
       "       'imvalance_price_predictions', 'day_ahead_price_predictions',\n",
       "       'Total_MW', 'Revenue_40', 'Revenue_30', 'Revenue_20', 'Revenue_10',\n",
       "       'Revenue_60', 'Revenue_50', 'Revenue_70', 'Revenue_80', 'Revenue_90',\n",
       "       'optimized_trade', 'revenue_normal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_merged2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_17300\\1782585997.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_imbalance_mlp.load_state_dict(torch.load(\"MLP_day_ahead_price.pth\"))\n"
     ]
    }
   ],
   "source": [
    "model_imbalance_mlp = MLP(input_dim=15)\n",
    "model_imbalance_mlp.load_state_dict(torch.load(\"MLP_day_ahead_price.pth\"))\n",
    "model_imbalance_mlp.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_imbalance_mlp(X_test)\n",
    "predictions = predictions.numpy()\n",
    "df_api_new_merged2[\"day_ahead_price_predictions_MLP\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_17300\\360064670.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_day_ahead_price.load_state_dict(torch.load(\"MLP_imbalance_price.pth\"))\n"
     ]
    }
   ],
   "source": [
    "model_day_ahead_price = MLP(input_dim=15)\n",
    "model_day_ahead_price.load_state_dict(torch.load(\"MLP_imbalance_price.pth\"))\n",
    "model_day_ahead_price.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_day_ahead_price(X_test)\n",
    "predictions = predictions.numpy()\n",
    "df_api_new_merged2[\"imbalance_price_predictions_MLP\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the revenue function (objective function)\n",
    "def revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return zb * DAP + (Target_MW - zb) * (imbalance_price - 0.07 * (Target_MW - zb))\n",
    "\n",
    "# Negative revenue function (for minimization)\n",
    "def negative_revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return -revenue(zb, DAP, Target_MW, imbalance_price)\n",
    "\n",
    "# Optimization function to compute the optimal bidding value for each row\n",
    "def optimize_bidding(row):\n",
    "    # Extract the values from the row\n",
    "    DAP = row['day_ahead_price_predictions_MLP']\n",
    "    Target_MW = row['5']\n",
    "    imbalance_price = row['imbalance_price_predictions_MLP']\n",
    "    \n",
    "    # Initial guess for zb (midpoint between 0 and Target_MW)\n",
    "    initial_zb = Target_MW / 2\n",
    "    \n",
    "    # Bounds for zb (as per KKT conditions)\n",
    "    bounds = [(0, 1800)]\n",
    "    \n",
    "    # Perform the optimization\n",
    "    result = minimize(negative_revenue, initial_zb, args=(DAP, Target_MW, imbalance_price), bounds=bounds)\n",
    "    \n",
    "    # Optimal trade value (zb)\n",
    "    return result.x[0]\n",
    "\n",
    "# Apply the optimization to each row and replace column '5' with the optimized trade value\n",
    "df_api_new_merged2['optimized_trade_MLP'] = df_api_new_merged2.apply(optimize_bidding, axis=1)\n",
    "\n",
    "# Now calculate the revenue using the optimized trade values\n",
    "df_api_new_merged2['revenue_normal'] = df_api_new_merged2['day_ahead_price'] * df_api_new_merged2['optimized_trade_MLP'] + \\\n",
    "                         (df_api_new_merged2['Total_MW'] - df_api_new_merged2['optimized_trade_MLP']) * \\\n",
    "                         (df_api_new_merged2['imbalance_price'] - 0.07 * (df_api_new_merged2['Total_MW'] - df_api_new_merged2['optimized_trade_MLP']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14837.89604976067"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_merged2.revenue_normal.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        \n",
    "        # Zwei Hidden Layers\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # Erster Hidden Layer\n",
    "        self.fc2 = nn.Linear(128, 64)         # Zweiter Hidden Layer\n",
    "        \n",
    "        # Ausgangsschicht\n",
    "        self.fc3 = nn.Linear(64, 1)           # Ausgangsschicht\n",
    "        \n",
    "        # Dropout und Aktivierungsfunktion\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.swish = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Durch die Hidden Layers\n",
    "        x = self.swish(self.fc1(x))  # Erster Hidden Layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.swish(self.fc2(x))  # Zweiter Hidden Layer\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Ausgang\n",
    "        x = self.fc3(x)  # Ausgangsschicht\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_ahead_demand = pd.read_csv('D:/Users/paulh\\Desktop/Domäneprojekt2/Energy_production_price_prediction/day_ahead_demand_forecast.csv')\n",
    "df_margin_forecast = pd.read_csv('D:/Users/paulh\\Desktop/Domäneprojekt2/Energy_production_price_prediction/margin_forecast.csv')\n",
    "df_margin_forecast.forecast_date = pd.to_datetime(df_margin_forecast.forecast_date)\n",
    "df_day_ahead_demand.timestamp_utc = pd.to_datetime(df_day_ahead_demand.timestamp_utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_new_merged3 = pd.merge(df_api_new_merged2,df_day_ahead_demand, left_on='timestamp_utc', right_on='timestamp_utc', how='left')\n",
    "df_api_new_merged3[\"date\"] = df_api_new_merged3[\"timestamp_utc\"].dt.date\n",
    "df_api_new_merged3[\"date\"] = pd.to_datetime(df_api_new_merged3[\"date\"])\n",
    "df_api_new_merged3 = pd.merge(df_api_new_merged3,df_margin_forecast, left_on='date', right_on='forecast_date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_new_merged3.dropna(inplace=True)\n",
    "df_api_new_merged3 = df_api_new_merged3.groupby(\"timestamp_utc\").last().reset_index()\n",
    "df_api_new_merged3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulh\\anaconda3\\envs\\HEFTcom24\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_17300\\2423680995.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_imbalance.load_state_dict(torch.load(\"MLP_extension_imbalance.pth\"))\n"
     ]
    }
   ],
   "source": [
    "combined_imbalance_X = df_api_new_merged3[[\"imbalance_price_predictions_MLP\", \"national_demand\", \"transmission_system_demand\", \"margin\"]]\n",
    "with open(\"scaler_MLP_extension_imbalance.pkl\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)\n",
    "combined_imbalance_X_scaled = scaler.transform(combined_imbalance_X.values)\n",
    "combined_imbalance_X_scaled = torch.tensor(combined_imbalance_X_scaled, dtype=torch.float32)\n",
    "\n",
    "model_imbalance = SimpleModel(input_dim=4)\n",
    "model_imbalance.load_state_dict(torch.load(\"MLP_extension_imbalance.pth\"))\n",
    "model_imbalance.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_imbalance(combined_imbalance_X_scaled)\n",
    "predictions = predictions.numpy()\n",
    "df_api_new_merged3[\"imbalance_price_predictions_MLP_extension\"] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulh\\anaconda3\\envs\\HEFTcom24\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_17300\\952351878.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_day_ahead.load_state_dict(torch.load(\"MLP_extension_day_ahead.pth\"))\n"
     ]
    }
   ],
   "source": [
    "combined_day_ahead_X = df_api_new_merged3[[\"day_ahead_price_predictions_MLP\", \"national_demand\", \"transmission_system_demand\", \"margin\"]]\n",
    "with open(\"scaler_MLP_extension_day_ahead.pkl\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)\n",
    "combined_day_ahead_X_scaled = scaler.transform(combined_day_ahead_X.values)\n",
    "combined_day_ahead_X_scaled = torch.tensor(combined_day_ahead_X_scaled, dtype=torch.float32)\n",
    "\n",
    "model_day_ahead = SimpleModel(input_dim=4)\n",
    "model_day_ahead.load_state_dict(torch.load(\"MLP_extension_day_ahead.pth\"))\n",
    "model_day_ahead.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_day_ahead(combined_day_ahead_X_scaled)\n",
    "predictions = predictions.numpy()\n",
    "df_api_new_merged3[\"day_ahead_price_predictions_MLP_extension\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the revenue function (objective function)\n",
    "def revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return zb * DAP + (Target_MW - zb) * (imbalance_price - 0.07 * (Target_MW - zb))\n",
    "\n",
    "# Negative revenue function (for minimization)\n",
    "def negative_revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return -revenue(zb, DAP, Target_MW, imbalance_price)\n",
    "\n",
    "# Optimization function to compute the optimal bidding value for each row\n",
    "def optimize_bidding(row):\n",
    "    # Extract the values from the row\n",
    "    DAP = row['day_ahead_price_predictions_MLP_extension']\n",
    "    Target_MW = row['1']\n",
    "    imbalance_price = row['imbalance_price_predictions_MLP_extension']\n",
    "    \n",
    "    # Initial guess for zb (midpoint between 0 and Target_MW)\n",
    "    initial_zb = Target_MW / 2\n",
    "    \n",
    "    # Bounds for zb (as per KKT conditions)\n",
    "    bounds = [(0, 1800)]\n",
    "    \n",
    "    # Perform the optimization\n",
    "    result = minimize(negative_revenue, initial_zb, args=(DAP, Target_MW, imbalance_price), bounds=bounds)\n",
    "    \n",
    "    # Optimal trade value (zb)\n",
    "    return result.x[0]\n",
    "\n",
    "# Apply the optimization to each row and replace column '5' with the optimized trade value\n",
    "df_api_new_merged3['optimized_trade_MLP'] = df_api_new_merged3.apply(optimize_bidding, axis=1)\n",
    "\n",
    "# Now calculate the revenue using the optimized trade values\n",
    "df_api_new_merged3['revenue_normal'] = df_api_new_merged3['day_ahead_price'] * df_api_new_merged3['optimized_trade_MLP'] + \\\n",
    "                         (df_api_new_merged3['Total_MW'] - df_api_new_merged3['optimized_trade_MLP']) * \\\n",
    "                         (df_api_new_merged3['imbalance_price'] - 0.07 * (df_api_new_merged3['Total_MW'] - df_api_new_merged3['optimized_trade_MLP']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21175.863774534082"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_merged3.revenue_normal.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp_utc', 'market_price', 'day_ahead_price', 'volume',\n",
       "       'settlement_period_x', 'cos_hour', 'cos_day', '1', '2', '3', '4', '5',\n",
       "       '6', '7', '8', '9', 'imbalance_price', 'market_price_lag96h',\n",
       "       'imbalance_price_lag96h', 'day_ahead_price_lag1week', 'volume_lag96h',\n",
       "       'generation_solar', 'installed_capacity_mwp', 'capacity_mwp',\n",
       "       'settlement_date_x', 'settlement_period_y', 'boa', 'generation_wind',\n",
       "       'imvalance_price_predictions', 'day_ahead_price_predictions',\n",
       "       'Total_MW', 'Revenue_40', 'Revenue_30', 'Revenue_20', 'Revenue_10',\n",
       "       'Revenue_60', 'Revenue_50', 'Revenue_70', 'Revenue_80', 'Revenue_90',\n",
       "       'optimized_trade', 'revenue_normal', 'day_ahead_price_predictions_MLP',\n",
       "       'imbalance_price_predictions_MLP', 'optimized_trade_MLP',\n",
       "       'settlement_date_y', 'settlement_period', 'boundary',\n",
       "       'publish_time_utc_x', 'transmission_system_demand', 'national_demand',\n",
       "       'date', 'forecast_date', 'publish_time_utc_y', 'margin',\n",
       "       'imbalance_price_predictions_MLP_extension',\n",
       "       'day_ahead_price_predictions_MLP_extension'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_merged3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## newer LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMPredictor1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.1):\n",
    "        super(LSTMPredictor1, self).__init__()\n",
    "        \n",
    "        # Parameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define the LSTM layer(s)\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, \n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.dropout)\n",
    "        \n",
    "        # Fully connected layer to map LSTM output to the target size\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states for LSTM\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  # Hidden state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  # Cell state\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # We only need the output\n",
    "        \n",
    "        # Get the last output (many-to-one), out[:, -1, :] gives the last time step\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Pass the output through a fully connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imbalance = df_api_new_merged2.dropna()[[\"imbalance_price\"]].dropna().values\n",
    "# X_imbalance = X_imbalance[384:]\n",
    "\n",
    "# # Define the sequence length\n",
    "# sequence_length = 192\n",
    "\n",
    "# # Function to create sequences from just X (no need for y)\n",
    "# def create_sequences_from_X(X, sequence_length):\n",
    "#     sequences = []\n",
    "#     for i in range(len(X) - sequence_length):\n",
    "#         # Create a sequence of the desired length\n",
    "#         seq = X[i:i + sequence_length]\n",
    "#         sequences.append(seq)\n",
    "#     return np.array(sequences)\n",
    "\n",
    "# # Create sequences from X\n",
    "# X_imbalance = create_sequences_from_X(X_imbalance, sequence_length)\n",
    "\n",
    "# # Output the shape of the resulting sequences\n",
    "# print(\"X_seq shape:\", X_imbalance.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_day_ahead = df_api_new_merged2.dropna()[[\"day_ahead_price\"]].dropna().values\n",
    "# X_day_ahead = X_day_ahead[384:]\n",
    "\n",
    "# Define the sequence length\n",
    "# sequence_length = 192\n",
    "\n",
    "# # Function to create sequences from just X (no need for y)\n",
    "# def create_sequences_from_X(X, sequence_length):\n",
    "#     sequences = []\n",
    "#     for i in range(len(X) - sequence_length):\n",
    "#         # Create a sequence of the desired length\n",
    "#         seq = X[i:i + sequence_length]\n",
    "#         sequences.append(seq)\n",
    "#     return np.array(sequences)\n",
    "\n",
    "# # Create sequences from X\n",
    "# X_day_ahead = create_sequences_from_X(X_day_ahead, sequence_length)\n",
    "\n",
    "# # Output the shape of the resulting sequences\n",
    "# print(\"X_seq shape:\", X_day_ahead.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_day_ahead.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_11040\\339041631.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_day_ahead_price.load_state_dict(torch.load(\"LSTM_day_ahead_price_only_1Feature.pth\"))\n"
     ]
    }
   ],
   "source": [
    "model_day_ahead_price = LSTMPredictor1(input_size=1, hidden_size=64, num_layers=3, output_size=1, dropout=0.1)\n",
    "model_day_ahead_price.load_state_dict(torch.load(\"LSTM_day_ahead_price_only_1Feature.pth\"))\n",
    "model_day_ahead_price.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_day_ahead_price(torch.tensor(X_day_ahead, dtype=torch.float32).unsqueeze(2))\n",
    "predictions_dayahead = predictions.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([381, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api2 = df_api_new_merged2.dropna().copy()\n",
    "df_api2[\"day_ahead_price_predictions_LSTM\"] = predictions_dayahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_11040\\1974065888.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_imbalance_price.load_state_dict(torch.load(\"LSTM_imbalance_price_only_1Feature.pth\"))\n"
     ]
    }
   ],
   "source": [
    "model_imbalance_price = LSTMPredictor1(input_size=1, hidden_size=64, num_layers=3, output_size=1, dropout=0.1)\n",
    "model_imbalance_price.load_state_dict(torch.load(\"LSTM_imbalance_price_only_1Feature.pth\"))\n",
    "model_imbalance_price.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_imbalance_price(torch.tensor(X_imbalance, dtype=torch.float32).unsqueeze(2))\n",
    "predictions_imbalance = predictions.numpy()\n",
    "\n",
    "df_api2[\"imbalance_price_predictions_LSTM\"] = predictions_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the revenue function (objective function)\n",
    "def revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return zb * DAP + (Target_MW - zb) * (imbalance_price - 0.07 * (Target_MW - zb))\n",
    "\n",
    "# Negative revenue function (for minimization)\n",
    "def negative_revenue(zb, DAP, Target_MW, imbalance_price):\n",
    "    return -revenue(zb, DAP, Target_MW, imbalance_price)\n",
    "\n",
    "# Optimization function to compute the optimal bidding value for each row\n",
    "def optimize_bidding(row):\n",
    "    # Extract the values from the row\n",
    "    DAP = row['day_ahead_price_predictions_LSTM']\n",
    "    Target_MW = row['5']\n",
    "    imbalance_price = row['imbalance_price_predictions_LSTM']\n",
    "    \n",
    "    # Initial guess for zb (midpoint between 0 and Target_MW)\n",
    "    initial_zb = Target_MW / 2\n",
    "    \n",
    "    # Bounds for zb (as per KKT conditions)\n",
    "    bounds = [(0, 1800)]\n",
    "    \n",
    "    # Perform the optimization\n",
    "    result = minimize(negative_revenue, initial_zb, args=(DAP, Target_MW, imbalance_price), bounds=bounds)\n",
    "    \n",
    "    # Optimal trade value (zb)\n",
    "    return result.x[0]\n",
    "\n",
    "# Apply the optimization to each row and replace column '5' with the optimized trade value\n",
    "df_api2['optimized_trade_MLP'] = df_api2.apply(optimize_bidding, axis=1)\n",
    "\n",
    "# Now calculate the revenue using the optimized trade values\n",
    "df_api2['revenue_normal'] = df_api2['day_ahead_price'] * df_api2['optimized_trade_MLP'] + \\\n",
    "                         (df_api2['Total_MW'] - df_api2['optimized_trade_MLP']) * \\\n",
    "                         (df_api2['imbalance_price'] - 0.07 * (df_api2['Total_MW'] - df_api2['optimized_trade_MLP']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12449.748795248075"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api2.revenue_normal.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HEFTcom24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
