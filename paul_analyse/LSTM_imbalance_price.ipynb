{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timestamp_utc',\n",
       " 'Mean_SolarRadiation_dwd',\n",
       " 'SolarDownwardRadiation_RW_dwd_Mean_30min',\n",
       " 'SolarDownwardRadiation_RW_dwd_Mean_1h',\n",
       " 'SolarDownwardRadiation_dwd_Mean_Lag_30min',\n",
       " 'SolarDownwardRadiation_dwd_Mean_Lag_1h',\n",
       " 'SolarDownwardRadiation_dwd_Mean_Lag_24h',\n",
       " 'Panel_Efficiency_dwd_mean',\n",
       " 'Panel_Efficiency_dwd_std',\n",
       " 'Panel_Temperature_dwd_mean',\n",
       " 'Panel_Temperature_dwd_std',\n",
       " 'Std_Temperature_dwd',\n",
       " 'Mean_Temperature_dwd',\n",
       " 'cos_hour',\n",
       " 'cos_day',\n",
       " 'solar_mw_lag_48h',\n",
       " 'capacity_mwp_lag_48h',\n",
       " 'Target_Capacity_MWP%_lag_48h',\n",
       " 'Target_Capacity_MWP%',\n",
       " 'Solar_MWh_credit',\n",
       " 'reference_time',\n",
       " 'valid_time',\n",
       " 'RelativeHumidity_dwd',\n",
       " 'Temperature_dwd',\n",
       " 'WindDirection_dwd',\n",
       " 'WindDirection:100_dwd',\n",
       " 'WindSpeed^3_dwd',\n",
       " 'WindSpeed:100^3_dwd',\n",
       " 'WindSpeed_dwd',\n",
       " 'WindSpeed:100_dwd',\n",
       " 'WindSpeed^3:100_dwd',\n",
       " 'RelativeHumidity_ncep',\n",
       " 'Temperature_ncep',\n",
       " 'WindDirection_ncep',\n",
       " 'WindDirection:100_ncep',\n",
       " 'WindSpeed^3_ncep',\n",
       " 'WindSpeed:100^3_ncep',\n",
       " 'WindSpeed_ncep',\n",
       " 'WindSpeed:100_ncep',\n",
       " 'WindSpeed^3:100_ncep',\n",
       " 'dtm',\n",
       " 'MIP',\n",
       " 'Wind_MW',\n",
       " 'SS_Price',\n",
       " 'boa_MWh',\n",
       " 'DA_Price',\n",
       " 'Wind_MWh_credit',\n",
       " 'Target_MW',\n",
       " '9',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " 'Temperature',\n",
       " 'Temperature_K',\n",
       " 'RelativeHumidity',\n",
       " 'AirDensity',\n",
       " 'WindSpeed',\n",
       " 'WindSpeed:100',\n",
       " 'WindSpeed_full_avg',\n",
       " 'WindPower_full',\n",
       " 'UsableWindPower_full',\n",
       " 'PowerOutput_full',\n",
       " 'Temperature_avg',\n",
       " 'RelativeHumidity_avg',\n",
       " 'WindSpeed:100_dwd_lag1',\n",
       " 'WindSpeed:100_dwd_lag2',\n",
       " 'WindSpeed:100_dwd_lag3',\n",
       " 'UsableWindPower_opt',\n",
       " 'settlement_date_x',\n",
       " 'settlement_period_x',\n",
       " 'price_x',\n",
       " 'settlement_date_y',\n",
       " 'settlement_period_y',\n",
       " 'imbalance_price',\n",
       " 'settlement_date',\n",
       " 'settlement_period',\n",
       " 'data_provider',\n",
       " 'price_y',\n",
       " 'volume',\n",
       " 'day_ahead_price',\n",
       " 'market_price']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbidding = pd.read_csv('bidding_training.csv')\n",
    "df_bbidding[\"day_ahead_price\"] = df_bbidding[\"price_x\"].rename(\"day_ahead_price\")\n",
    "df_bbidding[\"market_price\"] = df_bbidding[\"price_y\"].rename(\"market_price\")\n",
    "df_bbidding.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>market_price</th>\n",
       "      <th>day_ahead_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>settlement_period</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>imbalance_price</th>\n",
       "      <th>market_price_lag96h</th>\n",
       "      <th>imbalance_price_lag96h</th>\n",
       "      <th>day_ahead_price_lag1week</th>\n",
       "      <th>volume_lag96h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2021-03-04 08:00:00+00:00</td>\n",
       "      <td>68.55</td>\n",
       "      <td>73.77</td>\n",
       "      <td>1201.25</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.467359</td>\n",
       "      <td>106.202828</td>\n",
       "      <td>126.692556</td>\n",
       "      <td>188.827864</td>\n",
       "      <td>...</td>\n",
       "      <td>248.421344</td>\n",
       "      <td>278.463233</td>\n",
       "      <td>323.809394</td>\n",
       "      <td>373.852140</td>\n",
       "      <td>463.068992</td>\n",
       "      <td>89.95</td>\n",
       "      <td>7.54</td>\n",
       "      <td>8.00</td>\n",
       "      <td>32.38</td>\n",
       "      <td>755.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2021-03-04 08:30:00+00:00</td>\n",
       "      <td>69.25</td>\n",
       "      <td>73.77</td>\n",
       "      <td>1105.35</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.467359</td>\n",
       "      <td>109.169687</td>\n",
       "      <td>146.438753</td>\n",
       "      <td>203.691171</td>\n",
       "      <td>...</td>\n",
       "      <td>237.873544</td>\n",
       "      <td>290.936786</td>\n",
       "      <td>336.975817</td>\n",
       "      <td>382.262617</td>\n",
       "      <td>516.284064</td>\n",
       "      <td>89.00</td>\n",
       "      <td>-9.71</td>\n",
       "      <td>7.00</td>\n",
       "      <td>32.38</td>\n",
       "      <td>900.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2021-03-04 09:00:00+00:00</td>\n",
       "      <td>75.18</td>\n",
       "      <td>70.86</td>\n",
       "      <td>1245.05</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.467359</td>\n",
       "      <td>85.628752</td>\n",
       "      <td>156.903984</td>\n",
       "      <td>199.220095</td>\n",
       "      <td>...</td>\n",
       "      <td>238.966779</td>\n",
       "      <td>300.425701</td>\n",
       "      <td>345.177645</td>\n",
       "      <td>375.303556</td>\n",
       "      <td>488.195210</td>\n",
       "      <td>92.00</td>\n",
       "      <td>55.58</td>\n",
       "      <td>33.65</td>\n",
       "      <td>17.34</td>\n",
       "      <td>497.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2021-03-04 09:30:00+00:00</td>\n",
       "      <td>73.19</td>\n",
       "      <td>70.86</td>\n",
       "      <td>1590.00</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.467359</td>\n",
       "      <td>89.618646</td>\n",
       "      <td>163.000319</td>\n",
       "      <td>205.983800</td>\n",
       "      <td>...</td>\n",
       "      <td>263.775945</td>\n",
       "      <td>307.808096</td>\n",
       "      <td>356.190088</td>\n",
       "      <td>404.786859</td>\n",
       "      <td>445.870108</td>\n",
       "      <td>92.00</td>\n",
       "      <td>57.95</td>\n",
       "      <td>62.70</td>\n",
       "      <td>17.34</td>\n",
       "      <td>554.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2021-03-04 10:00:00+00:00</td>\n",
       "      <td>74.12</td>\n",
       "      <td>63.72</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.467359</td>\n",
       "      <td>140.104118</td>\n",
       "      <td>259.247292</td>\n",
       "      <td>313.074122</td>\n",
       "      <td>...</td>\n",
       "      <td>350.917349</td>\n",
       "      <td>469.297198</td>\n",
       "      <td>491.961995</td>\n",
       "      <td>584.346472</td>\n",
       "      <td>624.029818</td>\n",
       "      <td>98.00</td>\n",
       "      <td>53.11</td>\n",
       "      <td>34.10</td>\n",
       "      <td>14.25</td>\n",
       "      <td>739.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42280</th>\n",
       "      <td>2023-08-25 23:30:00+00:00</td>\n",
       "      <td>83.91</td>\n",
       "      <td>84.41</td>\n",
       "      <td>1201.85</td>\n",
       "      <td>2</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.591261</td>\n",
       "      <td>28.044030</td>\n",
       "      <td>85.584636</td>\n",
       "      <td>147.450968</td>\n",
       "      <td>...</td>\n",
       "      <td>257.545157</td>\n",
       "      <td>312.000836</td>\n",
       "      <td>389.209655</td>\n",
       "      <td>461.471346</td>\n",
       "      <td>565.748439</td>\n",
       "      <td>66.01</td>\n",
       "      <td>91.88</td>\n",
       "      <td>126.00</td>\n",
       "      <td>50.21</td>\n",
       "      <td>1271.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42281</th>\n",
       "      <td>2023-08-26 00:00:00+00:00</td>\n",
       "      <td>82.13</td>\n",
       "      <td>79.96</td>\n",
       "      <td>1066.95</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.577292</td>\n",
       "      <td>-2.130944</td>\n",
       "      <td>44.062739</td>\n",
       "      <td>80.500728</td>\n",
       "      <td>...</td>\n",
       "      <td>152.946134</td>\n",
       "      <td>213.340381</td>\n",
       "      <td>285.856261</td>\n",
       "      <td>352.111989</td>\n",
       "      <td>494.824570</td>\n",
       "      <td>66.01</td>\n",
       "      <td>90.64</td>\n",
       "      <td>90.64</td>\n",
       "      <td>37.82</td>\n",
       "      <td>1643.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42282</th>\n",
       "      <td>2023-08-26 00:30:00+00:00</td>\n",
       "      <td>78.76</td>\n",
       "      <td>79.96</td>\n",
       "      <td>997.60</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.577292</td>\n",
       "      <td>-53.850807</td>\n",
       "      <td>-31.030380</td>\n",
       "      <td>1.674412</td>\n",
       "      <td>...</td>\n",
       "      <td>80.555516</td>\n",
       "      <td>138.624007</td>\n",
       "      <td>177.132223</td>\n",
       "      <td>250.514362</td>\n",
       "      <td>333.223882</td>\n",
       "      <td>66.01</td>\n",
       "      <td>95.15</td>\n",
       "      <td>115.99</td>\n",
       "      <td>37.82</td>\n",
       "      <td>1599.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42283</th>\n",
       "      <td>2023-08-26 01:00:00+00:00</td>\n",
       "      <td>77.47</td>\n",
       "      <td>73.84</td>\n",
       "      <td>913.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.577292</td>\n",
       "      <td>-42.706652</td>\n",
       "      <td>-38.988480</td>\n",
       "      <td>19.495393</td>\n",
       "      <td>...</td>\n",
       "      <td>72.199724</td>\n",
       "      <td>128.661011</td>\n",
       "      <td>157.102188</td>\n",
       "      <td>214.652927</td>\n",
       "      <td>345.416021</td>\n",
       "      <td>66.01</td>\n",
       "      <td>91.30</td>\n",
       "      <td>125.00</td>\n",
       "      <td>31.66</td>\n",
       "      <td>1619.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42284</th>\n",
       "      <td>2023-08-26 01:30:00+00:00</td>\n",
       "      <td>77.86</td>\n",
       "      <td>73.84</td>\n",
       "      <td>954.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.577292</td>\n",
       "      <td>-46.142542</td>\n",
       "      <td>-16.541504</td>\n",
       "      <td>24.898802</td>\n",
       "      <td>...</td>\n",
       "      <td>82.390712</td>\n",
       "      <td>129.822254</td>\n",
       "      <td>156.779314</td>\n",
       "      <td>205.090697</td>\n",
       "      <td>301.330725</td>\n",
       "      <td>66.01</td>\n",
       "      <td>101.04</td>\n",
       "      <td>124.11</td>\n",
       "      <td>31.66</td>\n",
       "      <td>1895.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41949 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp_utc  market_price  day_ahead_price   volume  \\\n",
       "336    2021-03-04 08:00:00+00:00         68.55            73.77  1201.25   \n",
       "337    2021-03-04 08:30:00+00:00         69.25            73.77  1105.35   \n",
       "338    2021-03-04 09:00:00+00:00         75.18            70.86  1245.05   \n",
       "339    2021-03-04 09:30:00+00:00         73.19            70.86  1590.00   \n",
       "340    2021-03-04 10:00:00+00:00         74.12            63.72  1415.30   \n",
       "...                          ...           ...              ...      ...   \n",
       "42280  2023-08-25 23:30:00+00:00         83.91            84.41  1201.85   \n",
       "42281  2023-08-26 00:00:00+00:00         82.13            79.96  1066.95   \n",
       "42282  2023-08-26 00:30:00+00:00         78.76            79.96   997.60   \n",
       "42283  2023-08-26 01:00:00+00:00         77.47            73.84   913.25   \n",
       "42284  2023-08-26 01:30:00+00:00         77.86            73.84   954.00   \n",
       "\n",
       "       settlement_period  cos_hour   cos_day           1           2  \\\n",
       "336                   17 -0.500000  0.467359  106.202828  126.692556   \n",
       "337                   18 -0.500000  0.467359  109.169687  146.438753   \n",
       "338                   19 -0.707107  0.467359   85.628752  156.903984   \n",
       "339                   20 -0.707107  0.467359   89.618646  163.000319   \n",
       "340                   21 -0.866025  0.467359  140.104118  259.247292   \n",
       "...                  ...       ...       ...         ...         ...   \n",
       "42280                  2  0.965926 -0.591261   28.044030   85.584636   \n",
       "42281                  3  1.000000 -0.577292   -2.130944   44.062739   \n",
       "42282                  4  1.000000 -0.577292  -53.850807  -31.030380   \n",
       "42283                  5  0.965926 -0.577292  -42.706652  -38.988480   \n",
       "42284                  6  0.965926 -0.577292  -46.142542  -16.541504   \n",
       "\n",
       "                3  ...           5           6           7           8  \\\n",
       "336    188.827864  ...  248.421344  278.463233  323.809394  373.852140   \n",
       "337    203.691171  ...  237.873544  290.936786  336.975817  382.262617   \n",
       "338    199.220095  ...  238.966779  300.425701  345.177645  375.303556   \n",
       "339    205.983800  ...  263.775945  307.808096  356.190088  404.786859   \n",
       "340    313.074122  ...  350.917349  469.297198  491.961995  584.346472   \n",
       "...           ...  ...         ...         ...         ...         ...   \n",
       "42280  147.450968  ...  257.545157  312.000836  389.209655  461.471346   \n",
       "42281   80.500728  ...  152.946134  213.340381  285.856261  352.111989   \n",
       "42282    1.674412  ...   80.555516  138.624007  177.132223  250.514362   \n",
       "42283   19.495393  ...   72.199724  128.661011  157.102188  214.652927   \n",
       "42284   24.898802  ...   82.390712  129.822254  156.779314  205.090697   \n",
       "\n",
       "                9  imbalance_price  market_price_lag96h  \\\n",
       "336    463.068992            89.95                 7.54   \n",
       "337    516.284064            89.00                -9.71   \n",
       "338    488.195210            92.00                55.58   \n",
       "339    445.870108            92.00                57.95   \n",
       "340    624.029818            98.00                53.11   \n",
       "...           ...              ...                  ...   \n",
       "42280  565.748439            66.01                91.88   \n",
       "42281  494.824570            66.01                90.64   \n",
       "42282  333.223882            66.01                95.15   \n",
       "42283  345.416021            66.01                91.30   \n",
       "42284  301.330725            66.01               101.04   \n",
       "\n",
       "       imbalance_price_lag96h  day_ahead_price_lag1week  volume_lag96h  \n",
       "336                      8.00                     32.38         755.80  \n",
       "337                      7.00                     32.38         900.35  \n",
       "338                     33.65                     17.34         497.60  \n",
       "339                     62.70                     17.34         554.50  \n",
       "340                     34.10                     14.25         739.95  \n",
       "...                       ...                       ...            ...  \n",
       "42280                  126.00                     50.21        1271.20  \n",
       "42281                   90.64                     37.82        1643.15  \n",
       "42282                  115.99                     37.82        1599.25  \n",
       "42283                  125.00                     31.66        1619.70  \n",
       "42284                  124.11                     31.66        1895.15  \n",
       "\n",
       "[41949 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbidding1 = df_bbidding[[\"timestamp_utc\",\"market_price\",\"day_ahead_price\",\"volume\",\"settlement_period\",\"cos_hour\",\"cos_day\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"imbalance_price\"]].copy()\n",
    "df_bbidding1.loc[:,\"market_price_lag96h\"] = df_bbidding1[\"market_price\"].shift(192)\n",
    "df_bbidding1.loc[:,\"imbalance_price_lag96h\"] = df_bbidding1[\"imbalance_price\"].shift(192)\n",
    "df_bbidding1.loc[:,\"day_ahead_price_lag1week\"] = df_bbidding1[\"day_ahead_price\"].shift(336)\n",
    "df_bbidding1.loc[:,\"volume_lag96h\"] = df_bbidding1[\"volume\"].shift(192)\n",
    "df_bbidding1.dropna(inplace=True)\n",
    "df_bbidding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset\n",
    "X = df_bbidding1[[\"market_price_lag96h\",\"imbalance_price_lag96h\",\"day_ahead_price_lag1week\",\"volume_lag96h\",\n",
    "                  \"cos_hour\",\"cos_day\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]].values\n",
    "y = df_bbidding1[\"imbalance_price\"].values  # Convert to numpy\n",
    "\n",
    "# Step 1: Split into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Step 2: Further split the training set into train and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Step 3: Standardize the data (use only training data to fit the scaler)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "#save the scaler\n",
    "pickle.dump(scaler, open(\"LSTM_imbalance_scaler.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.1):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        \n",
    "        # Parameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define the LSTM layer(s)\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, \n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.dropout)\n",
    "        \n",
    "        # Fully connected layer to map LSTM output to the target size\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states for LSTM\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  # Hidden state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  # Cell state\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # We only need the output\n",
    "        \n",
    "        # Get the last output (many-to-one), out[:, -1, :] gives the last time step\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # Pass the output through a fully connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.values\n",
    "# y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Step 4: Create TensorDataset and DataLoader for training, validation, and testing\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = X_train.shape[1]  # Number of features\n",
    "hidden_size = 64              # Number of LSTM units\n",
    "num_layers = 3                 # Number of LSTM layers\n",
    "output_size = 1                # Always 9 for 9 quantiles\n",
    "dropout = 0.1                  # Dropout rate\n",
    "learning_rate = 0.0001         # Learning rate for optimizer\n",
    "batch_size = 32                # Batch size\n",
    "num_epochs = 500               # Maximum number of epochs\n",
    "patience = 15                  # Patience for early stopping\n",
    "rel_improvement_threshold = 0.0001  # Relative improvement threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMPredictor(input_size, hidden_size, num_layers, output_size, dropout)\n",
    "\n",
    "# Loss function and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "patience_counter = 0\n",
    "previous_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 161.6005\n",
      "Epoch [1/500], Validation Loss: 149.7111\n",
      "Best model saved with validation loss: 149.7111\n",
      "Epoch [2/500], Training Loss: 152.9179\n",
      "Epoch [2/500], Validation Loss: 144.7974\n",
      "Best model saved with validation loss: 144.7974\n",
      "Epoch [3/500], Training Loss: 148.3845\n",
      "Epoch [3/500], Validation Loss: 141.0752\n",
      "Best model saved with validation loss: 141.0752\n",
      "Epoch [4/500], Training Loss: 144.4170\n",
      "Epoch [4/500], Validation Loss: 137.6364\n",
      "Best model saved with validation loss: 137.6364\n",
      "Epoch [5/500], Training Loss: 140.6555\n",
      "Epoch [5/500], Validation Loss: 134.3360\n",
      "Best model saved with validation loss: 134.3360\n",
      "Epoch [6/500], Training Loss: 137.0239\n",
      "Epoch [6/500], Validation Loss: 131.1920\n",
      "Best model saved with validation loss: 131.1920\n",
      "Epoch [7/500], Training Loss: 133.5244\n",
      "Epoch [7/500], Validation Loss: 128.1892\n",
      "Best model saved with validation loss: 128.1892\n",
      "Epoch [8/500], Training Loss: 130.1087\n",
      "Epoch [8/500], Validation Loss: 125.2668\n",
      "Best model saved with validation loss: 125.2668\n",
      "Epoch [9/500], Training Loss: 126.8053\n",
      "Epoch [9/500], Validation Loss: 122.4881\n",
      "Best model saved with validation loss: 122.4881\n",
      "Epoch [10/500], Training Loss: 123.6551\n",
      "Epoch [10/500], Validation Loss: 119.8735\n",
      "Best model saved with validation loss: 119.8735\n",
      "Epoch [11/500], Training Loss: 120.6573\n",
      "Epoch [11/500], Validation Loss: 117.3884\n",
      "Best model saved with validation loss: 117.3884\n",
      "Epoch [12/500], Training Loss: 117.8133\n",
      "Epoch [12/500], Validation Loss: 115.0821\n",
      "Best model saved with validation loss: 115.0821\n",
      "Epoch [13/500], Training Loss: 115.1095\n",
      "Epoch [13/500], Validation Loss: 112.8987\n",
      "Best model saved with validation loss: 112.8987\n",
      "Epoch [14/500], Training Loss: 112.5032\n",
      "Epoch [14/500], Validation Loss: 110.8300\n",
      "Best model saved with validation loss: 110.8300\n",
      "Epoch [15/500], Training Loss: 110.0336\n",
      "Epoch [15/500], Validation Loss: 108.9094\n",
      "Best model saved with validation loss: 108.9094\n",
      "Epoch [16/500], Training Loss: 107.7183\n",
      "Epoch [16/500], Validation Loss: 107.1161\n",
      "Best model saved with validation loss: 107.1161\n",
      "Epoch [17/500], Training Loss: 105.5639\n",
      "Epoch [17/500], Validation Loss: 105.4296\n",
      "Best model saved with validation loss: 105.4296\n",
      "Epoch [18/500], Training Loss: 103.5609\n",
      "Epoch [18/500], Validation Loss: 103.8657\n",
      "Best model saved with validation loss: 103.8657\n",
      "Epoch [19/500], Training Loss: 101.7206\n",
      "Epoch [19/500], Validation Loss: 102.4401\n",
      "Best model saved with validation loss: 102.4401\n",
      "Epoch [20/500], Training Loss: 100.0317\n",
      "Epoch [20/500], Validation Loss: 101.0956\n",
      "Best model saved with validation loss: 101.0956\n",
      "Epoch [21/500], Training Loss: 98.5087\n",
      "Epoch [21/500], Validation Loss: 99.8573\n",
      "Best model saved with validation loss: 99.8573\n",
      "Epoch [22/500], Training Loss: 97.1050\n",
      "Epoch [22/500], Validation Loss: 98.6951\n",
      "Best model saved with validation loss: 98.6951\n",
      "Epoch [23/500], Training Loss: 95.8273\n",
      "Epoch [23/500], Validation Loss: 97.6174\n",
      "Best model saved with validation loss: 97.6174\n",
      "Epoch [24/500], Training Loss: 94.6641\n",
      "Epoch [24/500], Validation Loss: 96.6265\n",
      "Best model saved with validation loss: 96.6265\n",
      "Epoch [25/500], Training Loss: 93.6422\n",
      "Epoch [25/500], Validation Loss: 95.7369\n",
      "Best model saved with validation loss: 95.7369\n",
      "Epoch [26/500], Training Loss: 92.7397\n",
      "Epoch [26/500], Validation Loss: 94.9428\n",
      "Best model saved with validation loss: 94.9428\n",
      "Epoch [27/500], Training Loss: 91.9415\n",
      "Epoch [27/500], Validation Loss: 94.2369\n",
      "Best model saved with validation loss: 94.2369\n",
      "Epoch [28/500], Training Loss: 91.2336\n",
      "Epoch [28/500], Validation Loss: 93.6128\n",
      "Best model saved with validation loss: 93.6128\n",
      "Epoch [29/500], Training Loss: 90.6324\n",
      "Epoch [29/500], Validation Loss: 93.0821\n",
      "Best model saved with validation loss: 93.0821\n",
      "Epoch [30/500], Training Loss: 90.1101\n",
      "Epoch [30/500], Validation Loss: 92.6058\n",
      "Best model saved with validation loss: 92.6058\n",
      "Epoch [31/500], Training Loss: 89.6268\n",
      "Epoch [31/500], Validation Loss: 92.1733\n",
      "Best model saved with validation loss: 92.1733\n",
      "Epoch [32/500], Training Loss: 89.1907\n",
      "Epoch [32/500], Validation Loss: 91.7879\n",
      "Best model saved with validation loss: 91.7879\n",
      "Epoch [33/500], Training Loss: 88.8153\n",
      "Epoch [33/500], Validation Loss: 91.4392\n",
      "Best model saved with validation loss: 91.4392\n",
      "Epoch [34/500], Training Loss: 88.4702\n",
      "Epoch [34/500], Validation Loss: 91.1173\n",
      "Best model saved with validation loss: 91.1173\n",
      "Epoch [35/500], Training Loss: 88.1548\n",
      "Epoch [35/500], Validation Loss: 90.8186\n",
      "Best model saved with validation loss: 90.8186\n",
      "Epoch [36/500], Training Loss: 87.5322\n",
      "Epoch [36/500], Validation Loss: 90.5296\n",
      "Best model saved with validation loss: 90.5296\n",
      "Epoch [37/500], Training Loss: 87.1173\n",
      "Epoch [37/500], Validation Loss: 90.2556\n",
      "Best model saved with validation loss: 90.2556\n",
      "Epoch [38/500], Training Loss: 86.6979\n",
      "Epoch [38/500], Validation Loss: 89.9742\n",
      "Best model saved with validation loss: 89.9742\n",
      "Epoch [39/500], Training Loss: 86.2315\n",
      "Epoch [39/500], Validation Loss: 89.6903\n",
      "Best model saved with validation loss: 89.6903\n",
      "Epoch [40/500], Training Loss: 85.6368\n",
      "Epoch [40/500], Validation Loss: 89.4358\n",
      "Best model saved with validation loss: 89.4358\n",
      "Epoch [41/500], Training Loss: 85.0099\n",
      "Epoch [41/500], Validation Loss: 89.2075\n",
      "Best model saved with validation loss: 89.2075\n",
      "Epoch [42/500], Training Loss: 84.4290\n",
      "Epoch [42/500], Validation Loss: 88.9924\n",
      "Best model saved with validation loss: 88.9924\n",
      "Epoch [43/500], Training Loss: 83.9870\n",
      "Epoch [43/500], Validation Loss: 88.7981\n",
      "Best model saved with validation loss: 88.7981\n",
      "Epoch [44/500], Training Loss: 83.6508\n",
      "Epoch [44/500], Validation Loss: 88.5704\n",
      "Best model saved with validation loss: 88.5704\n",
      "Epoch [45/500], Training Loss: 83.2484\n",
      "Epoch [45/500], Validation Loss: 88.3755\n",
      "Best model saved with validation loss: 88.3755\n",
      "Epoch [46/500], Training Loss: 82.8423\n",
      "Epoch [46/500], Validation Loss: 88.2331\n",
      "Best model saved with validation loss: 88.2331\n",
      "Epoch [47/500], Training Loss: 82.3805\n",
      "Epoch [47/500], Validation Loss: 88.1268\n",
      "Best model saved with validation loss: 88.1268\n",
      "Epoch [48/500], Training Loss: 81.6034\n",
      "Epoch [48/500], Validation Loss: 88.1724\n",
      "Epoch [49/500], Training Loss: 79.6936\n",
      "Epoch [49/500], Validation Loss: 88.0612\n",
      "Best model saved with validation loss: 88.0612\n",
      "Epoch [50/500], Training Loss: 78.6954\n",
      "Epoch [50/500], Validation Loss: 87.8289\n",
      "Best model saved with validation loss: 87.8289\n",
      "Epoch [51/500], Training Loss: 78.0480\n",
      "Epoch [51/500], Validation Loss: 87.6147\n",
      "Best model saved with validation loss: 87.6147\n",
      "Epoch [52/500], Training Loss: 77.5366\n",
      "Epoch [52/500], Validation Loss: 87.4313\n",
      "Best model saved with validation loss: 87.4313\n",
      "Epoch [53/500], Training Loss: 77.1154\n",
      "Epoch [53/500], Validation Loss: 87.2828\n",
      "Best model saved with validation loss: 87.2828\n",
      "Epoch [54/500], Training Loss: 76.6023\n",
      "Epoch [54/500], Validation Loss: 87.1191\n",
      "Best model saved with validation loss: 87.1191\n",
      "Epoch [55/500], Training Loss: 76.2427\n",
      "Epoch [55/500], Validation Loss: 86.9697\n",
      "Best model saved with validation loss: 86.9697\n",
      "Epoch [56/500], Training Loss: 75.7919\n",
      "Epoch [56/500], Validation Loss: 86.8763\n",
      "Best model saved with validation loss: 86.8763\n",
      "Epoch [57/500], Training Loss: 75.4174\n",
      "Epoch [57/500], Validation Loss: 86.7414\n",
      "Best model saved with validation loss: 86.7414\n",
      "Epoch [58/500], Training Loss: 75.0877\n",
      "Epoch [58/500], Validation Loss: 86.6362\n",
      "Best model saved with validation loss: 86.6362\n",
      "Epoch [59/500], Training Loss: 74.7282\n",
      "Epoch [59/500], Validation Loss: 86.5207\n",
      "Best model saved with validation loss: 86.5207\n",
      "Epoch [60/500], Training Loss: 74.4382\n",
      "Epoch [60/500], Validation Loss: 86.4098\n",
      "Best model saved with validation loss: 86.4098\n",
      "Epoch [61/500], Training Loss: 74.0805\n",
      "Epoch [61/500], Validation Loss: 86.3154\n",
      "Best model saved with validation loss: 86.3154\n",
      "Epoch [62/500], Training Loss: 73.8573\n",
      "Epoch [62/500], Validation Loss: 86.2065\n",
      "Best model saved with validation loss: 86.2065\n",
      "Epoch [63/500], Training Loss: 73.5625\n",
      "Epoch [63/500], Validation Loss: 86.1393\n",
      "Best model saved with validation loss: 86.1393\n",
      "Epoch [64/500], Training Loss: 73.3367\n",
      "Epoch [64/500], Validation Loss: 86.0812\n",
      "Best model saved with validation loss: 86.0812\n",
      "Epoch [65/500], Training Loss: 73.1079\n",
      "Epoch [65/500], Validation Loss: 85.9499\n",
      "Best model saved with validation loss: 85.9499\n",
      "Epoch [66/500], Training Loss: 72.8845\n",
      "Epoch [66/500], Validation Loss: 85.9305\n",
      "Best model saved with validation loss: 85.9305\n",
      "Epoch [67/500], Training Loss: 72.6801\n",
      "Epoch [67/500], Validation Loss: 85.8673\n",
      "Best model saved with validation loss: 85.8673\n",
      "Epoch [68/500], Training Loss: 72.4829\n",
      "Epoch [68/500], Validation Loss: 85.7376\n",
      "Best model saved with validation loss: 85.7376\n",
      "Epoch [69/500], Training Loss: 72.2855\n",
      "Epoch [69/500], Validation Loss: 85.6917\n",
      "Best model saved with validation loss: 85.6917\n",
      "Epoch [70/500], Training Loss: 72.0985\n",
      "Epoch [70/500], Validation Loss: 85.6213\n",
      "Best model saved with validation loss: 85.6213\n",
      "Epoch [71/500], Training Loss: 71.8806\n",
      "Epoch [71/500], Validation Loss: 85.5356\n",
      "Best model saved with validation loss: 85.5356\n",
      "Epoch [72/500], Training Loss: 71.7677\n",
      "Epoch [72/500], Validation Loss: 85.5203\n",
      "Best model saved with validation loss: 85.5203\n",
      "Epoch [73/500], Training Loss: 71.5697\n",
      "Epoch [73/500], Validation Loss: 85.4132\n",
      "Best model saved with validation loss: 85.4132\n",
      "Epoch [74/500], Training Loss: 71.4541\n",
      "Epoch [74/500], Validation Loss: 85.3474\n",
      "Best model saved with validation loss: 85.3474\n",
      "Epoch [75/500], Training Loss: 71.2805\n",
      "Epoch [75/500], Validation Loss: 85.2988\n",
      "Best model saved with validation loss: 85.2988\n",
      "Epoch [76/500], Training Loss: 71.1157\n",
      "Epoch [76/500], Validation Loss: 85.2118\n",
      "Best model saved with validation loss: 85.2118\n",
      "Epoch [77/500], Training Loss: 70.9976\n",
      "Epoch [77/500], Validation Loss: 85.2356\n",
      "Epoch [78/500], Training Loss: 70.8821\n",
      "Epoch [78/500], Validation Loss: 85.1677\n",
      "Best model saved with validation loss: 85.1677\n",
      "Epoch [79/500], Training Loss: 70.7544\n",
      "Epoch [79/500], Validation Loss: 85.0918\n",
      "Best model saved with validation loss: 85.0918\n",
      "Epoch [80/500], Training Loss: 70.6619\n",
      "Epoch [80/500], Validation Loss: 85.0878\n",
      "Best model saved with validation loss: 85.0878\n",
      "Epoch [81/500], Training Loss: 70.5431\n",
      "Epoch [81/500], Validation Loss: 85.0767\n",
      "Best model saved with validation loss: 85.0767\n",
      "Epoch [82/500], Training Loss: 70.4175\n",
      "Epoch [82/500], Validation Loss: 85.0230\n",
      "Best model saved with validation loss: 85.0230\n",
      "Epoch [83/500], Training Loss: 70.2769\n",
      "Epoch [83/500], Validation Loss: 84.9899\n",
      "Best model saved with validation loss: 84.9899\n",
      "Epoch [84/500], Training Loss: 70.1833\n",
      "Epoch [84/500], Validation Loss: 84.9392\n",
      "Best model saved with validation loss: 84.9392\n",
      "Epoch [85/500], Training Loss: 70.0829\n",
      "Epoch [85/500], Validation Loss: 84.9342\n",
      "Best model saved with validation loss: 84.9342\n",
      "Epoch [86/500], Training Loss: 70.0289\n",
      "Epoch [86/500], Validation Loss: 84.9134\n",
      "Best model saved with validation loss: 84.9134\n",
      "Epoch [87/500], Training Loss: 69.8850\n",
      "Epoch [87/500], Validation Loss: 84.8470\n",
      "Best model saved with validation loss: 84.8470\n",
      "Epoch [88/500], Training Loss: 69.8189\n",
      "Epoch [88/500], Validation Loss: 84.8215\n",
      "Best model saved with validation loss: 84.8215\n",
      "Epoch [89/500], Training Loss: 69.7338\n",
      "Epoch [89/500], Validation Loss: 84.8133\n",
      "Best model saved with validation loss: 84.8133\n",
      "Epoch [90/500], Training Loss: 69.6263\n",
      "Epoch [90/500], Validation Loss: 84.8601\n",
      "Epoch [91/500], Training Loss: 69.5126\n",
      "Epoch [91/500], Validation Loss: 84.7460\n",
      "Best model saved with validation loss: 84.7460\n",
      "Epoch [92/500], Training Loss: 69.4530\n",
      "Epoch [92/500], Validation Loss: 84.6973\n",
      "Best model saved with validation loss: 84.6973\n",
      "Epoch [93/500], Training Loss: 69.4142\n",
      "Epoch [93/500], Validation Loss: 84.6846\n",
      "Best model saved with validation loss: 84.6846\n",
      "Epoch [94/500], Training Loss: 69.3456\n",
      "Epoch [94/500], Validation Loss: 84.6565\n",
      "Best model saved with validation loss: 84.6565\n",
      "Epoch [95/500], Training Loss: 69.2405\n",
      "Epoch [95/500], Validation Loss: 84.6939\n",
      "Epoch [96/500], Training Loss: 69.1349\n",
      "Epoch [96/500], Validation Loss: 84.6480\n",
      "Best model saved with validation loss: 84.6480\n",
      "Epoch [97/500], Training Loss: 69.0806\n",
      "Epoch [97/500], Validation Loss: 84.6335\n",
      "Best model saved with validation loss: 84.6335\n",
      "Epoch [98/500], Training Loss: 69.0357\n",
      "Epoch [98/500], Validation Loss: 84.5516\n",
      "Best model saved with validation loss: 84.5516\n",
      "Epoch [99/500], Training Loss: 68.9712\n",
      "Epoch [99/500], Validation Loss: 84.5394\n",
      "Best model saved with validation loss: 84.5394\n",
      "Epoch [100/500], Training Loss: 68.9273\n",
      "Epoch [100/500], Validation Loss: 84.4468\n",
      "Best model saved with validation loss: 84.4468\n",
      "Epoch [101/500], Training Loss: 68.8426\n",
      "Epoch [101/500], Validation Loss: 84.5332\n",
      "Epoch [102/500], Training Loss: 68.8128\n",
      "Epoch [102/500], Validation Loss: 84.4416\n",
      "Best model saved with validation loss: 84.4416\n",
      "Epoch [103/500], Training Loss: 68.7465\n",
      "Epoch [103/500], Validation Loss: 84.4516\n",
      "Epoch [104/500], Training Loss: 68.6476\n",
      "Epoch [104/500], Validation Loss: 84.3928\n",
      "Best model saved with validation loss: 84.3928\n",
      "Epoch [105/500], Training Loss: 68.5863\n",
      "Epoch [105/500], Validation Loss: 84.3170\n",
      "Best model saved with validation loss: 84.3170\n",
      "Epoch [106/500], Training Loss: 68.5870\n",
      "Epoch [106/500], Validation Loss: 84.3309\n",
      "Epoch [107/500], Training Loss: 68.5277\n",
      "Epoch [107/500], Validation Loss: 84.2679\n",
      "Best model saved with validation loss: 84.2679\n",
      "Epoch [108/500], Training Loss: 68.4871\n",
      "Epoch [108/500], Validation Loss: 84.2232\n",
      "Best model saved with validation loss: 84.2232\n",
      "Epoch [109/500], Training Loss: 68.4069\n",
      "Epoch [109/500], Validation Loss: 84.2133\n",
      "Best model saved with validation loss: 84.2133\n",
      "Epoch [110/500], Training Loss: 68.3244\n",
      "Epoch [110/500], Validation Loss: 84.2202\n",
      "Epoch [111/500], Training Loss: 68.3009\n",
      "Epoch [111/500], Validation Loss: 84.1706\n",
      "Best model saved with validation loss: 84.1706\n",
      "Epoch [112/500], Training Loss: 68.3035\n",
      "Epoch [112/500], Validation Loss: 84.1535\n",
      "Best model saved with validation loss: 84.1535\n",
      "Epoch [113/500], Training Loss: 68.2282\n",
      "Epoch [113/500], Validation Loss: 84.0589\n",
      "Best model saved with validation loss: 84.0589\n",
      "Epoch [114/500], Training Loss: 68.2016\n",
      "Epoch [114/500], Validation Loss: 84.0890\n",
      "Epoch [115/500], Training Loss: 68.1733\n",
      "Epoch [115/500], Validation Loss: 84.0884\n",
      "Epoch [116/500], Training Loss: 68.0907\n",
      "Epoch [116/500], Validation Loss: 83.9798\n",
      "Best model saved with validation loss: 83.9798\n",
      "Epoch [117/500], Training Loss: 68.0551\n",
      "Epoch [117/500], Validation Loss: 83.9748\n",
      "Best model saved with validation loss: 83.9748\n",
      "Epoch [118/500], Training Loss: 68.0086\n",
      "Epoch [118/500], Validation Loss: 83.9521\n",
      "Best model saved with validation loss: 83.9521\n",
      "Epoch [119/500], Training Loss: 67.9485\n",
      "Epoch [119/500], Validation Loss: 83.9734\n",
      "Epoch [120/500], Training Loss: 67.9288\n",
      "Epoch [120/500], Validation Loss: 83.9066\n",
      "Best model saved with validation loss: 83.9066\n",
      "Epoch [121/500], Training Loss: 67.8842\n",
      "Epoch [121/500], Validation Loss: 83.8100\n",
      "Best model saved with validation loss: 83.8100\n",
      "Epoch [122/500], Training Loss: 67.8460\n",
      "Epoch [122/500], Validation Loss: 83.6979\n",
      "Best model saved with validation loss: 83.6979\n",
      "Epoch [123/500], Training Loss: 67.8133\n",
      "Epoch [123/500], Validation Loss: 83.7242\n",
      "Epoch [124/500], Training Loss: 67.7982\n",
      "Epoch [124/500], Validation Loss: 83.7767\n",
      "Epoch [125/500], Training Loss: 67.7302\n",
      "Epoch [125/500], Validation Loss: 83.7666\n",
      "Epoch [126/500], Training Loss: 67.6968\n",
      "Epoch [126/500], Validation Loss: 83.6935\n",
      "Best model saved with validation loss: 83.6935\n",
      "Epoch [127/500], Training Loss: 67.6827\n",
      "Epoch [127/500], Validation Loss: 83.7374\n",
      "Epoch [128/500], Training Loss: 67.6591\n",
      "Epoch [128/500], Validation Loss: 83.6448\n",
      "Best model saved with validation loss: 83.6448\n",
      "Epoch [129/500], Training Loss: 67.5801\n",
      "Epoch [129/500], Validation Loss: 83.5633\n",
      "Best model saved with validation loss: 83.5633\n",
      "Epoch [130/500], Training Loss: 67.5553\n",
      "Epoch [130/500], Validation Loss: 83.6043\n",
      "Epoch [131/500], Training Loss: 67.5514\n",
      "Epoch [131/500], Validation Loss: 83.5145\n",
      "Best model saved with validation loss: 83.5145\n",
      "Epoch [132/500], Training Loss: 67.5240\n",
      "Epoch [132/500], Validation Loss: 83.5357\n",
      "Epoch [133/500], Training Loss: 67.4807\n",
      "Epoch [133/500], Validation Loss: 83.4903\n",
      "Best model saved with validation loss: 83.4903\n",
      "Epoch [134/500], Training Loss: 67.4255\n",
      "Epoch [134/500], Validation Loss: 83.4868\n",
      "Best model saved with validation loss: 83.4868\n",
      "Epoch [135/500], Training Loss: 67.3967\n",
      "Epoch [135/500], Validation Loss: 83.5244\n",
      "Epoch [136/500], Training Loss: 67.4017\n",
      "Epoch [136/500], Validation Loss: 83.4338\n",
      "Best model saved with validation loss: 83.4338\n",
      "Epoch [137/500], Training Loss: 67.3375\n",
      "Epoch [137/500], Validation Loss: 83.4316\n",
      "Best model saved with validation loss: 83.4316\n",
      "Epoch [138/500], Training Loss: 67.3068\n",
      "Epoch [138/500], Validation Loss: 83.4167\n",
      "Best model saved with validation loss: 83.4167\n",
      "Epoch [139/500], Training Loss: 67.2480\n",
      "Epoch [139/500], Validation Loss: 83.3299\n",
      "Best model saved with validation loss: 83.3299\n",
      "Epoch [140/500], Training Loss: 67.2740\n",
      "Epoch [140/500], Validation Loss: 83.2795\n",
      "Best model saved with validation loss: 83.2795\n",
      "Epoch [141/500], Training Loss: 67.2808\n",
      "Epoch [141/500], Validation Loss: 83.2962\n",
      "Epoch [142/500], Training Loss: 67.1648\n",
      "Epoch [142/500], Validation Loss: 83.2191\n",
      "Best model saved with validation loss: 83.2191\n",
      "Epoch [143/500], Training Loss: 67.1601\n",
      "Epoch [143/500], Validation Loss: 83.1727\n",
      "Best model saved with validation loss: 83.1727\n",
      "Epoch [144/500], Training Loss: 67.1304\n",
      "Epoch [144/500], Validation Loss: 83.1416\n",
      "Best model saved with validation loss: 83.1416\n",
      "Epoch [145/500], Training Loss: 67.1096\n",
      "Epoch [145/500], Validation Loss: 83.1092\n",
      "Best model saved with validation loss: 83.1092\n",
      "Epoch [146/500], Training Loss: 67.0785\n",
      "Epoch [146/500], Validation Loss: 83.1387\n",
      "Epoch [147/500], Training Loss: 67.0706\n",
      "Epoch [147/500], Validation Loss: 83.0981\n",
      "Best model saved with validation loss: 83.0981\n",
      "Epoch [148/500], Training Loss: 67.0079\n",
      "Epoch [148/500], Validation Loss: 83.0636\n",
      "Best model saved with validation loss: 83.0636\n",
      "Epoch [149/500], Training Loss: 67.0074\n",
      "Epoch [149/500], Validation Loss: 83.1150\n",
      "Epoch [150/500], Training Loss: 66.9952\n",
      "Epoch [150/500], Validation Loss: 83.0098\n",
      "Best model saved with validation loss: 83.0098\n",
      "Epoch [151/500], Training Loss: 66.9174\n",
      "Epoch [151/500], Validation Loss: 83.0313\n",
      "Epoch [152/500], Training Loss: 66.9768\n",
      "Epoch [152/500], Validation Loss: 83.0057\n",
      "Best model saved with validation loss: 83.0057\n",
      "Epoch [153/500], Training Loss: 66.8834\n",
      "Epoch [153/500], Validation Loss: 82.9779\n",
      "Best model saved with validation loss: 82.9779\n",
      "Epoch [154/500], Training Loss: 66.8974\n",
      "Epoch [154/500], Validation Loss: 83.0326\n",
      "Epoch [155/500], Training Loss: 66.8305\n",
      "Epoch [155/500], Validation Loss: 83.0824\n",
      "Epoch [156/500], Training Loss: 66.7843\n",
      "Epoch [156/500], Validation Loss: 82.9432\n",
      "Best model saved with validation loss: 82.9432\n",
      "Epoch [157/500], Training Loss: 66.8339\n",
      "Epoch [157/500], Validation Loss: 82.8763\n",
      "Best model saved with validation loss: 82.8763\n",
      "Epoch [158/500], Training Loss: 66.7496\n",
      "Epoch [158/500], Validation Loss: 82.9343\n",
      "Epoch [159/500], Training Loss: 66.7844\n",
      "Epoch [159/500], Validation Loss: 82.8597\n",
      "Best model saved with validation loss: 82.8597\n",
      "Epoch [160/500], Training Loss: 66.7250\n",
      "Epoch [160/500], Validation Loss: 82.8040\n",
      "Best model saved with validation loss: 82.8040\n",
      "Epoch [161/500], Training Loss: 66.6936\n",
      "Epoch [161/500], Validation Loss: 82.7830\n",
      "Best model saved with validation loss: 82.7830\n",
      "Epoch [162/500], Training Loss: 66.6666\n",
      "Epoch [162/500], Validation Loss: 82.8421\n",
      "Epoch [163/500], Training Loss: 66.6392\n",
      "Epoch [163/500], Validation Loss: 82.7462\n",
      "Best model saved with validation loss: 82.7462\n",
      "Epoch [164/500], Training Loss: 66.6855\n",
      "Epoch [164/500], Validation Loss: 82.7115\n",
      "Best model saved with validation loss: 82.7115\n",
      "Epoch [165/500], Training Loss: 66.6360\n",
      "Epoch [165/500], Validation Loss: 82.6937\n",
      "Best model saved with validation loss: 82.6937\n",
      "Epoch [166/500], Training Loss: 66.6355\n",
      "Epoch [166/500], Validation Loss: 82.7595\n",
      "Epoch [167/500], Training Loss: 66.5551\n",
      "Epoch [167/500], Validation Loss: 82.7070\n",
      "Epoch [168/500], Training Loss: 66.5236\n",
      "Epoch [168/500], Validation Loss: 82.6926\n",
      "Best model saved with validation loss: 82.6926\n",
      "Epoch [169/500], Training Loss: 66.5221\n",
      "Epoch [169/500], Validation Loss: 82.7901\n",
      "Epoch [170/500], Training Loss: 66.5167\n",
      "Epoch [170/500], Validation Loss: 82.6836\n",
      "Best model saved with validation loss: 82.6836\n",
      "Epoch [171/500], Training Loss: 66.4992\n",
      "Epoch [171/500], Validation Loss: 82.6803\n",
      "Best model saved with validation loss: 82.6803\n",
      "Epoch [172/500], Training Loss: 66.4739\n",
      "Epoch [172/500], Validation Loss: 82.5828\n",
      "Best model saved with validation loss: 82.5828\n",
      "Epoch [173/500], Training Loss: 66.4593\n",
      "Epoch [173/500], Validation Loss: 82.7314\n",
      "Epoch [174/500], Training Loss: 66.4155\n",
      "Epoch [174/500], Validation Loss: 82.6480\n",
      "Epoch [175/500], Training Loss: 66.3733\n",
      "Epoch [175/500], Validation Loss: 82.6913\n",
      "Epoch [176/500], Training Loss: 66.4060\n",
      "Epoch [176/500], Validation Loss: 82.6210\n",
      "Epoch [177/500], Training Loss: 66.3436\n",
      "Epoch [177/500], Validation Loss: 82.6510\n",
      "Epoch [178/500], Training Loss: 66.3411\n",
      "Epoch [178/500], Validation Loss: 82.6630\n",
      "Epoch [179/500], Training Loss: 66.3505\n",
      "Epoch [179/500], Validation Loss: 82.5965\n",
      "Epoch [180/500], Training Loss: 66.3351\n",
      "Epoch [180/500], Validation Loss: 82.6042\n",
      "Epoch [181/500], Training Loss: 66.3410\n",
      "Epoch [181/500], Validation Loss: 82.5539\n",
      "Best model saved with validation loss: 82.5539\n",
      "Epoch [182/500], Training Loss: 66.2911\n",
      "Epoch [182/500], Validation Loss: 82.5171\n",
      "Best model saved with validation loss: 82.5171\n",
      "Epoch [183/500], Training Loss: 66.2707\n",
      "Epoch [183/500], Validation Loss: 82.5539\n",
      "Epoch [184/500], Training Loss: 66.2004\n",
      "Epoch [184/500], Validation Loss: 82.4588\n",
      "Best model saved with validation loss: 82.4588\n",
      "Epoch [185/500], Training Loss: 66.2440\n",
      "Epoch [185/500], Validation Loss: 82.5711\n",
      "Epoch [186/500], Training Loss: 66.1988\n",
      "Epoch [186/500], Validation Loss: 82.5181\n",
      "Epoch [187/500], Training Loss: 66.1854\n",
      "Epoch [187/500], Validation Loss: 82.4901\n",
      "Epoch [188/500], Training Loss: 66.1867\n",
      "Epoch [188/500], Validation Loss: 82.4605\n",
      "Epoch [189/500], Training Loss: 66.1662\n",
      "Epoch [189/500], Validation Loss: 82.4817\n",
      "Epoch [190/500], Training Loss: 66.1845\n",
      "Epoch [190/500], Validation Loss: 82.4753\n",
      "Epoch [191/500], Training Loss: 66.0820\n",
      "Epoch [191/500], Validation Loss: 82.5198\n",
      "Epoch [192/500], Training Loss: 66.1072\n",
      "Epoch [192/500], Validation Loss: 82.4398\n",
      "Best model saved with validation loss: 82.4398\n",
      "Epoch [193/500], Training Loss: 66.1002\n",
      "Epoch [193/500], Validation Loss: 82.3757\n",
      "Best model saved with validation loss: 82.3757\n",
      "Epoch [194/500], Training Loss: 66.0919\n",
      "Epoch [194/500], Validation Loss: 82.3948\n",
      "Epoch [195/500], Training Loss: 66.0810\n",
      "Epoch [195/500], Validation Loss: 82.3620\n",
      "Best model saved with validation loss: 82.3620\n",
      "Epoch [196/500], Training Loss: 66.1163\n",
      "Epoch [196/500], Validation Loss: 82.4031\n",
      "Epoch [197/500], Training Loss: 66.0720\n",
      "Epoch [197/500], Validation Loss: 82.3429\n",
      "Best model saved with validation loss: 82.3429\n",
      "Epoch [198/500], Training Loss: 66.0811\n",
      "Epoch [198/500], Validation Loss: 82.2939\n",
      "Best model saved with validation loss: 82.2939\n",
      "Epoch [199/500], Training Loss: 65.9842\n",
      "Epoch [199/500], Validation Loss: 82.3222\n",
      "Epoch [200/500], Training Loss: 66.0285\n",
      "Epoch [200/500], Validation Loss: 82.3665\n",
      "Epoch [201/500], Training Loss: 66.0142\n",
      "Epoch [201/500], Validation Loss: 82.2574\n",
      "Best model saved with validation loss: 82.2574\n",
      "Epoch [202/500], Training Loss: 65.9629\n",
      "Epoch [202/500], Validation Loss: 82.2788\n",
      "Epoch [203/500], Training Loss: 65.9574\n",
      "Epoch [203/500], Validation Loss: 82.2639\n",
      "Epoch [204/500], Training Loss: 65.9848\n",
      "Epoch [204/500], Validation Loss: 82.3172\n",
      "Epoch [205/500], Training Loss: 65.9062\n",
      "Epoch [205/500], Validation Loss: 82.3096\n",
      "Epoch [206/500], Training Loss: 65.9368\n",
      "Epoch [206/500], Validation Loss: 82.3128\n",
      "Epoch [207/500], Training Loss: 65.9418\n",
      "Epoch [207/500], Validation Loss: 82.3268\n",
      "Epoch [208/500], Training Loss: 65.9310\n",
      "Epoch [208/500], Validation Loss: 82.4000\n",
      "Epoch [209/500], Training Loss: 65.8720\n",
      "Epoch [209/500], Validation Loss: 82.3645\n",
      "Epoch [210/500], Training Loss: 65.9038\n",
      "Epoch [210/500], Validation Loss: 82.3032\n",
      "Epoch [211/500], Training Loss: 65.8783\n",
      "Epoch [211/500], Validation Loss: 82.3347\n",
      "Epoch [212/500], Training Loss: 65.8514\n",
      "Epoch [212/500], Validation Loss: 82.3209\n",
      "Epoch [213/500], Training Loss: 65.8766\n",
      "Epoch [213/500], Validation Loss: 82.3420\n",
      "Epoch [214/500], Training Loss: 65.8263\n",
      "Epoch [214/500], Validation Loss: 82.3335\n",
      "Epoch [215/500], Training Loss: 65.8040\n",
      "Epoch [215/500], Validation Loss: 82.2306\n",
      "Best model saved with validation loss: 82.2306\n",
      "Epoch [216/500], Training Loss: 65.7997\n",
      "Epoch [216/500], Validation Loss: 82.2710\n",
      "Epoch [217/500], Training Loss: 65.7350\n",
      "Epoch [217/500], Validation Loss: 82.2341\n",
      "Epoch [218/500], Training Loss: 65.7191\n",
      "Epoch [218/500], Validation Loss: 82.2068\n",
      "Best model saved with validation loss: 82.2068\n",
      "Epoch [219/500], Training Loss: 65.7464\n",
      "Epoch [219/500], Validation Loss: 82.2164\n",
      "Epoch [220/500], Training Loss: 65.7144\n",
      "Epoch [220/500], Validation Loss: 82.3148\n",
      "Epoch [221/500], Training Loss: 65.6694\n",
      "Epoch [221/500], Validation Loss: 82.3070\n",
      "Epoch [222/500], Training Loss: 65.7229\n",
      "Epoch [222/500], Validation Loss: 82.2982\n",
      "Epoch [223/500], Training Loss: 65.7298\n",
      "Epoch [223/500], Validation Loss: 82.3410\n",
      "Epoch [224/500], Training Loss: 65.6534\n",
      "Epoch [224/500], Validation Loss: 82.2692\n",
      "Epoch [225/500], Training Loss: 65.6930\n",
      "Epoch [225/500], Validation Loss: 82.2574\n",
      "Epoch [226/500], Training Loss: 65.6096\n",
      "Epoch [226/500], Validation Loss: 82.2551\n",
      "Epoch [227/500], Training Loss: 65.6393\n",
      "Epoch [227/500], Validation Loss: 82.2137\n",
      "Epoch [228/500], Training Loss: 65.6380\n",
      "Epoch [228/500], Validation Loss: 82.2721\n",
      "Epoch [229/500], Training Loss: 65.6534\n",
      "Epoch [229/500], Validation Loss: 82.2648\n",
      "Epoch [230/500], Training Loss: 65.5944\n",
      "Epoch [230/500], Validation Loss: 82.2000\n",
      "Best model saved with validation loss: 82.2000\n",
      "Epoch [231/500], Training Loss: 65.5989\n",
      "Epoch [231/500], Validation Loss: 82.1765\n",
      "Best model saved with validation loss: 82.1765\n",
      "Epoch [232/500], Training Loss: 65.5715\n",
      "Epoch [232/500], Validation Loss: 82.1500\n",
      "Best model saved with validation loss: 82.1500\n",
      "Epoch [233/500], Training Loss: 65.6243\n",
      "Epoch [233/500], Validation Loss: 82.1717\n",
      "Epoch [234/500], Training Loss: 65.5719\n",
      "Epoch [234/500], Validation Loss: 82.1939\n",
      "Epoch [235/500], Training Loss: 65.5132\n",
      "Epoch [235/500], Validation Loss: 82.1757\n",
      "Epoch [236/500], Training Loss: 65.5114\n",
      "Epoch [236/500], Validation Loss: 82.2282\n",
      "Epoch [237/500], Training Loss: 65.5231\n",
      "Epoch [237/500], Validation Loss: 82.2078\n",
      "Epoch [238/500], Training Loss: 65.4498\n",
      "Epoch [238/500], Validation Loss: 82.1275\n",
      "Best model saved with validation loss: 82.1275\n",
      "Epoch [239/500], Training Loss: 65.4913\n",
      "Epoch [239/500], Validation Loss: 82.2086\n",
      "Epoch [240/500], Training Loss: 65.4859\n",
      "Epoch [240/500], Validation Loss: 82.2384\n",
      "Epoch [241/500], Training Loss: 65.4223\n",
      "Epoch [241/500], Validation Loss: 82.1689\n",
      "Epoch [242/500], Training Loss: 65.4777\n",
      "Epoch [242/500], Validation Loss: 82.1322\n",
      "Epoch [243/500], Training Loss: 65.3460\n",
      "Epoch [243/500], Validation Loss: 82.2135\n",
      "Epoch [244/500], Training Loss: 65.3874\n",
      "Epoch [244/500], Validation Loss: 82.2271\n",
      "Epoch [245/500], Training Loss: 65.3269\n",
      "Epoch [245/500], Validation Loss: 82.1910\n",
      "Epoch [246/500], Training Loss: 65.3906\n",
      "Epoch [246/500], Validation Loss: 82.2239\n",
      "Epoch [247/500], Training Loss: 65.3786\n",
      "Epoch [247/500], Validation Loss: 82.1988\n",
      "Epoch [248/500], Training Loss: 65.3523\n",
      "Epoch [248/500], Validation Loss: 82.2508\n",
      "Epoch [249/500], Training Loss: 65.2767\n",
      "Epoch [249/500], Validation Loss: 82.1415\n",
      "Epoch [250/500], Training Loss: 65.3226\n",
      "Epoch [250/500], Validation Loss: 82.1616\n",
      "Epoch [251/500], Training Loss: 65.3037\n",
      "Epoch [251/500], Validation Loss: 82.0398\n",
      "Best model saved with validation loss: 82.0398\n",
      "Epoch [252/500], Training Loss: 65.3272\n",
      "Epoch [252/500], Validation Loss: 82.1468\n",
      "Epoch [253/500], Training Loss: 65.2914\n",
      "Epoch [253/500], Validation Loss: 82.1877\n",
      "Epoch [254/500], Training Loss: 65.3015\n",
      "Epoch [254/500], Validation Loss: 82.2265\n",
      "Epoch [255/500], Training Loss: 65.1997\n",
      "Epoch [255/500], Validation Loss: 82.2305\n",
      "Epoch [256/500], Training Loss: 65.2317\n",
      "Epoch [256/500], Validation Loss: 82.1623\n",
      "Epoch [257/500], Training Loss: 65.2256\n",
      "Epoch [257/500], Validation Loss: 82.0347\n",
      "Best model saved with validation loss: 82.0347\n",
      "Epoch [258/500], Training Loss: 65.2342\n",
      "Epoch [258/500], Validation Loss: 82.1094\n",
      "Epoch [259/500], Training Loss: 65.2182\n",
      "Epoch [259/500], Validation Loss: 82.1093\n",
      "Epoch [260/500], Training Loss: 65.1444\n",
      "Epoch [260/500], Validation Loss: 82.2262\n",
      "Epoch [261/500], Training Loss: 65.1725\n",
      "Epoch [261/500], Validation Loss: 82.2322\n",
      "Epoch [262/500], Training Loss: 65.1677\n",
      "Epoch [262/500], Validation Loss: 82.2259\n",
      "Epoch [263/500], Training Loss: 65.0743\n",
      "Epoch [263/500], Validation Loss: 82.1070\n",
      "Epoch [264/500], Training Loss: 65.0383\n",
      "Epoch [264/500], Validation Loss: 82.2754\n",
      "Epoch [265/500], Training Loss: 65.1115\n",
      "Epoch [265/500], Validation Loss: 82.2400\n",
      "Epoch [266/500], Training Loss: 65.0674\n",
      "Epoch [266/500], Validation Loss: 82.1791\n",
      "Epoch [267/500], Training Loss: 65.1262\n",
      "Epoch [267/500], Validation Loss: 82.3424\n",
      "Epoch [268/500], Training Loss: 65.0596\n",
      "Epoch [268/500], Validation Loss: 82.3169\n",
      "Epoch [269/500], Training Loss: 65.0565\n",
      "Epoch [269/500], Validation Loss: 82.3398\n",
      "Epoch [270/500], Training Loss: 65.0586\n",
      "Epoch [270/500], Validation Loss: 82.2403\n",
      "Epoch [271/500], Training Loss: 65.0075\n",
      "Epoch [271/500], Validation Loss: 82.1721\n",
      "Epoch [272/500], Training Loss: 65.0082\n",
      "Epoch [272/500], Validation Loss: 82.2602\n",
      "Early stopping triggered after 272 epochs.\n",
      "Test Loss: 43.4394\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F  # For MAE loss function\n",
    "\n",
    "best_val_loss = float('inf')  # Initialize the best validation loss\n",
    "best_model = None\n",
    "patience_counter = 0  # For early stopping\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Reshape input to add sequence length dimension (for some models)\n",
    "        X_batch = X_batch.unsqueeze(1)  # (batch_size, 1, input_size)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch)  # (batch_size, output_size)\n",
    "\n",
    "        # Compute the loss using MAE\n",
    "        loss = F.l1_loss(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_train_loss:.4f}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # Reshape input to add sequence length dimension\n",
    "            X_batch = X_batch.unsqueeze(1)  # (batch_size, 1, input_size)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(X_batch)  # (batch_size, output_size)\n",
    "\n",
    "            # Compute the validation loss using MAE\n",
    "            val_loss = F.l1_loss(y_pred, y_batch)\n",
    "            running_val_loss += val_loss.item()\n",
    "\n",
    "    epoch_val_loss = running_val_loss / len(val_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {epoch_val_loss:.4f}')\n",
    "\n",
    "    # Early stopping based on validation loss\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_model = model.state_dict()  # Save the best model's weights\n",
    "        patience_counter = 0  # Reset patience counter\n",
    "        print(f\"Best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "# Load the best model\n",
    "if best_model is not None:\n",
    "    model.load_state_dict(best_model)\n",
    "else:\n",
    "    print(\"No improvement was observed during training.\")\n",
    "\n",
    "torch.save(model.state_dict(), 'LSTM_imbalance_price.pth')\n",
    "\n",
    "# Test the model using the best model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Reshape input to add sequence length dimension\n",
    "        X_batch = X_batch.unsqueeze(1)  # (batch_size, 1, input_size)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch)  # (batch_size, output_size)\n",
    "\n",
    "        # Compute the test loss using MAE\n",
    "        loss = F.l1_loss(y_pred, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    print(f'Test Loss: {test_loss/len(test_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "path_df = os.path.abspath(os.path.join(current_dir, '..', 'basic_files'))\n",
    "df_total_solar = pd.read_csv(os.path.join(path_df, 'solar_total_production.csv'))\n",
    "df_total_solar.generation_mw = df_total_solar.generation_mw *0.5\n",
    "df_total_wind = pd.read_csv(os.path.join(path_df, 'wind_total_production.csv'))\n",
    "df_total_wind.generation_mw = df_total_wind.generation_mw *0.5 - df_total_wind.boa\n",
    "df_imbalance_price = pd.read_csv(os.path.join(path_df, 'imbalance_price.csv'))\n",
    "df_day_ahead_price = pd.read_csv(os.path.join(path_df, 'day_ahead_price.csv'))\n",
    "df_market_price = pd.read_csv(os.path.join(path_df, 'market_index.csv'))\n",
    "\n",
    "# Get the path to the 'logs' directory in the parent directory\n",
    "path = os.path.abspath(os.path.join(current_dir, '..', 'logs'))\n",
    "files = os.listdir(path)\n",
    "txt_files = [file for file in files if file.endswith('.txt')]\n",
    "data = []\n",
    "for file in txt_files:\n",
    "    with open(os.path.join(path, file), 'r') as f:\n",
    "        try:\n",
    "            json_data = json.load(f)\n",
    "            data.append(json_data)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to decode JSON from file: {file}\")\n",
    "date_name = []\n",
    "for i in range(len(data)):\n",
    "    date_name.append(data[i][\"prediction_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2024-10-03T22:00:00+00:00</td>\n",
       "      <td>1355</td>\n",
       "      <td>487</td>\n",
       "      <td>963</td>\n",
       "      <td>1544</td>\n",
       "      <td>1330</td>\n",
       "      <td>867</td>\n",
       "      <td>326</td>\n",
       "      <td>1402</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2024-10-03T22:30:00+00:00</td>\n",
       "      <td>788</td>\n",
       "      <td>584</td>\n",
       "      <td>1148</td>\n",
       "      <td>1320</td>\n",
       "      <td>1007</td>\n",
       "      <td>565</td>\n",
       "      <td>923</td>\n",
       "      <td>797</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2024-10-03T23:00:00+00:00</td>\n",
       "      <td>571</td>\n",
       "      <td>748</td>\n",
       "      <td>1001</td>\n",
       "      <td>1460</td>\n",
       "      <td>740</td>\n",
       "      <td>1017</td>\n",
       "      <td>1533</td>\n",
       "      <td>597</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2024-10-03T23:30:00+00:00</td>\n",
       "      <td>1476</td>\n",
       "      <td>1194</td>\n",
       "      <td>1512</td>\n",
       "      <td>334</td>\n",
       "      <td>1054</td>\n",
       "      <td>1572</td>\n",
       "      <td>744</td>\n",
       "      <td>1497</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2024-10-04T00:00:00+00:00</td>\n",
       "      <td>1352</td>\n",
       "      <td>1390</td>\n",
       "      <td>912</td>\n",
       "      <td>662</td>\n",
       "      <td>1505</td>\n",
       "      <td>1093</td>\n",
       "      <td>814</td>\n",
       "      <td>487</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-10-19T19:30:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-10-19T20:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>60</td>\n",
       "      <td>82</td>\n",
       "      <td>103</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-10-19T20:30:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>89</td>\n",
       "      <td>106</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-10-19T21:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>75</td>\n",
       "      <td>97</td>\n",
       "      <td>113</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-10-19T21:30:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "      <td>112</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction_date                  timestamp     1     2     3     4     5  \\\n",
       "0        2024-10-04  2024-10-03T22:00:00+00:00  1355   487   963  1544  1330   \n",
       "1        2024-10-04  2024-10-03T22:30:00+00:00   788   584  1148  1320  1007   \n",
       "2        2024-10-04  2024-10-03T23:00:00+00:00   571   748  1001  1460   740   \n",
       "3        2024-10-04  2024-10-03T23:30:00+00:00  1476  1194  1512   334  1054   \n",
       "4        2024-10-04  2024-10-04T00:00:00+00:00  1352  1390   912   662  1505   \n",
       "..              ...                        ...   ...   ...   ...   ...   ...   \n",
       "811      2024-10-19  2024-10-19T19:30:00+00:00     3     7    23    32    45   \n",
       "812      2024-10-19  2024-10-19T20:00:00+00:00     0    11    25    36    42   \n",
       "813      2024-10-19  2024-10-19T20:30:00+00:00     0    16    27    39    44   \n",
       "814      2024-10-19  2024-10-19T21:00:00+00:00     0    11    29    42    51   \n",
       "815      2024-10-19  2024-10-19T21:30:00+00:00     0    10    24    42    65   \n",
       "\n",
       "        6     7     8     9  \n",
       "0     867   326  1402  1357  \n",
       "1     565   923   797   487  \n",
       "2    1017  1533   597   991  \n",
       "3    1572   744  1497   463  \n",
       "4    1093   814   487  1340  \n",
       "..    ...   ...   ...   ...  \n",
       "811    57    77    93   125  \n",
       "812    60    82   103   132  \n",
       "813    64    89   106   140  \n",
       "814    75    97   113   151  \n",
       "815    80    97   112   143  \n",
       "\n",
       "[816 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrahiere Daten\n",
    "dataframe_list = []\n",
    "\n",
    "for entry in data:\n",
    "    prediction_date = entry['prediction_date']\n",
    "    \n",
    "    # Iteriere durch jedes 'submission' Element\n",
    "    for submission in entry['solution']['submission']:\n",
    "        timestamp = submission['timestamp']\n",
    "        probabilistic_forecast = submission['probabilistic_forecast']\n",
    "        \n",
    "        # Extrahiere die Werte von 'probabilistic_forecast' und füge sie der Liste hinzu\n",
    "        row = {\n",
    "            'prediction_date': prediction_date,\n",
    "            'timestamp': timestamp,\n",
    "            '1': probabilistic_forecast.get('10', None),\n",
    "            '2': probabilistic_forecast.get('20', None),\n",
    "            '3': probabilistic_forecast.get('30', None),\n",
    "            '4': probabilistic_forecast.get('40', None),\n",
    "            '5': probabilistic_forecast.get('50', None),\n",
    "            '6': probabilistic_forecast.get('60', None),\n",
    "            '7': probabilistic_forecast.get('70', None),\n",
    "            '8': probabilistic_forecast.get('80', None),\n",
    "            '9': probabilistic_forecast.get('90', None)\n",
    "        }\n",
    "        dataframe_list.append(row)\n",
    "\n",
    "# Erstelle DataFrame\n",
    "df_api_new = pd.DataFrame(dataframe_list)\n",
    "df_api_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>price_y</th>\n",
       "      <th>volume</th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_period</th>\n",
       "      <th>imbalance_price</th>\n",
       "      <th>day_ahead_price</th>\n",
       "      <th>market_price</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>cos_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2024-10-03 22:00:00+00:00</td>\n",
       "      <td>1355</td>\n",
       "      <td>487</td>\n",
       "      <td>963</td>\n",
       "      <td>1544</td>\n",
       "      <td>1330</td>\n",
       "      <td>867</td>\n",
       "      <td>326</td>\n",
       "      <td>1402</td>\n",
       "      <td>...</td>\n",
       "      <td>71.32</td>\n",
       "      <td>1322.45</td>\n",
       "      <td>2024-10-03 22:00:00+00:00</td>\n",
       "      <td>2024-10-03</td>\n",
       "      <td>47.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>78.47</td>\n",
       "      <td>71.32</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2024-10-03 22:30:00+00:00</td>\n",
       "      <td>788</td>\n",
       "      <td>584</td>\n",
       "      <td>1148</td>\n",
       "      <td>1320</td>\n",
       "      <td>1007</td>\n",
       "      <td>565</td>\n",
       "      <td>923</td>\n",
       "      <td>797</td>\n",
       "      <td>...</td>\n",
       "      <td>71.42</td>\n",
       "      <td>1035.65</td>\n",
       "      <td>2024-10-03 22:30:00+00:00</td>\n",
       "      <td>2024-10-03</td>\n",
       "      <td>48.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>78.47</td>\n",
       "      <td>71.42</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2024-10-03 23:00:00+00:00</td>\n",
       "      <td>571</td>\n",
       "      <td>748</td>\n",
       "      <td>1001</td>\n",
       "      <td>1460</td>\n",
       "      <td>740</td>\n",
       "      <td>1017</td>\n",
       "      <td>1533</td>\n",
       "      <td>597</td>\n",
       "      <td>...</td>\n",
       "      <td>66.94</td>\n",
       "      <td>1378.55</td>\n",
       "      <td>2024-10-03 23:00:00+00:00</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>71.36</td>\n",
       "      <td>66.94</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2024-10-03 23:30:00+00:00</td>\n",
       "      <td>1476</td>\n",
       "      <td>1194</td>\n",
       "      <td>1512</td>\n",
       "      <td>334</td>\n",
       "      <td>1054</td>\n",
       "      <td>1572</td>\n",
       "      <td>744</td>\n",
       "      <td>1497</td>\n",
       "      <td>...</td>\n",
       "      <td>60.03</td>\n",
       "      <td>1539.90</td>\n",
       "      <td>2024-10-03 23:30:00+00:00</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>71.36</td>\n",
       "      <td>60.03</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>2024-10-04 00:00:00+00:00</td>\n",
       "      <td>1352</td>\n",
       "      <td>1390</td>\n",
       "      <td>912</td>\n",
       "      <td>662</td>\n",
       "      <td>1505</td>\n",
       "      <td>1093</td>\n",
       "      <td>814</td>\n",
       "      <td>487</td>\n",
       "      <td>...</td>\n",
       "      <td>65.21</td>\n",
       "      <td>1818.40</td>\n",
       "      <td>2024-10-04 00:00:00+00:00</td>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>72.80</td>\n",
       "      <td>65.21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-10-19 19:30:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-10-19 20:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>60</td>\n",
       "      <td>82</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-10-19 20:30:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>89</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-10-19 21:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>75</td>\n",
       "      <td>97</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2024-10-19 21:30:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>823 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction_date                 timestamp     1     2     3     4     5  \\\n",
       "0        2024-10-04 2024-10-03 22:00:00+00:00  1355   487   963  1544  1330   \n",
       "1        2024-10-04 2024-10-03 22:30:00+00:00   788   584  1148  1320  1007   \n",
       "2        2024-10-04 2024-10-03 23:00:00+00:00   571   748  1001  1460   740   \n",
       "3        2024-10-04 2024-10-03 23:30:00+00:00  1476  1194  1512   334  1054   \n",
       "4        2024-10-04 2024-10-04 00:00:00+00:00  1352  1390   912   662  1505   \n",
       "..              ...                       ...   ...   ...   ...   ...   ...   \n",
       "818      2024-10-19 2024-10-19 19:30:00+00:00     3     7    23    32    45   \n",
       "819      2024-10-19 2024-10-19 20:00:00+00:00     0    11    25    36    42   \n",
       "820      2024-10-19 2024-10-19 20:30:00+00:00     0    16    27    39    44   \n",
       "821      2024-10-19 2024-10-19 21:00:00+00:00     0    11    29    42    51   \n",
       "822      2024-10-19 2024-10-19 21:30:00+00:00     0    10    24    42    65   \n",
       "\n",
       "        6     7     8  ...  price_y   volume             timestamp_utc  \\\n",
       "0     867   326  1402  ...    71.32  1322.45 2024-10-03 22:00:00+00:00   \n",
       "1     565   923   797  ...    71.42  1035.65 2024-10-03 22:30:00+00:00   \n",
       "2    1017  1533   597  ...    66.94  1378.55 2024-10-03 23:00:00+00:00   \n",
       "3    1572   744  1497  ...    60.03  1539.90 2024-10-03 23:30:00+00:00   \n",
       "4    1093   814   487  ...    65.21  1818.40 2024-10-04 00:00:00+00:00   \n",
       "..    ...   ...   ...  ...      ...      ...                       ...   \n",
       "818    57    77    93  ...      NaN      NaN                       NaT   \n",
       "819    60    82   103  ...      NaN      NaN                       NaT   \n",
       "820    64    89   106  ...      NaN      NaN                       NaT   \n",
       "821    75    97   113  ...      NaN      NaN                       NaT   \n",
       "822    80    97   112  ...      NaN      NaN                       NaT   \n",
       "\n",
       "     settlement_date  settlement_period imbalance_price day_ahead_price  \\\n",
       "0         2024-10-03               47.0            61.0           78.47   \n",
       "1         2024-10-03               48.0            50.0           78.47   \n",
       "2         2024-10-04                1.0            93.5           71.36   \n",
       "3         2024-10-04                2.0            93.5           71.36   \n",
       "4         2024-10-04                3.0            93.0           72.80   \n",
       "..               ...                ...             ...             ...   \n",
       "818              NaN                NaN             NaN             NaN   \n",
       "819              NaN                NaN             NaN             NaN   \n",
       "820              NaN                NaN             NaN             NaN   \n",
       "821              NaN                NaN             NaN             NaN   \n",
       "822              NaN                NaN             NaN             NaN   \n",
       "\n",
       "     market_price  cos_hour   cos_day  \n",
       "0           71.32  0.866025 -0.900969  \n",
       "1           71.42  0.866025 -0.900969  \n",
       "2           66.94  0.965926 -0.900969  \n",
       "3           60.03  0.965926 -0.900969  \n",
       "4           65.21  1.000000 -0.900969  \n",
       "..            ...       ...       ...  \n",
       "818           NaN  0.258819 -0.222521  \n",
       "819           NaN  0.500000 -0.222521  \n",
       "820           NaN  0.500000 -0.222521  \n",
       "821           NaN  0.707107 -0.222521  \n",
       "822           NaN  0.707107 -0.222521  \n",
       "\n",
       "[823 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new[\"timestamp\"] = pd.to_datetime(df_api_new[\"timestamp\"])\n",
    "df_day_ahead_price.timestamp_utc = pd.to_datetime(df_day_ahead_price.timestamp_utc)\n",
    "df_market_price.timestamp_utc = pd.to_datetime(df_market_price.timestamp_utc)\n",
    "df_imbalance_price.timestamp_utc = pd.to_datetime(df_imbalance_price.timestamp_utc)\n",
    "df_api_new_merged = pd.merge(df_api_new,df_day_ahead_price, left_on='timestamp', right_on='timestamp_utc', how='left')\n",
    "df_api_new_merged = pd.merge(df_api_new_merged,df_market_price, left_on='timestamp', right_on='timestamp_utc', how='left')\n",
    "df_api_new_merged = pd.merge(df_api_new_merged,df_imbalance_price, left_on='timestamp', right_on='timestamp_utc', how='left')\n",
    "df_api_new_merged[\"day_ahead_price\"] = df_api_new_merged[\"price_x\"].rename(\"day_ahead_price\")\n",
    "df_api_new_merged[\"market_price\"] = df_api_new_merged[\"price_y\"].rename(\"market_price\")\n",
    "df_api_new_merged[\"settlement_period\"] = df_api_new_merged[\"settlement_period_x\"].rename(\"settlement_period\")\n",
    "df_api_new_merged[\"cos_hour\"] = np.cos(2*np.pi*df_api_new_merged[\"timestamp\"].dt.hour/24)\n",
    "df_api_new_merged[\"cos_day\"] = np.cos(2*np.pi*df_api_new_merged[\"timestamp\"].dt.day/7)\n",
    "df_api_new_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>market_price</th>\n",
       "      <th>day_ahead_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>settlement_period</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>imbalance_price</th>\n",
       "      <th>market_price_lag96h</th>\n",
       "      <th>imbalance_price_lag96h</th>\n",
       "      <th>day_ahead_price_lag1week</th>\n",
       "      <th>volume_lag96h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2024-10-13 18:30:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>960</td>\n",
       "      <td>1020</td>\n",
       "      <td>1081</td>\n",
       "      <td>...</td>\n",
       "      <td>1201</td>\n",
       "      <td>1261</td>\n",
       "      <td>1322</td>\n",
       "      <td>1382</td>\n",
       "      <td>1443</td>\n",
       "      <td>159.00</td>\n",
       "      <td>61.97</td>\n",
       "      <td>94.00</td>\n",
       "      <td>78.47</td>\n",
       "      <td>2851.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2024-10-13 19:00:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>960</td>\n",
       "      <td>1021</td>\n",
       "      <td>1081</td>\n",
       "      <td>...</td>\n",
       "      <td>1201</td>\n",
       "      <td>1261</td>\n",
       "      <td>1321</td>\n",
       "      <td>1381</td>\n",
       "      <td>1441</td>\n",
       "      <td>159.00</td>\n",
       "      <td>55.09</td>\n",
       "      <td>55.09</td>\n",
       "      <td>78.47</td>\n",
       "      <td>2360.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2024-10-13 19:30:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>960</td>\n",
       "      <td>1021</td>\n",
       "      <td>1081</td>\n",
       "      <td>...</td>\n",
       "      <td>1201</td>\n",
       "      <td>1261</td>\n",
       "      <td>1321</td>\n",
       "      <td>1381</td>\n",
       "      <td>1441</td>\n",
       "      <td>159.00</td>\n",
       "      <td>74.08</td>\n",
       "      <td>93.45</td>\n",
       "      <td>71.36</td>\n",
       "      <td>861.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2024-10-13 20:00:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>66.77</td>\n",
       "      <td>90.00</td>\n",
       "      <td>71.36</td>\n",
       "      <td>1152.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2024-10-13 20:30:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>47.21</td>\n",
       "      <td>90.00</td>\n",
       "      <td>72.80</td>\n",
       "      <td>1095.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2024-10-15 19:30:00+00:00</td>\n",
       "      <td>88.67</td>\n",
       "      <td>80.72</td>\n",
       "      <td>2071.15</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>850</td>\n",
       "      <td>921</td>\n",
       "      <td>980</td>\n",
       "      <td>...</td>\n",
       "      <td>1060</td>\n",
       "      <td>1081</td>\n",
       "      <td>1104</td>\n",
       "      <td>1123</td>\n",
       "      <td>1142</td>\n",
       "      <td>105.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>159.00</td>\n",
       "      <td>82.15</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2024-10-15 20:00:00+00:00</td>\n",
       "      <td>83.31</td>\n",
       "      <td>64.10</td>\n",
       "      <td>1709.85</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>897</td>\n",
       "      <td>964</td>\n",
       "      <td>1010</td>\n",
       "      <td>...</td>\n",
       "      <td>1074</td>\n",
       "      <td>1097</td>\n",
       "      <td>1111</td>\n",
       "      <td>1129</td>\n",
       "      <td>1151</td>\n",
       "      <td>104.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>79.14</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2024-10-15 20:30:00+00:00</td>\n",
       "      <td>69.98</td>\n",
       "      <td>64.10</td>\n",
       "      <td>1551.30</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>910</td>\n",
       "      <td>984</td>\n",
       "      <td>1040</td>\n",
       "      <td>...</td>\n",
       "      <td>1101</td>\n",
       "      <td>1120</td>\n",
       "      <td>1122</td>\n",
       "      <td>1139</td>\n",
       "      <td>1154</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>79.14</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2024-10-15 21:00:00+00:00</td>\n",
       "      <td>69.82</td>\n",
       "      <td>28.87</td>\n",
       "      <td>1055.25</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>938</td>\n",
       "      <td>1034</td>\n",
       "      <td>1069</td>\n",
       "      <td>...</td>\n",
       "      <td>1124</td>\n",
       "      <td>1135</td>\n",
       "      <td>1139</td>\n",
       "      <td>1152</td>\n",
       "      <td>1164</td>\n",
       "      <td>33.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129.00</td>\n",
       "      <td>91.45</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2024-10-15 21:30:00+00:00</td>\n",
       "      <td>54.81</td>\n",
       "      <td>28.87</td>\n",
       "      <td>932.10</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>1048</td>\n",
       "      <td>1075</td>\n",
       "      <td>1105</td>\n",
       "      <td>...</td>\n",
       "      <td>1129</td>\n",
       "      <td>1144</td>\n",
       "      <td>1145</td>\n",
       "      <td>1156</td>\n",
       "      <td>1167</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.11</td>\n",
       "      <td>91.45</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp_utc  market_price  day_ahead_price   volume  \\\n",
       "336 2024-10-13 18:30:00+00:00          0.00           101.24     0.00   \n",
       "337 2024-10-13 19:00:00+00:00          0.00            89.62     0.00   \n",
       "338 2024-10-13 19:30:00+00:00          0.00            89.62     0.00   \n",
       "339 2024-10-13 20:00:00+00:00          0.00            84.30     0.00   \n",
       "340 2024-10-13 20:30:00+00:00          0.00            84.30     0.00   \n",
       "..                        ...           ...              ...      ...   \n",
       "530 2024-10-15 19:30:00+00:00         88.67            80.72  2071.15   \n",
       "531 2024-10-15 20:00:00+00:00         83.31            64.10  1709.85   \n",
       "532 2024-10-15 20:30:00+00:00         69.98            64.10  1551.30   \n",
       "533 2024-10-15 21:00:00+00:00         69.82            28.87  1055.25   \n",
       "534 2024-10-15 21:30:00+00:00         54.81            28.87   932.10   \n",
       "\n",
       "     settlement_period      cos_hour  cos_day     1     2     3  ...     5  \\\n",
       "336               40.0 -1.836970e-16  0.62349   960  1020  1081  ...  1201   \n",
       "337               41.0  2.588190e-01  0.62349   960  1021  1081  ...  1201   \n",
       "338               42.0  2.588190e-01  0.62349   960  1021  1081  ...  1201   \n",
       "339               43.0  5.000000e-01  0.62349     0     0     0  ...     0   \n",
       "340               44.0  5.000000e-01  0.62349     0     0     0  ...     0   \n",
       "..                 ...           ...      ...   ...   ...   ...  ...   ...   \n",
       "530               42.0  2.588190e-01  0.62349   850   921   980  ...  1060   \n",
       "531               43.0  5.000000e-01  0.62349   897   964  1010  ...  1074   \n",
       "532               44.0  5.000000e-01  0.62349   910   984  1040  ...  1101   \n",
       "533               45.0  7.071068e-01  0.62349   938  1034  1069  ...  1124   \n",
       "534               46.0  7.071068e-01  0.62349  1048  1075  1105  ...  1129   \n",
       "\n",
       "        6     7     8     9  imbalance_price  market_price_lag96h  \\\n",
       "336  1261  1322  1382  1443           159.00                61.97   \n",
       "337  1261  1321  1381  1441           159.00                55.09   \n",
       "338  1261  1321  1381  1441           159.00                74.08   \n",
       "339     0     0     0     0            70.00                66.77   \n",
       "340     0     0     0     0            70.00                47.21   \n",
       "..    ...   ...   ...   ...              ...                  ...   \n",
       "530  1081  1104  1123  1142           105.00                 0.00   \n",
       "531  1097  1111  1129  1151           104.90                 0.00   \n",
       "532  1120  1122  1139  1154            64.00                 0.00   \n",
       "533  1135  1139  1152  1164            33.77                 0.00   \n",
       "534  1144  1145  1156  1167             0.00                 0.00   \n",
       "\n",
       "     imbalance_price_lag96h  day_ahead_price_lag1week  volume_lag96h  \n",
       "336                   94.00                     78.47        2851.35  \n",
       "337                   55.09                     78.47        2360.40  \n",
       "338                   93.45                     71.36         861.85  \n",
       "339                   90.00                     71.36        1152.85  \n",
       "340                   90.00                     72.80        1095.30  \n",
       "..                      ...                       ...            ...  \n",
       "530                  159.00                     82.15           0.00  \n",
       "531                   70.00                     79.14           0.00  \n",
       "532                   70.00                     79.14           0.00  \n",
       "533                  129.00                     91.45           0.00  \n",
       "534                   70.11                     91.45           0.00  \n",
       "\n",
       "[198 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_new_merged1 = df_api_new_merged[[\"timestamp_utc\",\"market_price\",\"day_ahead_price\",\"volume\",\"settlement_period\",\"cos_hour\",\"cos_day\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"imbalance_price\"]].copy()\n",
    "df_api_new_merged1.loc[:,\"market_price_lag96h\"] = df_api_new_merged1[\"market_price\"].shift(192)\n",
    "df_api_new_merged1.loc[:,\"imbalance_price_lag96h\"] = df_api_new_merged1[\"imbalance_price\"].shift(192)\n",
    "df_api_new_merged1.loc[:,\"day_ahead_price_lag1week\"] = df_api_new_merged1[\"day_ahead_price\"].shift(336)\n",
    "df_api_new_merged1.loc[:,\"volume_lag96h\"] = df_api_new_merged1[\"volume\"].shift(192)\n",
    "df_api_new_merged1.dropna(inplace=True)\n",
    "df_api_new_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_new_merged1 = df_api_new_merged1.groupby(\"timestamp_utc\").last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([103, 15])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_api_new_merged1[[\"market_price_lag96h\",\"imbalance_price_lag96h\",\"day_ahead_price_lag1week\",\"volume_lag96h\",\n",
    "                    \"cos_hour\",\"cos_day\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]].values\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "X_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = X_test_tensor.unsqueeze(1)  # Adds a sequence length dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>market_price</th>\n",
       "      <th>day_ahead_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>settlement_period</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>imbalance_price</th>\n",
       "      <th>market_price_lag96h</th>\n",
       "      <th>imbalance_price_lag96h</th>\n",
       "      <th>day_ahead_price_lag1week</th>\n",
       "      <th>volume_lag96h</th>\n",
       "      <th>imbalance_price_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-13 18:30:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>960</td>\n",
       "      <td>1020</td>\n",
       "      <td>1081</td>\n",
       "      <td>...</td>\n",
       "      <td>1261</td>\n",
       "      <td>1322</td>\n",
       "      <td>1382</td>\n",
       "      <td>1443</td>\n",
       "      <td>159.00</td>\n",
       "      <td>61.97</td>\n",
       "      <td>94.00</td>\n",
       "      <td>78.47</td>\n",
       "      <td>2851.35</td>\n",
       "      <td>66.798347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-13 19:00:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>960</td>\n",
       "      <td>1021</td>\n",
       "      <td>1081</td>\n",
       "      <td>...</td>\n",
       "      <td>1261</td>\n",
       "      <td>1321</td>\n",
       "      <td>1381</td>\n",
       "      <td>1441</td>\n",
       "      <td>159.00</td>\n",
       "      <td>55.09</td>\n",
       "      <td>55.09</td>\n",
       "      <td>78.47</td>\n",
       "      <td>2360.40</td>\n",
       "      <td>68.725052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-13 19:30:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>960</td>\n",
       "      <td>1021</td>\n",
       "      <td>1081</td>\n",
       "      <td>...</td>\n",
       "      <td>1261</td>\n",
       "      <td>1321</td>\n",
       "      <td>1381</td>\n",
       "      <td>1441</td>\n",
       "      <td>159.00</td>\n",
       "      <td>74.08</td>\n",
       "      <td>93.45</td>\n",
       "      <td>71.36</td>\n",
       "      <td>861.85</td>\n",
       "      <td>91.374313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-13 20:00:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>66.77</td>\n",
       "      <td>90.00</td>\n",
       "      <td>71.36</td>\n",
       "      <td>1152.85</td>\n",
       "      <td>76.828766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-13 20:30:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>47.21</td>\n",
       "      <td>90.00</td>\n",
       "      <td>72.80</td>\n",
       "      <td>1095.30</td>\n",
       "      <td>70.860718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2024-10-15 19:30:00+00:00</td>\n",
       "      <td>88.67</td>\n",
       "      <td>80.72</td>\n",
       "      <td>2071.15</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>850</td>\n",
       "      <td>921</td>\n",
       "      <td>980</td>\n",
       "      <td>...</td>\n",
       "      <td>1081</td>\n",
       "      <td>1104</td>\n",
       "      <td>1123</td>\n",
       "      <td>1142</td>\n",
       "      <td>105.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>159.00</td>\n",
       "      <td>82.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>105.983086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2024-10-15 20:00:00+00:00</td>\n",
       "      <td>83.31</td>\n",
       "      <td>64.10</td>\n",
       "      <td>1709.85</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>897</td>\n",
       "      <td>964</td>\n",
       "      <td>1010</td>\n",
       "      <td>...</td>\n",
       "      <td>1097</td>\n",
       "      <td>1111</td>\n",
       "      <td>1129</td>\n",
       "      <td>1151</td>\n",
       "      <td>104.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>79.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>88.226570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2024-10-15 20:30:00+00:00</td>\n",
       "      <td>69.98</td>\n",
       "      <td>64.10</td>\n",
       "      <td>1551.30</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>910</td>\n",
       "      <td>984</td>\n",
       "      <td>1040</td>\n",
       "      <td>...</td>\n",
       "      <td>1120</td>\n",
       "      <td>1122</td>\n",
       "      <td>1139</td>\n",
       "      <td>1154</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>79.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.353539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2024-10-15 21:00:00+00:00</td>\n",
       "      <td>69.82</td>\n",
       "      <td>28.87</td>\n",
       "      <td>1055.25</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>938</td>\n",
       "      <td>1034</td>\n",
       "      <td>1069</td>\n",
       "      <td>...</td>\n",
       "      <td>1135</td>\n",
       "      <td>1139</td>\n",
       "      <td>1152</td>\n",
       "      <td>1164</td>\n",
       "      <td>33.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129.00</td>\n",
       "      <td>91.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>92.058922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2024-10-15 21:30:00+00:00</td>\n",
       "      <td>54.81</td>\n",
       "      <td>28.87</td>\n",
       "      <td>932.10</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>1048</td>\n",
       "      <td>1075</td>\n",
       "      <td>1105</td>\n",
       "      <td>...</td>\n",
       "      <td>1144</td>\n",
       "      <td>1145</td>\n",
       "      <td>1156</td>\n",
       "      <td>1167</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.11</td>\n",
       "      <td>91.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.375885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp_utc  market_price  day_ahead_price   volume  \\\n",
       "0   2024-10-13 18:30:00+00:00          0.00           101.24     0.00   \n",
       "1   2024-10-13 19:00:00+00:00          0.00            89.62     0.00   \n",
       "2   2024-10-13 19:30:00+00:00          0.00            89.62     0.00   \n",
       "3   2024-10-13 20:00:00+00:00          0.00            84.30     0.00   \n",
       "4   2024-10-13 20:30:00+00:00          0.00            84.30     0.00   \n",
       "..                        ...           ...              ...      ...   \n",
       "98  2024-10-15 19:30:00+00:00         88.67            80.72  2071.15   \n",
       "99  2024-10-15 20:00:00+00:00         83.31            64.10  1709.85   \n",
       "100 2024-10-15 20:30:00+00:00         69.98            64.10  1551.30   \n",
       "101 2024-10-15 21:00:00+00:00         69.82            28.87  1055.25   \n",
       "102 2024-10-15 21:30:00+00:00         54.81            28.87   932.10   \n",
       "\n",
       "     settlement_period      cos_hour  cos_day     1     2     3  ...     6  \\\n",
       "0                 40.0 -1.836970e-16  0.62349   960  1020  1081  ...  1261   \n",
       "1                 41.0  2.588190e-01  0.62349   960  1021  1081  ...  1261   \n",
       "2                 42.0  2.588190e-01  0.62349   960  1021  1081  ...  1261   \n",
       "3                 43.0  5.000000e-01  0.62349     0     0     0  ...     0   \n",
       "4                 44.0  5.000000e-01  0.62349     0     0     0  ...     0   \n",
       "..                 ...           ...      ...   ...   ...   ...  ...   ...   \n",
       "98                42.0  2.588190e-01  0.62349   850   921   980  ...  1081   \n",
       "99                43.0  5.000000e-01  0.62349   897   964  1010  ...  1097   \n",
       "100               44.0  5.000000e-01  0.62349   910   984  1040  ...  1120   \n",
       "101               45.0  7.071068e-01  0.62349   938  1034  1069  ...  1135   \n",
       "102               46.0  7.071068e-01  0.62349  1048  1075  1105  ...  1144   \n",
       "\n",
       "        7     8     9  imbalance_price  market_price_lag96h  \\\n",
       "0    1322  1382  1443           159.00                61.97   \n",
       "1    1321  1381  1441           159.00                55.09   \n",
       "2    1321  1381  1441           159.00                74.08   \n",
       "3       0     0     0            70.00                66.77   \n",
       "4       0     0     0            70.00                47.21   \n",
       "..    ...   ...   ...              ...                  ...   \n",
       "98   1104  1123  1142           105.00                 0.00   \n",
       "99   1111  1129  1151           104.90                 0.00   \n",
       "100  1122  1139  1154            64.00                 0.00   \n",
       "101  1139  1152  1164            33.77                 0.00   \n",
       "102  1145  1156  1167             0.00                 0.00   \n",
       "\n",
       "     imbalance_price_lag96h  day_ahead_price_lag1week  volume_lag96h  \\\n",
       "0                     94.00                     78.47        2851.35   \n",
       "1                     55.09                     78.47        2360.40   \n",
       "2                     93.45                     71.36         861.85   \n",
       "3                     90.00                     71.36        1152.85   \n",
       "4                     90.00                     72.80        1095.30   \n",
       "..                      ...                       ...            ...   \n",
       "98                   159.00                     82.15           0.00   \n",
       "99                    70.00                     79.14           0.00   \n",
       "100                   70.00                     79.14           0.00   \n",
       "101                  129.00                     91.45           0.00   \n",
       "102                   70.11                     91.45           0.00   \n",
       "\n",
       "     imbalance_price_predictions  \n",
       "0                      66.798347  \n",
       "1                      68.725052  \n",
       "2                      91.374313  \n",
       "3                      76.828766  \n",
       "4                      70.860718  \n",
       "..                           ...  \n",
       "98                    105.983086  \n",
       "99                     88.226570  \n",
       "100                    87.353539  \n",
       "101                    92.058922  \n",
       "102                    84.375885  \n",
       "\n",
       "[103 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_test_outputs = model(X_test_tensor)\n",
    "    final_test_outputs = final_test_outputs.numpy().flatten()\n",
    "\n",
    "df_api_new_merged1[\"imbalance_price_predictions\"] = final_test_outputs\n",
    "df_api_new_merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Imbalance Price",
         "type": "scatter",
         "x": [
          "2024-10-13T18:30:00+00:00",
          "2024-10-13T19:00:00+00:00",
          "2024-10-13T19:30:00+00:00",
          "2024-10-13T20:00:00+00:00",
          "2024-10-13T20:30:00+00:00",
          "2024-10-13T21:00:00+00:00",
          "2024-10-13T21:30:00+00:00",
          "2024-10-13T22:00:00+00:00",
          "2024-10-13T22:30:00+00:00",
          "2024-10-13T23:00:00+00:00",
          "2024-10-13T23:30:00+00:00",
          "2024-10-14T00:00:00+00:00",
          "2024-10-14T00:30:00+00:00",
          "2024-10-14T01:00:00+00:00",
          "2024-10-14T01:30:00+00:00",
          "2024-10-14T02:00:00+00:00",
          "2024-10-14T02:30:00+00:00",
          "2024-10-14T03:00:00+00:00",
          "2024-10-14T03:30:00+00:00",
          "2024-10-14T04:00:00+00:00",
          "2024-10-14T04:30:00+00:00",
          "2024-10-14T05:00:00+00:00",
          "2024-10-14T05:30:00+00:00",
          "2024-10-14T06:00:00+00:00",
          "2024-10-14T06:30:00+00:00",
          "2024-10-14T07:00:00+00:00",
          "2024-10-14T07:30:00+00:00",
          "2024-10-14T08:00:00+00:00",
          "2024-10-14T08:30:00+00:00",
          "2024-10-14T09:00:00+00:00",
          "2024-10-14T09:30:00+00:00",
          "2024-10-14T10:00:00+00:00",
          "2024-10-14T10:30:00+00:00",
          "2024-10-14T11:00:00+00:00",
          "2024-10-14T11:30:00+00:00",
          "2024-10-14T12:00:00+00:00",
          "2024-10-14T12:30:00+00:00",
          "2024-10-14T13:00:00+00:00",
          "2024-10-14T13:30:00+00:00",
          "2024-10-14T14:00:00+00:00",
          "2024-10-14T14:30:00+00:00",
          "2024-10-14T15:00:00+00:00",
          "2024-10-14T15:30:00+00:00",
          "2024-10-14T16:00:00+00:00",
          "2024-10-14T16:30:00+00:00",
          "2024-10-14T17:00:00+00:00",
          "2024-10-14T17:30:00+00:00",
          "2024-10-14T18:00:00+00:00",
          "2024-10-14T18:30:00+00:00",
          "2024-10-14T19:00:00+00:00",
          "2024-10-14T19:30:00+00:00",
          "2024-10-14T20:00:00+00:00",
          "2024-10-14T20:30:00+00:00",
          "2024-10-14T21:00:00+00:00",
          "2024-10-14T21:30:00+00:00",
          "2024-10-14T22:00:00+00:00",
          "2024-10-14T22:30:00+00:00",
          "2024-10-14T23:00:00+00:00",
          "2024-10-14T23:30:00+00:00",
          "2024-10-15T00:00:00+00:00",
          "2024-10-15T00:30:00+00:00",
          "2024-10-15T01:00:00+00:00",
          "2024-10-15T01:30:00+00:00",
          "2024-10-15T02:00:00+00:00",
          "2024-10-15T02:30:00+00:00",
          "2024-10-15T03:00:00+00:00",
          "2024-10-15T03:30:00+00:00",
          "2024-10-15T04:00:00+00:00",
          "2024-10-15T04:30:00+00:00",
          "2024-10-15T05:00:00+00:00",
          "2024-10-15T05:30:00+00:00",
          "2024-10-15T06:00:00+00:00",
          "2024-10-15T06:30:00+00:00",
          "2024-10-15T07:00:00+00:00",
          "2024-10-15T07:30:00+00:00",
          "2024-10-15T08:00:00+00:00",
          "2024-10-15T08:30:00+00:00",
          "2024-10-15T09:00:00+00:00",
          "2024-10-15T09:30:00+00:00",
          "2024-10-15T10:00:00+00:00",
          "2024-10-15T10:30:00+00:00",
          "2024-10-15T11:00:00+00:00",
          "2024-10-15T11:30:00+00:00",
          "2024-10-15T12:00:00+00:00",
          "2024-10-15T12:30:00+00:00",
          "2024-10-15T13:00:00+00:00",
          "2024-10-15T13:30:00+00:00",
          "2024-10-15T14:00:00+00:00",
          "2024-10-15T14:30:00+00:00",
          "2024-10-15T15:00:00+00:00",
          "2024-10-15T15:30:00+00:00",
          "2024-10-15T16:00:00+00:00",
          "2024-10-15T16:30:00+00:00",
          "2024-10-15T17:00:00+00:00",
          "2024-10-15T17:30:00+00:00",
          "2024-10-15T18:00:00+00:00",
          "2024-10-15T18:30:00+00:00",
          "2024-10-15T19:00:00+00:00",
          "2024-10-15T19:30:00+00:00",
          "2024-10-15T20:00:00+00:00",
          "2024-10-15T20:30:00+00:00",
          "2024-10-15T21:00:00+00:00",
          "2024-10-15T21:30:00+00:00"
         ],
         "y": [
          159,
          159,
          159,
          70,
          70,
          129,
          70.11,
          70.12,
          70.12,
          67.02,
          89.89,
          89.89,
          0,
          0,
          0,
          0,
          110,
          67.86,
          109,
          66,
          66,
          70.13,
          98,
          114.9,
          133,
          125,
          120,
          120,
          129,
          135.2,
          135,
          130,
          134.2,
          136.7,
          136.07063001725848,
          130,
          134.72516025641025,
          126.97772061426318,
          137.8,
          129.88,
          91.66308842531662,
          251.94,
          309.06,
          669.212,
          662,
          662,
          659.35,
          102.5,
          95.05,
          124.98,
          124.71,
          74.72,
          74.72,
          102,
          102,
          73.95,
          70.15,
          70.15,
          72,
          72.01,
          72.01,
          70.2,
          70.15,
          70.15,
          64.1,
          70.16,
          64,
          70.16,
          72.3,
          126.5,
          126.5,
          129,
          129.62,
          120,
          120,
          71.1,
          110,
          110,
          109.5,
          84.54,
          84.7,
          85.97,
          82.31,
          95,
          95,
          94,
          94,
          91.36,
          108,
          109,
          109,
          110.99778328928572,
          115,
          116.000099960016,
          115,
          102,
          85,
          104.9,
          105,
          104.9,
          64,
          33.77,
          0
         ]
        },
        {
         "mode": "lines",
         "name": "Imbalance Price Predictions",
         "type": "scatter",
         "x": [
          "2024-10-13T18:30:00+00:00",
          "2024-10-13T19:00:00+00:00",
          "2024-10-13T19:30:00+00:00",
          "2024-10-13T20:00:00+00:00",
          "2024-10-13T20:30:00+00:00",
          "2024-10-13T21:00:00+00:00",
          "2024-10-13T21:30:00+00:00",
          "2024-10-13T22:00:00+00:00",
          "2024-10-13T22:30:00+00:00",
          "2024-10-13T23:00:00+00:00",
          "2024-10-13T23:30:00+00:00",
          "2024-10-14T00:00:00+00:00",
          "2024-10-14T00:30:00+00:00",
          "2024-10-14T01:00:00+00:00",
          "2024-10-14T01:30:00+00:00",
          "2024-10-14T02:00:00+00:00",
          "2024-10-14T02:30:00+00:00",
          "2024-10-14T03:00:00+00:00",
          "2024-10-14T03:30:00+00:00",
          "2024-10-14T04:00:00+00:00",
          "2024-10-14T04:30:00+00:00",
          "2024-10-14T05:00:00+00:00",
          "2024-10-14T05:30:00+00:00",
          "2024-10-14T06:00:00+00:00",
          "2024-10-14T06:30:00+00:00",
          "2024-10-14T07:00:00+00:00",
          "2024-10-14T07:30:00+00:00",
          "2024-10-14T08:00:00+00:00",
          "2024-10-14T08:30:00+00:00",
          "2024-10-14T09:00:00+00:00",
          "2024-10-14T09:30:00+00:00",
          "2024-10-14T10:00:00+00:00",
          "2024-10-14T10:30:00+00:00",
          "2024-10-14T11:00:00+00:00",
          "2024-10-14T11:30:00+00:00",
          "2024-10-14T12:00:00+00:00",
          "2024-10-14T12:30:00+00:00",
          "2024-10-14T13:00:00+00:00",
          "2024-10-14T13:30:00+00:00",
          "2024-10-14T14:00:00+00:00",
          "2024-10-14T14:30:00+00:00",
          "2024-10-14T15:00:00+00:00",
          "2024-10-14T15:30:00+00:00",
          "2024-10-14T16:00:00+00:00",
          "2024-10-14T16:30:00+00:00",
          "2024-10-14T17:00:00+00:00",
          "2024-10-14T17:30:00+00:00",
          "2024-10-14T18:00:00+00:00",
          "2024-10-14T18:30:00+00:00",
          "2024-10-14T19:00:00+00:00",
          "2024-10-14T19:30:00+00:00",
          "2024-10-14T20:00:00+00:00",
          "2024-10-14T20:30:00+00:00",
          "2024-10-14T21:00:00+00:00",
          "2024-10-14T21:30:00+00:00",
          "2024-10-14T22:00:00+00:00",
          "2024-10-14T22:30:00+00:00",
          "2024-10-14T23:00:00+00:00",
          "2024-10-14T23:30:00+00:00",
          "2024-10-15T00:00:00+00:00",
          "2024-10-15T00:30:00+00:00",
          "2024-10-15T01:00:00+00:00",
          "2024-10-15T01:30:00+00:00",
          "2024-10-15T02:00:00+00:00",
          "2024-10-15T02:30:00+00:00",
          "2024-10-15T03:00:00+00:00",
          "2024-10-15T03:30:00+00:00",
          "2024-10-15T04:00:00+00:00",
          "2024-10-15T04:30:00+00:00",
          "2024-10-15T05:00:00+00:00",
          "2024-10-15T05:30:00+00:00",
          "2024-10-15T06:00:00+00:00",
          "2024-10-15T06:30:00+00:00",
          "2024-10-15T07:00:00+00:00",
          "2024-10-15T07:30:00+00:00",
          "2024-10-15T08:00:00+00:00",
          "2024-10-15T08:30:00+00:00",
          "2024-10-15T09:00:00+00:00",
          "2024-10-15T09:30:00+00:00",
          "2024-10-15T10:00:00+00:00",
          "2024-10-15T10:30:00+00:00",
          "2024-10-15T11:00:00+00:00",
          "2024-10-15T11:30:00+00:00",
          "2024-10-15T12:00:00+00:00",
          "2024-10-15T12:30:00+00:00",
          "2024-10-15T13:00:00+00:00",
          "2024-10-15T13:30:00+00:00",
          "2024-10-15T14:00:00+00:00",
          "2024-10-15T14:30:00+00:00",
          "2024-10-15T15:00:00+00:00",
          "2024-10-15T15:30:00+00:00",
          "2024-10-15T16:00:00+00:00",
          "2024-10-15T16:30:00+00:00",
          "2024-10-15T17:00:00+00:00",
          "2024-10-15T17:30:00+00:00",
          "2024-10-15T18:00:00+00:00",
          "2024-10-15T18:30:00+00:00",
          "2024-10-15T19:00:00+00:00",
          "2024-10-15T19:30:00+00:00",
          "2024-10-15T20:00:00+00:00",
          "2024-10-15T20:30:00+00:00",
          "2024-10-15T21:00:00+00:00",
          "2024-10-15T21:30:00+00:00"
         ],
         "y": [
          66.79834747314453,
          68.72505187988281,
          91.37431335449219,
          76.82876586914062,
          70.8607177734375,
          61.57890701293945,
          68.64640045166016,
          74.08094787597656,
          79.81919860839844,
          82.86605834960938,
          83.53715515136719,
          103.05518341064453,
          101.46893310546875,
          110.17554473876953,
          107.96324157714844,
          101.89811706542969,
          100.61724853515625,
          101.21296691894531,
          90.15623474121094,
          86.10334777832031,
          81.80933380126953,
          76.70952606201172,
          77.18256378173828,
          73.43229675292969,
          76.78091430664062,
          70.29177856445312,
          72.40412902832031,
          70.87054443359375,
          69.85564422607422,
          79.0970230102539,
          99.99444580078125,
          82.50707244873047,
          76.38926696777344,
          67.8020248413086,
          93.3311767578125,
          60.740692138671875,
          81.22856140136719,
          27.646678924560547,
          33.91017532348633,
          34.37294006347656,
          30.621227264404297,
          48.97237014770508,
          54.0721435546875,
          59.75447463989258,
          73.90493774414062,
          75.32471466064453,
          59.494449615478516,
          74.34922790527344,
          72.46536254882812,
          57.83574676513672,
          48.51819610595703,
          49.90354537963867,
          48.917659759521484,
          50.74732971191406,
          48.375877380371094,
          61.93531799316406,
          55.487335205078125,
          47.40251922607422,
          49.36736297607422,
          44.15363693237305,
          42.20060729980469,
          40.6805534362793,
          36.68507766723633,
          35.550743103027344,
          31.060707092285156,
          37.59397506713867,
          48.539268493652344,
          66.22937774658203,
          73.77042388916016,
          85.92732238769531,
          89.6240234375,
          121.02883911132812,
          133.684814453125,
          145.93203735351562,
          122.12065124511719,
          113.93429565429688,
          104.6772689819336,
          102.82505798339844,
          100.21907806396484,
          100.9600830078125,
          97.37849426269531,
          98.60077667236328,
          98.37295532226562,
          97.74978637695312,
          98.33190155029297,
          98.12347412109375,
          103.8821792602539,
          110.5067367553711,
          115.05915832519531,
          119.50553894042969,
          122.23762512207031,
          131.0633544921875,
          133.32965087890625,
          128.8751983642578,
          130.1708526611328,
          116.79032135009766,
          113.93255615234375,
          105.21220397949219,
          105.98308563232422,
          88.22657012939453,
          87.3535385131836,
          92.05892181396484,
          84.37588500976562
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Imbalance Price and Predictions"
        },
        "xaxis": {
         "title": {
          "text": "Timestamp"
         }
        },
        "yaxis": {
         "title": {
          "text": "Imbalance Price"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot imbalance price and predictions\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_api_new_merged1[\"timestamp_utc\"], y=df_api_new_merged1[\"imbalance_price\"], mode='lines', name='Imbalance Price'))\n",
    "fig.add_trace(go.Scatter(x=df_api_new_merged1[\"timestamp_utc\"], y=df_api_new_merged1[\"imbalance_price_predictions\"], mode='lines', name='Imbalance Price Predictions'))\n",
    "fig.update_layout(title='Imbalance Price and Predictions', xaxis_title='Timestamp', yaxis_title='Imbalance Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for imbalance price predictions: 59.5189\n"
     ]
    }
   ],
   "source": [
    "#MAE calculation for imbalance price predictions\n",
    "mae = np.mean(np.abs(df_api_new_merged1[\"imbalance_price\"] - df_api_new_merged1[\"imbalance_price_predictions\"]))\n",
    "print(f\"MAE for imbalance price predictions: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict for the whole dataset\n",
    "X = df_bbidding1[[\"market_price_lag96h\",\"imbalance_price_lag96h\",\"day_ahead_price_lag1week\",\"volume_lag96h\",\n",
    "                  \"cos_hour\",\"cos_day\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]].values\n",
    "X = scaler.transform(X)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "X_tensor = X_tensor.unsqueeze(1)  # Adds a sequence length\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_outputs = model(X_tensor)\n",
    "    final_outputs = final_outputs.numpy().flatten()\n",
    "\n",
    "df_bbidding1[\"imbalance_price_predictions\"] = final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbidding1.to_csv('bidding_training_predictions_imbalance_price.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HEFTcom24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
