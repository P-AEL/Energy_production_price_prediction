{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind = pd.read_csv(f'{os.getcwd()}\\..\\data\\wind.csv', index_col=0)\n",
    "\n",
    "df_wind = df_wind.drop(columns=['SS_Price', 'boa_MWh', 'DA_Price', 'Wind_MWh_credit', 'Solar_MWh_credit', 'Solar_MW', 'Solar_capacity_mwp', 'Solar_installedcapacity_mwp', 'dtm'])\n",
    "df_wind['reference_time'] = pd.to_datetime(df_wind['reference_time'])\n",
    "df_wind['valid_time'] = pd.to_datetime(df_wind['valid_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.44444954)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wind['WindDirection:100_dwd'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_time 2020-09-20 01:30:00+00:00 2024-05-19 23:30:00+00:00\n",
      "reference_time 2020-09-20 00:00:00+00:00 2024-05-19 00:00:00+00:00\n",
      "RelativeHumidity_dwd 48.529324 100.00052\n",
      "Temperature_dwd -0.3765937 21.303053\n",
      "WindDirection_dwd 0.74073195 359.36404\n",
      "WindDirection:100_dwd 0.44444954 359.36792\n",
      "WindSpeed_dwd 0.18528552 26.82034\n",
      "WindSpeed:100_dwd 0.15628327 35.885605\n",
      "RelativeHumidity_ncep 43.966667 100.0\n",
      "Temperature_ncep -0.5038011 21.28925\n",
      "WindDirection_ncep 0.59209526 359.38287\n",
      "WindDirection:100_ncep 0.5916104 359.3482\n",
      "WindSpeed_ncep 0.15772003 27.78529\n",
      "WindSpeed:100_ncep 0.20670801 35.430717\n",
      "MIP -77.29 1983.66\n",
      "Wind_MW 0.0 1192.744\n",
      "sin_WindDirection_dwd -0.9999999999978068 0.999999999982805\n",
      "cos_WindDirection_dwd -0.9999999999862922 0.999938400117741\n",
      "sin_WindDirection_ncep -0.9999999999950652 0.9999999999950652\n",
      "cos_WindDirection_ncep -0.9999999999978068 0.9999466045755288\n",
      "WindSpeed_dwd_lag_1 0.18528552 26.82034\n",
      "Temperature_dwd_lag_1 -0.3765937 21.303053\n",
      "RelativeHumidity_dwd_lag_1 48.529324 100.00052\n",
      "wind_speed_diff -18.666356299999997 13.8533022\n",
      "temperature_diff -4.6028581 7.982538\n",
      "wind_temp_interaction -4.1878266370486 351.102823156751\n",
      "humidity_wind_interaction 16.5393507443976 2077.5405420308603\n",
      "WindSpeed_dwd_rolling_mean_1h 0.19948086499996004 26.36429899999993\n",
      "Temperature_dwd_rolling_std_2h 2.5736742955283055e-05 4.196899335191173\n"
     ]
    }
   ],
   "source": [
    "for col in df_wind.columns:\n",
    "    print(col, df_wind[col].min(), df_wind[col].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cyclical encoding for wind direction\n",
    "df_wind['sin_WindDirection_dwd'] = np.sin(df_wind['WindDirection_dwd'] * np.pi / 180)\n",
    "df_wind['cos_WindDirection_dwd'] = np.cos(df_wind['WindDirection_dwd'] * np.pi / 180)\n",
    "df_wind['sin_WindDirection_ncep'] = np.sin(df_wind['WindDirection_ncep'] * np.pi / 180)\n",
    "df_wind['cos_WindDirection_ncep'] = np.cos(df_wind['WindDirection_ncep'] * np.pi / 180)\n",
    "\n",
    "# Lag features (e.g., 1 time step in the past, assuming 30-minute intervals)\n",
    "df_wind['WindSpeed_dwd_lag_1'] = df_wind['WindSpeed_dwd'].shift(1)\n",
    "df_wind['Temperature_dwd_lag_1'] = df_wind['Temperature_dwd'].shift(1)\n",
    "df_wind['RelativeHumidity_dwd_lag_1'] = df_wind['RelativeHumidity_dwd'].shift(1)\n",
    "\n",
    "# Difference features\n",
    "df_wind['wind_speed_diff'] = df_wind['WindSpeed_dwd'] - df_wind['WindSpeed_ncep']\n",
    "df_wind['temperature_diff'] = df_wind['Temperature_dwd'] - df_wind['Temperature_ncep']\n",
    "\n",
    "# Interaction features\n",
    "df_wind['wind_temp_interaction'] = df_wind['WindSpeed_dwd'] * df_wind['Temperature_dwd']\n",
    "df_wind['humidity_wind_interaction'] = df_wind['WindSpeed_dwd'] * df_wind['RelativeHumidity_dwd']\n",
    "\n",
    "# Rolling window features (e.g., rolling mean over 1 hour, 2 intervals for 30-minute steps)\n",
    "df_wind['WindSpeed_dwd_rolling_mean_1h'] = df_wind['WindSpeed_dwd'].rolling(window=2).mean()\n",
    "df_wind['Temperature_dwd_rolling_std_2h'] = df_wind['Temperature_dwd'].rolling(window=4).std()\n",
    "\n",
    "# Drop rows with NaN values introduced by lagging or rolling (optional)\n",
    "df_wind = df_wind.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclical encoding for wind direction\n",
    "\n",
    "# Average WindDirection\n",
    "df_wind['WindDirection_avg'] = (df_wind['WindDirection_dwd'] + df_wind['WindDirection_ncep']) / 2\n",
    "df_wind['WindDirection_100_avg'] =(df_wind['WindDirection:100_dwd'] + df_wind['WindDirection:100_ncep']) / 2\n",
    "df_wind['sin_WindDirection_avg'] = np.sin(df_wind['WindDirection_avg'] * np.pi / 180)\n",
    "df_wind['cos_WindDirection_avg'] = np.cos(df_wind['WindDirection_avg'] * np.pi / 180)\n",
    "df_wind = df_wind.drop(columns=['WindDirection_dwd', 'WindDirection_ncep', 'WindDirection:100_dwd', 'WindDirection:100_ncep', 'WindDirection_avg', 'WindDirection_100_avg'])\n",
    "\n",
    "# Average WindSpeed, Temperature, and RelativeHumidity, Lag features\n",
    "df_wind['WindSpeed_avg'] = (df_wind['WindSpeed_dwd'] + df_wind['WindSpeed_ncep']) / 2\n",
    "df_wind['Temperature_avg'] = (df_wind['Temperature_dwd'] + df_wind['Temperature_ncep']) / 2\n",
    "df_wind['RelativeHumidity_avg'] = (df_wind['RelativeHumidity_dwd'] + df_wind['RelativeHumidity_ncep']) / 2\n",
    "df_wind['WindSpeed_avg_lag_1'] = df_wind['WindSpeed_avg'].shift(1)\n",
    "df_wind['WindSpeed_avg_lag_2'] = df_wind['WindSpeed_avg'].shift(2) \n",
    "# df_wind['WindSpeed_avg_lag_1_diff'] = df_wind['WindSpeed_avg'].shift(1) - df_wind['WindSpeed_avg']\n",
    "# df_wind['WindSpeed_avg_lag_2_diff'] = df_wind['WindSpeed_avg'].shift(2) - df_wind['WindSpeed_avg']\n",
    "df_wind['Temperature_avg_lag_1'] = df_wind['Temperature_avg'].shift(1)\n",
    "df_wind['Temperature_avg_lag_2'] = df_wind['Temperature_avg'].shift(2)\n",
    "# df_wind['Temperature_avg_lag_1_diff'] = df_wind['Temperature_avg'].shift(1) - df_wind['Temperature_avg']\n",
    "# df_wind['Temperature_avg_lag_2_diff'] = df_wind['Temperature_avg'].shift(2) - df_wind['Temperature_avg']\n",
    "df_wind['RelativeHumidity_avg_lag_1'] = df_wind['RelativeHumidity_avg'].shift(1)\n",
    "df_wind['RelativeHumidity_avg_lag_2'] = df_wind['RelativeHumidity_avg'].shift(2)\n",
    "# df_wind['RelativeHumidity_avg_lag_1_diff'] = df_wind['RelativeHumidity_avg'].shift(1) - df_wind['RelativeHumidity_avg']\n",
    "# df_wind['RelativeHumidity_avg_lag_2_diff'] = df_wind['RelativeHumidity_avg'].shift(2) - df_wind['RelativeHumidity_avg']\n",
    "df_wind = df_wind.drop(columns=['WindSpeed_dwd', 'WindSpeed_ncep', 'Temperature_dwd', 'Temperature_ncep', 'RelativeHumidity_dwd', 'RelativeHumidity_ncep'])\n",
    "\n",
    "# Lag features (e.g., 1 time step in the past, assuming 30-minute intervals)\n",
    "df_wind['WindSpeed_dwd_lag_1'] = df_wind['WindSpeed_dwd'].shift(1)\n",
    "df_wind['Temperature_dwd_lag_1'] = df_wind['Temperature_dwd'].shift(1)\n",
    "df_wind['RelativeHumidity_dwd_lag_1'] = df_wind['RelativeHumidity_dwd'].shift(1)\n",
    "\n",
    "# Difference features\n",
    "df_wind['wind_speed_diff'] = df_wind['WindSpeed_dwd'] - df_wind['WindSpeed_ncep']\n",
    "df_wind['temperature_diff'] = df_wind['Temperature_dwd'] - df_wind['Temperature_ncep']\n",
    "\n",
    "# Interaction features\n",
    "df_wind['wind_temp_interaction'] = df_wind['WindSpeed_dwd'] * df_wind['Temperature_dwd']\n",
    "df_wind['humidity_wind_interaction'] = df_wind['WindSpeed_dwd'] * df_wind['RelativeHumidity_dwd']\n",
    "\n",
    "# Rolling window features (e.g., rolling mean over 1 hour, 2 intervals for 30-minute steps)\n",
    "df_wind['WindSpeed_dwd_rolling_mean_1h'] = df_wind['WindSpeed_dwd'].rolling(window=2).mean()\n",
    "df_wind['Temperature_dwd_rolling_std_2h'] = df_wind['Temperature_dwd'].rolling(window=4).std()\n",
    "\n",
    "# Drop rows with NaN values introduced by lagging or rolling (optional)\n",
    "df_wind = df_wind.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AirMassFlowPerHour --- idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "R_d = 287.05  # Specific gas constant for dry air (J/(kg·K))\n",
    "R_v = 461.5   # Specific gas constant for water vapor (J/(kg·K))\n",
    "p = 101325    # Standard atmospheric pressure in Pa\n",
    "\n",
    "# Assuming df_wind is your original DataFrame and contains 'Temperature_dwd', 'RelativeHumidity_dwd', 'WindSpeed_dwd'\n",
    "# Convert temperature from Celsius to Kelvin\n",
    "df_wind['Temperature_K'] = df_wind['Temperature_avg'] + 273.15\n",
    "\n",
    "# Calculate saturation vapor pressure (using temperature in Celsius), Tetens formula\n",
    "e_s = 0.61078 * np.exp((17.27 * df_wind['Temperature_avg']) / (df_wind['Temperature_avg'] + 237.3))\n",
    "\n",
    "# in pa\n",
    "e_s = 1000 * e_s\n",
    "\n",
    "# Calculate actual vapor pressure\n",
    "e = df_wind['RelativeHumidity_avg'] / 100 * e_s\n",
    "\n",
    "# Calculate air density (ρ) in kg/m³\n",
    "df_wind['AirDensity'] = (p - e) / (R_d * df_wind['Temperature_K']) + (e / (R_v * df_wind['Temperature_K']))\n",
    "\n",
    "# Calculate Air Mass Flow per hour (assuming a unit cross-sectional area)\n",
    "df_wind['AirMassFlowPerHour'] = df_wind['AirDensity'] * df_wind['WindSpeed_avg'] * 1000\n",
    "\n",
    "# Calculate Wind Power Density (W/m²)\n",
    "df_wind['WindPowerDensity'] = 0.5 * df_wind['AirDensity'] * (df_wind['WindSpeed_avg']/3.6) ** 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Load dataset (assuming df_merged is already loaded)\n",
    "# Select the latest 'reference_time' for each 'valid_time'\n",
    "df_latest = df_wind.groupby('valid_time').tail(1)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_latest.drop(columns=['Wind_MW', 'reference_time', 'valid_time'])\n",
    "y = df_latest['Wind_MW']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the quantiles for which models will be trained\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# Train one model for each quantile\n",
    "models = {}\n",
    "\n",
    "for quantile in quantiles:\n",
    "    model = GradientBoostingRegressor(loss='quantile', alpha=quantile, n_estimators=100, max_depth=3, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    models[quantile] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50894, 26) (12724, 26)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df_wind is the original dataframe with features already prepared\n",
    "# Define features and target\n",
    "X = df_latest.drop(columns=['Wind_MW', 'reference_time', 'valid_time'])\n",
    "y = df_latest['Wind_MW']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.columns = [col.replace(':', '_') for col in X_train.columns]\n",
    "X_test.columns = [col.replace(':', '_') for col in X_test.columns]\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "\n",
    "# Define quantiles to be predicted\n",
    "quantiles = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# Train separate models for each quantile\n",
    "models_lightgbm = {}\n",
    "for quantile in quantiles:\n",
    "    params = {\n",
    "        'objective': 'quantile',\n",
    "        'alpha': quantile,\n",
    "        'metric': 'quantile',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.07,\n",
    "        'n_estimators': 300,\n",
    "        'max_depth': 6\n",
    "    }\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    models_lightgbm[quantile] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.1: Train Loss = 29.1965, Test Loss = 29.9784\n",
      "Quantile 0.2: Train Loss = 40.3109, Test Loss = 41.3359\n",
      "Quantile 0.30000000000000004: Train Loss = 46.2676, Test Loss = 47.3926\n",
      "Quantile 0.4: Train Loss = 49.0065, Test Loss = 50.2207\n",
      "Quantile 0.5: Train Loss = 48.3344, Test Loss = 49.4861\n",
      "Quantile 0.6: Train Loss = 45.0970, Test Loss = 45.9745\n",
      "Quantile 0.7000000000000001: Train Loss = 39.3059, Test Loss = 39.9608\n",
      "Quantile 0.8: Train Loss = 30.7688, Test Loss = 31.1825\n",
      "Quantile 0.9: Train Loss = 18.6024, Test Loss = 19.1388\n",
      "Quantile 0.1: Train Loss = 56.0769, Test Loss = 57.2901\n",
      "Quantile 0.2: Train Loss = 112.1654, Test Loss = 114.5801\n",
      "Quantile 0.30000000000000004: Train Loss = 168.1937, Test Loss = 171.8107\n",
      "Quantile 0.4: Train Loss = 224.2788, Test Loss = 229.1147\n",
      "Quantile 0.5: Train Loss = 280.2575, Test Loss = 286.3015\n",
      "Quantile 0.6: Train Loss = 336.2462, Test Loss = 343.4811\n",
      "Quantile 0.7000000000000001: Train Loss = 391.0823, Test Loss = 399.4529\n",
      "Quantile 0.8: Train Loss = 441.8953, Test Loss = 451.3927\n",
      "Quantile 0.9: Train Loss = 499.5596, Test Loss = 510.3122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_pinball_loss\n",
    "\n",
    "# Assuming models is a dictionary of quantile regression models\n",
    "# quantiles is a list of quantiles used in training (e.g., [0.1, 0.2, ..., 0.9])\n",
    "\n",
    "train_losses = {}\n",
    "test_losses = {}\n",
    "\n",
    "\n",
    "for models_trained in [models, models_lightgbm]:\n",
    "    for quantile in quantiles:\n",
    "        # Extract the model for this quantile\n",
    "        model = models_trained[quantile]\n",
    "        \n",
    "        # Predict on the training set and compute the pinball loss\n",
    "        y_train_pred = model.predict(X_train_scaled)\n",
    "        train_loss = mean_pinball_loss(y_train, y_train_pred, alpha=quantile)\n",
    "        train_losses[quantile] = train_loss\n",
    "        \n",
    "        # Predict on the test set and compute the pinball loss\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "        test_loss = mean_pinball_loss(y_test, y_test_pred, alpha=quantile)\n",
    "        test_losses[quantile] = test_loss\n",
    "\n",
    "        print(f\"Quantile {quantile}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
